{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f749600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.logger import configure\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Crear carpetas\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "os.makedirs(\"./logs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a19ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_tensorboard/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 380      |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    fps             | 1378     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 584         |\n",
      "|    ep_rew_mean          | -107        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1061        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009692287 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.000547    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-113.12 +/- 0.10\n",
      "Episode length: 111.80 +/- 3.19\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 112        |\n",
      "|    mean_reward          | -113       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01205372 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.66      |\n",
      "|    explained_variance   | 0.89       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.194      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.567      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 464      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    fps             | 947      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 6144     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 519          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 937          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054632523 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 0.00976      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.8         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-111.73 +/- 0.56\n",
      "Episode length: 88.80 +/- 3.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 88.8        |\n",
      "|    mean_reward          | -112        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008337583 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 484      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    fps             | 915      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 459         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 914         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004731319 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 529         |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 906         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004613408 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-27.21 +/- 0.16\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -27.2       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008850981 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.52        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 530      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    fps             | 738      |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 526          |\n",
      "|    ep_rew_mean          | -110         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 752          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076224487 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.61        |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.4          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-41.86 +/- 0.29\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -41.9       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006465446 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 91.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 544      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    fps             | 668      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | -109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008378636 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 585         |\n",
      "|    ep_rew_mean          | -108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 705         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013151527 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.394       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-39.06 +/- 1.73\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -39.1       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 25000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011901485 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.47       |\n",
      "|    explained_variance   | -1.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.218       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 0.471       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 633      |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    fps             | 658      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 26624    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 642         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010035653 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | -0.271      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0807      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-36.82 +/- 4.29\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -36.8       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009398064 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0805      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 664      |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 639      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011224844 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.29       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.904       |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 722         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 665         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010783227 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.21       |\n",
      "|    explained_variance   | 0.00216     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0365      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-34.92 +/- 0.04\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -34.9       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 35000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006357274 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0447      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 740      |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    fps             | 635      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 36864    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 757         |\n",
      "|    ep_rew_mean          | -101        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008699606 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0252      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-35.84 +/- 6.27\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -35.8       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010256974 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0821      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 0.845       |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 774      |\n",
      "|    ep_rew_mean     | -100     |\n",
      "| time/              |          |\n",
      "|    fps             | 623      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 805         |\n",
      "|    ep_rew_mean          | -98.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009093492 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0579      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.839       |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-29.36 +/- 7.16\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -29.4       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 45000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009586927 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0684      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 820      |\n",
      "|    ep_rew_mean     | -97.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 612      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 45056    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 834         |\n",
      "|    ep_rew_mean          | -96.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009102877 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0401      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.825       |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 861         |\n",
      "|    ep_rew_mean          | -94.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011437818 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 0.809       |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-38.94 +/- 6.02\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -38.9       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008818409 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0344      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.802       |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 874      |\n",
      "|    ep_rew_mean     | -93.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 614      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 886         |\n",
      "|    ep_rew_mean          | -93.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009470768 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.797       |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-17.12 +/- 7.13\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | -17.1        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 55000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110707525 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 0.776        |\n",
      "|    value_loss           | 0.179        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 898      |\n",
      "|    ep_rew_mean     | -92.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 606      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 55296    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 920         |\n",
      "|    ep_rew_mean          | -90.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009287849 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.772       |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 918          |\n",
      "|    ep_rew_mean          | -90.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 621          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089734625 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | 0.81         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.113        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    std                  | 0.763        |\n",
      "|    value_loss           | 0.282        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=18.49 +/- 11.69\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 18.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006907224 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.59       |\n",
      "|    explained_variance   | -0.218      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    std                  | 0.763       |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 928      |\n",
      "|    ep_rew_mean     | -89.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 607      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 101      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 938         |\n",
      "|    ep_rew_mean          | -88.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010310866 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.58       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0735      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.759       |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-103.29 +/- 0.04\n",
      "Episode length: 67.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 67          |\n",
      "|    mean_reward          | -103        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 65000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010029264 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0983      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.75        |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 933      |\n",
      "|    ep_rew_mean     | -86.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 620      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 942         |\n",
      "|    ep_rew_mean          | -85.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004102052 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    std                  | 0.75        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | -84.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011234013 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.374       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.742       |\n",
      "|    value_loss           | 0.815       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=79.75 +/- 8.54\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.6e+03    |\n",
      "|    mean_reward          | 79.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 70000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01225588 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.46      |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.191      |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 0.735      |\n",
      "|    value_loss           | 0.31       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 967      |\n",
      "|    ep_rew_mean     | -83.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 621      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 964         |\n",
      "|    ep_rew_mean          | -82.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009600626 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    std                  | 0.736       |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-102.26 +/- 0.54\n",
      "Episode length: 73.20 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.2        |\n",
      "|    mean_reward          | -102        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010466916 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | -0.0357     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    std                  | 0.734       |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 972      |\n",
      "|    ep_rew_mean     | -81.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 632      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 75776    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 980         |\n",
      "|    ep_rew_mean          | -80.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 638         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012137925 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.725       |\n",
      "|    value_loss           | 0.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | -78.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010487459 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.362       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    std                  | 0.723       |\n",
      "|    value_loss           | 0.694       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=72.89 +/- 8.45\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 72.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009210445 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.35       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    std                  | 0.717       |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -77.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 631      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 129      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 988         |\n",
      "|    ep_rew_mean          | -76.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 637         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011879293 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.191       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    std                  | 0.708       |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-116.45 +/- 8.80\n",
      "Episode length: 131.60 +/- 27.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 132          |\n",
      "|    mean_reward          | -116         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 85000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069937063 |\n",
      "|    clip_fraction        | 0.0673       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.29        |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00898     |\n",
      "|    std                  | 0.709        |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 995      |\n",
      "|    ep_rew_mean     | -75.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 641      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 86016    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 978         |\n",
      "|    ep_rew_mean          | -75.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011233376 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.27       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 0.649       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=73.37 +/- 6.41\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | 73.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 90000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046582418 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.24        |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    std                  | 0.699        |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 956      |\n",
      "|    ep_rew_mean     | -75.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 634      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 141      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 969          |\n",
      "|    ep_rew_mean          | -73.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032554355 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.24        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.62         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    std                  | 0.7          |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 976         |\n",
      "|    ep_rew_mean          | -72.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012105392 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | -0.44       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.683       |\n",
      "|    value_loss           | 0.897       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=60.22 +/- 4.32\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.6e+03    |\n",
      "|    mean_reward          | 60.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 95000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01325292 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.11      |\n",
      "|    explained_variance   | 0.599      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.148      |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 0.672      |\n",
      "|    value_loss           | 0.333      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 973      |\n",
      "|    ep_rew_mean     | -71.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 634      |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 151      |\n",
      "|    total_timesteps | 96256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 979         |\n",
      "|    ep_rew_mean          | -70.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 638         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007671773 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    std                  | 0.674       |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-98.49 +/- 0.99\n",
      "Episode length: 121.80 +/- 2.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 122         |\n",
      "|    mean_reward          | -98.5       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012504991 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | -0.0898     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.31        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.669       |\n",
      "|    value_loss           | 0.784       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 985      |\n",
      "|    ep_rew_mean     | -68.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 641      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 156      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -67.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012076836 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    std                  | 0.668       |\n",
      "|    value_loss           | 0.538       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -66.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069600255 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.06        |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.12         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    std                  | 0.669        |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=79.77 +/- 9.30\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 79.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 105000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015228489 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | -0.102      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0906      |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    std                  | 0.659       |\n",
      "|    value_loss           | 0.38        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | -64.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 640      |\n",
      "|    iterations      | 52       |\n",
      "|    time_elapsed    | 166      |\n",
      "|    total_timesteps | 106496   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -61.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009949533 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    std                  | 0.652       |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=133.25 +/- 7.26\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 133         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014306184 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.645       |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.05e+03 |\n",
      "|    ep_rew_mean     | -59.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 635      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -57.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014684983 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.634       |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -56.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013025103 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.63        |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=123.88 +/- 14.48\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 124         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 115000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011249216 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    std                  | 0.619       |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | -52.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 633      |\n",
      "|    iterations      | 57       |\n",
      "|    time_elapsed    | 184      |\n",
      "|    total_timesteps | 116736   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -50.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 637         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013131583 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.608       |\n",
      "|    value_loss           | 0.414       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=41.08 +/- 86.14\n",
      "Episode length: 1220.20 +/- 544.17\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.22e+03   |\n",
      "|    mean_reward          | 41.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 120000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01081407 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.65      |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.126      |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 0.601      |\n",
      "|    value_loss           | 0.465      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | -49      |\n",
      "| time/              |          |\n",
      "|    fps             | 632      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 191      |\n",
      "|    total_timesteps | 120832   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -45.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013697728 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.595       |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -42.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012534187 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.592       |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-89.34 +/- 3.52\n",
      "Episode length: 162.40 +/- 25.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 162         |\n",
      "|    mean_reward          | -89.3       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 125000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010407171 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    std                  | 0.585       |\n",
      "|    value_loss           | 0.373       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.15e+03 |\n",
      "|    ep_rew_mean     | -41.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 642      |\n",
      "|    iterations      | 62       |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 126976   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -39.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006808957 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    std                  | 0.585       |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=133.22 +/- 121.00\n",
      "Episode length: 1248.60 +/- 442.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.25e+03     |\n",
      "|    mean_reward          | 133          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 130000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082498025 |\n",
      "|    clip_fraction        | 0.0827       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.52        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    std                  | 0.585        |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.15e+03 |\n",
      "|    ep_rew_mean     | -36.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 640      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 204      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -34.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 643         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007847078 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.585       |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=180.33 +/- 22.49\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 180         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 135000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013880101 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | -0.272      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    std                  | 0.58        |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.16e+03 |\n",
      "|    ep_rew_mean     | -32.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 635      |\n",
      "|    iterations      | 66       |\n",
      "|    time_elapsed    | 212      |\n",
      "|    total_timesteps | 135168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -29.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016812563 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.572       |\n",
      "|    value_loss           | 0.328       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -25         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012425463 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0808      |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    std                  | 0.564       |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-83.45 +/- 29.45\n",
      "Episode length: 190.60 +/- 136.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 191         |\n",
      "|    mean_reward          | -83.4       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014029264 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.553       |\n",
      "|    value_loss           | 0.5         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.22e+03 |\n",
      "|    ep_rew_mean     | -22.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 644      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 219      |\n",
      "|    total_timesteps | 141312   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -22         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013415137 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 0.546       |\n",
      "|    value_loss           | 0.498       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-70.51 +/- 27.53\n",
      "Episode length: 249.60 +/- 118.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 250        |\n",
      "|    mean_reward          | -70.5      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 145000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00818345 |\n",
      "|    clip_fraction        | 0.069      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.25      |\n",
      "|    explained_variance   | 0.806      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.67       |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.00791   |\n",
      "|    std                  | 0.545      |\n",
      "|    value_loss           | 17.2       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.22e+03 |\n",
      "|    ep_rew_mean     | -19.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 649      |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 223      |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -14.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012683762 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    std                  | 0.54        |\n",
      "|    value_loss           | 0.388       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -14.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013203485 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.673       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.537       |\n",
      "|    value_loss           | 0.957       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-104.88 +/- 0.06\n",
      "Episode length: 45.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 45           |\n",
      "|    mean_reward          | -105         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050827116 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.98         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    std                  | 0.536        |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.14e+03 |\n",
      "|    ep_rew_mean     | -12.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 657      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 230      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -9.94        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 660          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067310994 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.44         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    std                  | 0.536        |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-111.22 +/- 3.95\n",
      "Episode length: 86.80 +/- 17.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 86.8        |\n",
      "|    mean_reward          | -111        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 155000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008464817 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.6         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | -12.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 662      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 234      |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -10.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 665         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007491188 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 993         |\n",
      "|    ep_rew_mean          | -8.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008844273 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.75        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.534       |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-107.32 +/- 3.20\n",
      "Episode length: 49.80 +/- 9.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 49.8        |\n",
      "|    mean_reward          | -107        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008607395 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 978      |\n",
      "|    ep_rew_mean     | -6.91    |\n",
      "| time/              |          |\n",
      "|    fps             | 670      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 241      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 966         |\n",
      "|    ep_rew_mean          | -6.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 673         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014863382 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.531       |\n",
      "|    value_loss           | 2.13        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-118.40 +/- 1.18\n",
      "Episode length: 70.40 +/- 1.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 70.4        |\n",
      "|    mean_reward          | -118        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 165000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007966191 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    std                  | 0.531       |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 920      |\n",
      "|    ep_rew_mean     | -7.63    |\n",
      "| time/              |          |\n",
      "|    fps             | 675      |\n",
      "|    iterations      | 81       |\n",
      "|    time_elapsed    | 245      |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 898         |\n",
      "|    ep_rew_mean          | -7.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 678         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009511024 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.532       |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 891         |\n",
      "|    ep_rew_mean          | -7.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011157298 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.532       |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-116.64 +/- 4.16\n",
      "Episode length: 67.40 +/- 3.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 67.4        |\n",
      "|    mean_reward          | -117        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 170000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014526748 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.98        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 0.534       |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 891      |\n",
      "|    ep_rew_mean     | -2.99    |\n",
      "| time/              |          |\n",
      "|    fps             | 682      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 886         |\n",
      "|    ep_rew_mean          | -2.53       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029992465 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.85        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    std                  | 0.533       |\n",
      "|    value_loss           | 7.27        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-120.69 +/- 1.53\n",
      "Episode length: 73.40 +/- 0.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.4        |\n",
      "|    mean_reward          | -121        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 175000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015258285 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.587       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 9.17        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 887      |\n",
      "|    ep_rew_mean     | -0.586   |\n",
      "| time/              |          |\n",
      "|    fps             | 687      |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 256      |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 911        |\n",
      "|    ep_rew_mean          | 5.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 689        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02677379 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.14      |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.37       |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.00908   |\n",
      "|    std                  | 0.529      |\n",
      "|    value_loss           | 3.82       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-117.24 +/- 0.32\n",
      "Episode length: 68.80 +/- 0.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 68.8        |\n",
      "|    mean_reward          | -117        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018505871 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.743       |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    std                  | 0.526       |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 911      |\n",
      "|    ep_rew_mean     | 7.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 691      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 260      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 926         |\n",
      "|    ep_rew_mean          | 10.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018223383 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.08       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.964       |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    std                  | 0.523       |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 941        |\n",
      "|    ep_rew_mean          | 13.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 696        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 264        |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02269557 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.05      |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.205      |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.00285   |\n",
      "|    std                  | 0.518      |\n",
      "|    value_loss           | 0.619      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-115.36 +/- 0.34\n",
      "Episode length: 76.60 +/- 5.24\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 76.6      |\n",
      "|    mean_reward          | -115      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 185000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0179823 |\n",
      "|    clip_fraction        | 0.261     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.03     |\n",
      "|    explained_variance   | 0.288     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.11      |\n",
      "|    n_updates            | 900       |\n",
      "|    policy_gradient_loss | -0.00542  |\n",
      "|    std                  | 0.517     |\n",
      "|    value_loss           | 0.391     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 926      |\n",
      "|    ep_rew_mean     | 16       |\n",
      "| time/              |          |\n",
      "|    fps             | 697      |\n",
      "|    iterations      | 91       |\n",
      "|    time_elapsed    | 267      |\n",
      "|    total_timesteps | 186368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 919         |\n",
      "|    ep_rew_mean          | 16          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007906913 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.516       |\n",
      "|    value_loss           | 7.92        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-112.40 +/- 1.64\n",
      "Episode length: 77.60 +/- 6.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 77.6        |\n",
      "|    mean_reward          | -112        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011756873 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.74        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    std                  | 0.515       |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 889      |\n",
      "|    ep_rew_mean     | 15.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 701      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 271      |\n",
      "|    total_timesteps | 190464   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 900          |\n",
      "|    ep_rew_mean          | 19.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089495815 |\n",
      "|    clip_fraction        | 0.0893       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.03         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    std                  | 0.515        |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 891        |\n",
      "|    ep_rew_mean          | 20.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 706        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 275        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01710545 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.02      |\n",
      "|    explained_variance   | 0.912      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.68       |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.00184   |\n",
      "|    std                  | 0.518      |\n",
      "|    value_loss           | 9.32       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-116.44 +/- 0.17\n",
      "Episode length: 73.80 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 73.8        |\n",
      "|    mean_reward          | -116        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 195000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012491275 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    std                  | 0.517       |\n",
      "|    value_loss           | 8.28        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 881      |\n",
      "|    ep_rew_mean     | 21.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 707      |\n",
      "|    iterations      | 96       |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 867        |\n",
      "|    ep_rew_mean          | 22.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 709        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 279        |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00972272 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.03      |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.88       |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.00669   |\n",
      "|    std                  | 0.519      |\n",
      "|    value_loss           | 26.5       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-113.57 +/- 0.55\n",
      "Episode length: 66.40 +/- 2.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 66.4        |\n",
      "|    mean_reward          | -114        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019967686 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    std                  | 0.519       |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 848      |\n",
      "|    ep_rew_mean     | 20.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 711      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 282      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 833          |\n",
      "|    ep_rew_mean          | 20.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135857295 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.923        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.519        |\n",
      "|    value_loss           | 6.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 818         |\n",
      "|    ep_rew_mean          | 21.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021600388 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.599       |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    std                  | 0.516       |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=-31.91 +/- 158.76\n",
      "Episode length: 353.40 +/- 515.57\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 353        |\n",
      "|    mean_reward          | -31.9      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 205000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01837336 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.99      |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.363      |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 0.511      |\n",
      "|    value_loss           | 4.18       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 818      |\n",
      "|    ep_rew_mean     | 22.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 714      |\n",
      "|    iterations      | 101      |\n",
      "|    time_elapsed    | 289      |\n",
      "|    total_timesteps | 206848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 828         |\n",
      "|    ep_rew_mean          | 25.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015446174 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    std                  | 0.505       |\n",
      "|    value_loss           | 0.282       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-110.36 +/- 1.32\n",
      "Episode length: 81.60 +/- 4.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81.6        |\n",
      "|    mean_reward          | -110        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017678916 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.501       |\n",
      "|    value_loss           | 0.343       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 837      |\n",
      "|    ep_rew_mean     | 29       |\n",
      "| time/              |          |\n",
      "|    fps             | 717      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 210944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 845         |\n",
      "|    ep_rew_mean          | 31.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015219261 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    std                  | 0.501       |\n",
      "|    value_loss           | 4.46        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=127.84 +/- 193.72\n",
      "Episode length: 829.80 +/- 585.28\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 830        |\n",
      "|    mean_reward          | 128        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 215000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01034778 |\n",
      "|    clip_fraction        | 0.0967     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.88      |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.48       |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | -0.00362   |\n",
      "|    std                  | 0.499      |\n",
      "|    value_loss           | 8.24       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 850      |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 717      |\n",
      "|    iterations      | 105      |\n",
      "|    time_elapsed    | 299      |\n",
      "|    total_timesteps | 215040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 865         |\n",
      "|    ep_rew_mean          | 38.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014734268 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.497       |\n",
      "|    value_loss           | 4.25        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 879        |\n",
      "|    ep_rew_mean          | 43.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 720        |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 219136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01737719 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.677      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0666     |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 0.488      |\n",
      "|    value_loss           | 0.251      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=104.27 +/- 162.03\n",
      "Episode length: 751.60 +/- 435.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 752         |\n",
      "|    mean_reward          | 104         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011063021 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.06        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    std                  | 0.488       |\n",
      "|    value_loss           | 4.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 878      |\n",
      "|    ep_rew_mean     | 44.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 718      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 307      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 877         |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018055078 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.42        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 0.483       |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-111.97 +/- 3.15\n",
      "Episode length: 97.20 +/- 10.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 97.2        |\n",
      "|    mean_reward          | -112        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 225000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014437641 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.48        |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 874      |\n",
      "|    ep_rew_mean     | 48.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 721      |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 312      |\n",
      "|    total_timesteps | 225280   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 849         |\n",
      "|    ep_rew_mean          | 47.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018155687 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.449       |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    std                  | 0.477       |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 870         |\n",
      "|    ep_rew_mean          | 53.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010675052 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.477       |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-109.70 +/- 0.56\n",
      "Episode length: 74.60 +/- 0.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.6        |\n",
      "|    mean_reward          | -110        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012591992 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.76        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.474       |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 868      |\n",
      "|    ep_rew_mean     | 54.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 725      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 318      |\n",
      "|    total_timesteps | 231424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 862         |\n",
      "|    ep_rew_mean          | 55.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018951872 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | -0.877      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    std                  | 0.47        |\n",
      "|    value_loss           | 4.08        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=-110.14 +/- 1.11\n",
      "Episode length: 92.40 +/- 1.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 92.4        |\n",
      "|    mean_reward          | -110        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 235000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015975948 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    std                  | 0.472       |\n",
      "|    value_loss           | 9.36        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 873      |\n",
      "|    ep_rew_mean     | 58.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 728      |\n",
      "|    iterations      | 115      |\n",
      "|    time_elapsed    | 323      |\n",
      "|    total_timesteps | 235520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 882        |\n",
      "|    ep_rew_mean          | 61.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 730        |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 237568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02058208 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.65      |\n",
      "|    explained_variance   | -0.195     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.45       |\n",
      "|    n_updates            | 1150       |\n",
      "|    policy_gradient_loss | -0.00598   |\n",
      "|    std                  | 0.471      |\n",
      "|    value_loss           | 1.63       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 908         |\n",
      "|    ep_rew_mean          | 69.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015058325 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    std                  | 0.47        |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=233.60 +/- 134.17\n",
      "Episode length: 975.80 +/- 332.02\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 976        |\n",
      "|    mean_reward          | 234        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 240000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02161881 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.63      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.45       |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | -0.00841   |\n",
      "|    std                  | 0.469      |\n",
      "|    value_loss           | 2.58       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 921      |\n",
      "|    ep_rew_mean     | 73.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 728      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 331      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 917         |\n",
      "|    ep_rew_mean          | 74.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013288244 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    std                  | 0.469       |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=261.56 +/- 82.14\n",
      "Episode length: 1040.60 +/- 132.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.04e+03    |\n",
      "|    mean_reward          | 262         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 245000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005661082 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    std                  | 0.468       |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 910      |\n",
      "|    ep_rew_mean     | 73.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 726      |\n",
      "|    iterations      | 120      |\n",
      "|    time_elapsed    | 338      |\n",
      "|    total_timesteps | 245760   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 929         |\n",
      "|    ep_rew_mean          | 79          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010509381 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    std                  | 0.469       |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 935        |\n",
      "|    ep_rew_mean          | 80.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 729        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 342        |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00714562 |\n",
      "|    clip_fraction        | 0.0773     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.62      |\n",
      "|    explained_variance   | 0.928      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.00559   |\n",
      "|    std                  | 0.469      |\n",
      "|    value_loss           | 40.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=302.97 +/- 1.14\n",
      "Episode length: 1160.00 +/- 20.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.16e+03    |\n",
      "|    mean_reward          | 303         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009660631 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    std                  | 0.468       |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 933      |\n",
      "|    ep_rew_mean     | 81.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 725      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 251904   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 955         |\n",
      "|    ep_rew_mean          | 88.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024766555 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | -0.148      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.27        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    std                  | 0.472       |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=302.16 +/- 0.52\n",
      "Episode length: 1169.60 +/- 7.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.17e+03    |\n",
      "|    mean_reward          | 302         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 255000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022784919 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 0.472       |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 953      |\n",
      "|    ep_rew_mean     | 88.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 723      |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 353      |\n",
      "|    total_timesteps | 256000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 966         |\n",
      "|    ep_rew_mean          | 92.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016324835 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    std                  | 0.471       |\n",
      "|    value_loss           | 5.89        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=304.00 +/- 0.40\n",
      "Episode length: 1165.80 +/- 7.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.17e+03   |\n",
      "|    mean_reward          | 304        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 260000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02280762 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.62      |\n",
      "|    explained_variance   | 0.12       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.13       |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    std                  | 0.466      |\n",
      "|    value_loss           | 2.79       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | 95.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 720      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 978         |\n",
      "|    ep_rew_mean          | 98.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021906689 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.362       |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    std                  | 0.465       |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 105        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 723        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 364        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01943017 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.57      |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | -0.00742   |\n",
      "|    std                  | 0.461      |\n",
      "|    value_loss           | 1.57       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=301.24 +/- 1.29\n",
      "Episode length: 1164.80 +/- 15.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.16e+03    |\n",
      "|    mean_reward          | 301         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 265000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020851005 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.396       |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.465       |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01e+03 |\n",
      "|    ep_rew_mean     | 109      |\n",
      "| time/              |          |\n",
      "|    fps             | 720      |\n",
      "|    iterations      | 130      |\n",
      "|    time_elapsed    | 369      |\n",
      "|    total_timesteps | 266240   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021805562 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.84        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 0.465       |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=302.55 +/- 0.59\n",
      "Episode length: 1147.80 +/- 4.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.15e+03    |\n",
      "|    mean_reward          | 303         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010095596 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    std                  | 0.465       |\n",
      "|    value_loss           | 8.54        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03e+03 |\n",
      "|    ep_rew_mean     | 116      |\n",
      "| time/              |          |\n",
      "|    fps             | 717      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 376      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 118         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018398713 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.97        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    std                  | 0.465       |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.02e+03   |\n",
      "|    ep_rew_mean          | 118        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 720        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 380        |\n",
      "|    total_timesteps      | 274432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01069442 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.58      |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.8        |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | -0.00426   |\n",
      "|    std                  | 0.465      |\n",
      "|    value_loss           | 23.4       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=306.44 +/- 0.58\n",
      "Episode length: 1102.40 +/- 7.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.1e+03     |\n",
      "|    mean_reward          | 306         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 275000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014922973 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.37        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    std                  | 0.464       |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03e+03 |\n",
      "|    ep_rew_mean     | 122      |\n",
      "| time/              |          |\n",
      "|    fps             | 717      |\n",
      "|    iterations      | 135      |\n",
      "|    time_elapsed    | 385      |\n",
      "|    total_timesteps | 276480   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023813464 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.42        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    std                  | 0.458       |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=304.63 +/- 0.88\n",
      "Episode length: 1103.40 +/- 14.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.1e+03     |\n",
      "|    mean_reward          | 305         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027437972 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    std                  | 0.458       |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 122      |\n",
      "| time/              |          |\n",
      "|    fps             | 714      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 392      |\n",
      "|    total_timesteps | 280576   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 122         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011117802 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.29        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    std                  | 0.457       |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 992         |\n",
      "|    ep_rew_mean          | 121         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009509962 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.29        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    std                  | 0.456       |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=306.23 +/- 0.42\n",
      "Episode length: 1078.80 +/- 7.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.08e+03     |\n",
      "|    mean_reward          | 306          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 285000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117339445 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.21         |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    std                  | 0.455        |\n",
      "|    value_loss           | 20.6         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 999      |\n",
      "|    ep_rew_mean     | 125      |\n",
      "| time/              |          |\n",
      "|    fps             | 714      |\n",
      "|    iterations      | 140      |\n",
      "|    time_elapsed    | 401      |\n",
      "|    total_timesteps | 286720   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | 125         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016108837 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=239.05 +/- 137.29\n",
      "Episode length: 918.00 +/- 314.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 918         |\n",
      "|    mean_reward          | 239         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013961351 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01e+03 |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    fps             | 713      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 407      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 133         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015392423 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.844       |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 135         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027824547 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.0997      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.64        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.454       |\n",
      "|    value_loss           | 4.15        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=303.44 +/- 0.91\n",
      "Episode length: 1114.40 +/- 14.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.11e+03    |\n",
      "|    mean_reward          | 303         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 295000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027093355 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    fps             | 713      |\n",
      "|    iterations      | 145      |\n",
      "|    time_elapsed    | 416      |\n",
      "|    total_timesteps | 296960   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020406805 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.479       |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=304.50 +/- 0.54\n",
      "Episode length: 1114.00 +/- 9.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.11e+03    |\n",
      "|    mean_reward          | 304         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019976046 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.731       |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    std                  | 0.45        |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    fps             | 711      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 422      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAHHCAYAAABA5XcCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAxllJREFUeJzsnXd4FPX2xt/ZvpveEyAQegcpSpGigqJiAVFQUUARvSqC8MOKoiLCtYMFu+D1whVRFEVAERClijQBERAIoaWQnmy2zvz+2J3Z2T6z2U2yyfk8Tx7I7Mzsd0t23j3nPecwHMdxIAiCIAiCILxQ1PcCCIIgCIIgGioklAiCIAiCIPxAQokgCIIgCMIPJJQIgiAIgiD8QEKJIAiCIAjCDySUCIIgCIIg/EBCiSAIgiAIwg8klAiCIAiCIPxAQolosnz66af44IMP6nsZBEEQRAOGhBJRLzAMg+effz5i57/iiitwxRVX+L195cqVmD59Oi699NKIrUHM0qVLwTAMcnNz6+T+CKI++fLLL5GcnIyqqqr6XgomTZqEnJyc+l4GfvnlFzAMg19++aW+lyKJ4uJixMTEYO3atfW9lHqHhFIThr94+/vZuXNnfS8xIhw/fhz/+te/8OWXX6J37971vRyCkM0VV1zh9reanJyMSy+9FJ9++ilYlhX2mzRpktt+8fHx6NmzJ15//XWYzWav827btg2jR49GRkYGtFotcnJy8MADDyAvL0/y2ux2O5577jk88sgjiI2NDcvjJeqelJQU3HfffXj22Wfreyn1jqq+F0DUP3PnzkXr1q29trdr164eVhMefvrpJ7+3HThwAEuWLMF1111XhysiiPDSokULLFiwAABQVFSE//znP5g8eTKOHTuGf//738J+Wq0WH3/8MQCgrKwMX3/9NWbNmoXdu3fjiy++EPZ7++23MX36dLRp0waPPPIIsrKycOTIEXz88cdYsWIF1q5di4EDBwZd1/fff4+jR4/i/vvvD/Mjjm6GDBmCmpoaaDSa+l6KZP71r3/hrbfewqZNm3DVVVfV93LqD45osixZsoQDwO3evbvO7xsA99xzz9X5/dYX/HN96tSpiN1HVVVVxM5NNCyGDh3Kde3a1W1bdXU116JFCy4mJoazWCwcx3HcxIkTuZiYGLf97HY717dvXw4Ad+7cOY7jOG7r1q2cQqHgBg8ezFVXV7vt/88//3AZGRlcVlYWV1JSEnRtN910Ezdo0KDaPLywMnHiRK5Vq1b1vYyopVu3btzdd99d38uoVyj1RgTEarUiOTkZ99xzj9dtFRUV0Ol0mDVrlrCtsLAQkydPRkZGBnQ6HXr27InPPvss6P348xE8//zzYBjGa/t///tfXHbZZTAYDEhKSsKQIUPcoki+PEpS1pabmwuGYfDaa6/hww8/RNu2baHVanHppZdi9+7dQR8HABw+fBhXXXUV9Ho9WrRogXnz5rmlQ8SsW7cOgwcPRkxMDOLi4jBy5EgcPnw46H3wadMtW7bgoYceQnp6Olq0aCH7vH///TfGjh2LtLQ06PV6dOzYEbNnz3bbZ9++fbjuuusQHx+P2NhYDBs2zCsty69n69atmDZtGtLS0pCYmIgHHngAFosFZWVlmDBhApKSkpCUlITHH38cHMcJx4uf9zfffBOtWrWCXq/H0KFDcejQIZ/rvvXWW5GcnAydToe+ffviu+++87mmbdu2YebMmUhLS0NMTAxGjx6NoqIit33/+OMPjBgxAqmpqdDr9WjdujXuvfdet31ee+01DBw4ECkpKdDr9ejTpw+++uorr7Vt2LABgwYNQmJiImJjY9GxY0c8/fTTXvuFG4PBgP79+6O6utrr8YlRKBTC3wbvmXvxxRfBMAw+++wzGAwGt/3btm2LV155BRcuXAha/GAymbB+/XoMHz7c5+3//e9/0adPH+j1eiQnJ+P222/HmTNnhNunTp2K2NhYGI1Gr2PvuOMOZGZmwm63AwBWr16NkSNHolmzZtBqtWjbti1efPFF4XZ/+PMK8e/BpUuXCtv+/PNPTJo0CW3atIFOp0NmZibuvfdeFBcXe5333LlzmDx5srCe1q1b48EHH4TFYgl4vytXrhSek9TUVNx11104d+6c2z6TJk1CbGwszp07h1GjRiE2NhZpaWmYNWuW1+NlWRYLFy5E165dodPpkJGRgQceeAClpaVu+0l5zwPA1Vdfje+//97t77WpQak3AuXl5bh48aLbNoZhkJKSArVajdGjR2PVqlX44IMP3MLG3377LcxmM26//XYAQE1NDa644gr8888/mDp1Klq3bo2VK1di0qRJKCsrw/Tp08Oy3hdeeAHPP/88Bg4ciLlz50Kj0WDXrl3YtGkTrrnmGp/HyF3b8uXLUVlZiQceeAAMw+CVV17BLbfcgpMnT0KtVvtdW35+Pq688krYbDY8+eSTiImJwYcffgi9Xu+17+eff46JEydixIgRePnll2E0GvHee+9h0KBB2LdvnyQD6kMPPYS0tDTMmTMH1dXVss77559/YvDgwVCr1bj//vuRk5ODEydO4Pvvv8dLL70EwCH6Bg8ejPj4eDz++ONQq9X44IMPcMUVV2DLli3o16+f23oeeeQRZGZm4oUXXsDOnTvx4YcfIjExEdu3b0fLli0xf/58rF27Fq+++iq6deuGCRMmuB3/n//8B5WVlXj44YdhMpmwaNEiXHXVVTh48CAyMjKENV1++eVo3ry58Bx/+eWXGDVqFL7++muMHj3aa01JSUl47rnnkJubi4ULF2Lq1KlYsWIFAIeAvuaaa5CWloYnn3wSiYmJyM3NxapVq9zOs2jRItx0000YP348LBYLvvjiC9x2221Ys2YNRo4cKazthhtuQI8ePTB37lxotVr8888/2LZtW9DXMhycPHkSSqUSiYmJAfc7ceIEAIcPxWg0YuPGjRg8eLDPFDwAjBs3Dvfffz/WrFmDJ5980u959+zZA4vF4tP799JLL+HZZ5/F2LFjcd9996GoqAhvv/02hgwZgn379iExMRHjxo3Du+++ix9++AG33XabcKzRaMT333+PSZMmQalUAnAI4djYWMycOROxsbHYtGkT5syZg4qKCrz66qvBnipJbNiwASdPnsQ999yDzMxMHD58GB9++CEOHz6MnTt3Cl/izp8/j8suuwxlZWW4//770alTJ5w7dw5fffUVjEaj33Tb0qVLcc899+DSSy/FggULUFBQgEWLFmHbtm3Cc8Jjt9sxYsQI9OvXD6+99hp+/vlnvP7662jbti0efPBBYb8HHnhAOO+0adNw6tQpvPPOO9i3bx+2bdsGtVot+T0PAH369MGbb76Jw4cPo1u3bmF5XqOO+g5pEfUHnw7y9aPVaoX9fvzxRw4A9/3337sdf/3113Nt2rQRfl+4cCEHgPvvf/8rbLNYLNyAAQO42NhYrqKiQtgOj9Sbv/D4c889x4nfpsePH+cUCgU3evRozm63u+3Lsqzw/6FDh3JDhw6VvbZTp05xALiUlBS3NMPq1at9PgeePProoxwAbteuXcK2wsJCLiEhwS31VllZySUmJnJTpkxxOz4/P59LSEjw2u4J/9oNGjSIs9lswnY55x0yZAgXFxfHnT592m1f8fM4atQoTqPRcCdOnBC2nT9/nouLi+OGDBnitZ4RI0a4HT9gwACOYRjuX//6l7DNZrNxLVq0cHt9+Oddr9dzZ8+eFbbv2rWLA8DNmDFD2DZs2DCue/funMlkclvzwIEDufbt23utafjw4W5rmjFjBqdUKrmysjKO4zjum2++kZSCNhqNbr9bLBauW7du3FVXXSVse/PNNzkAXFFRUcBz1ZahQ4dynTp14oqKiriioiLuyJEj3LRp0zgA3I033ijsx6fe+P3++ecfbv78+RzDMFyPHj04juO4/fv3cwC46dOnB7zPHj16cMnJyQH3+fjjjzkA3MGDB9225+bmckqlknvppZfcth88eJBTqVTCdpZluebNm3Njxoxx2+/LL7/kAHC//vqrsM3z9eA4jnvggQc4g8Hg9t7w/GzZvHkzB4DbvHmz27H8e3DJkiUB7+N///uf11omTJjAKRQKn+8h/r3neb8Wi4VLT0/nunXrxtXU1Aj7r1mzhgPAzZkzx+0xAODmzp3rdu5evXpxffr0EX7/7bffOADcsmXL3PZbv36923ap73mO47jt27dzALgVK1YE3bexQqk3Au+++y42bNjg9rNu3Trh9quuugqpqanCN3AAKC0txYYNGzBu3Dhh29q1a5GZmYk77rhD2KZWqzFt2jRUVVVhy5YttV7rt99+C5ZlMWfOHCgU7m9fXym6UNc2btw4JCUlCb8PHjwYgOMbeyDWrl2L/v3747LLLhO2paWlYfz48W77bdiwAWVlZbjjjjtw8eJF4UepVKJfv37YvHlzwPvhmTJlivANW855i4qK8Ouvv+Lee+9Fy5Yt3c7JP492ux0//fQTRo0ahTZt2gi3Z2Vl4c4778TWrVtRUVHhduzkyZPdXod+/fqB4zhMnjxZ2KZUKtG3b1+fz+WoUaPQvHlz4ffLLrsM/fr1E0qUS0pKsGnTJowdOxaVlZXC4ysuLsaIESNw/Phxr7TF/fff77amwYMHw2634/Tp0wAgfGtfs2YNrFarv6faLSpYWlqK8vJyDB48GHv37hW28+davXq133RruPj777+RlpaGtLQ0dO7cGW+//TZGjhyJTz/91G2/6upqYb927drh6aefxoABA/DNN98AACorKwEAcXFxAe8vLi7O6/X2hE9Jif92AGDVqlVgWRZjx451e19mZmaiffv2wvuSYRjcdtttWLt2rVtrgRUrVqB58+YYNGiQsE38evDvhcGDB8NoNOLvv/8OuE6piO/DZDLh4sWL6N+/PwAIrzvLsvj2229x4403om/fvl7n8Pe59Mcff6CwsBAPPfQQdDqdsH3kyJHo1KkTfvjhB69j/vWvf7n9PnjwYLe/o5UrVyIhIQFXX3212/Pcp08fxMbGCs+z1Pc84HotPbMOTQlKvRG47LLLfP6B86hUKowZMwbLly+H2WyGVqvFqlWrYLVa3YTS6dOn0b59ey8B07lzZ+H22nLixAkoFAp06dJF1nFy1+YpHvgPC888v6/78UxHAUDHjh3dfj9+/DgA+K0kiY+PD3g/PJ6pEqnn5T9cA4XSi4qKYDQavdYOOJ43lmVx5swZdO3aVdju+bwlJCQAALKzs722+3ou27dv77WtQ4cO+PLLLwEA//zzDziOw7PPPuu3bLmwsNBNbAV7LYcOHYoxY8bghRdewJtvvokrrrgCo0aNwp133gmtVisct2bNGsybNw/79+93K60XXwjHjRuHjz/+GPfddx+efPJJDBs2DLfccgtuvfVWr/eemJKSEsHLAjgu0Pxz54+cnBx89NFHYBgGOp0O7du3R3p6utd+Op0O33//PQAI3hmxn40XSLxg8kdlZWVQMcXDefhZjh8/Do7jfL6+ANzS2ePGjcPChQvx3Xff4c4770RVVRXWrl0rpMF5Dh8+jGeeeQabNm3yEnDl5eWS1hmMkpISvPDCC/jiiy9QWFjo8z6KiopQUVEhOy3Ff+b4+vvq1KkTtm7d6rZNp9MhLS3NbVtSUpLb39Hx48dRXl7u830AQHgMUt/zgOu1DPRFtLFDQomQxO23344PPvgA69atw6hRo/Dll1+iU6dO6NmzZ1jO7++PMJgxM1KIozRiPC8AocJHGz7//HNkZmZ63a5SSfvT9PQ+heu8oeLvefO1PZTnkn98s2bNwogRI3zu49nWIthryTAMvvrqK+zcuRPff/89fvzxR9x77714/fXXsXPnTsTGxuK3337DTTfdhCFDhmDx4sXIysqCWq3GkiVLsHz5cuGcer0ev/76KzZv3owffvgB69evx4oVK3DVVVfhp59+8ruWW265xS2qOXHiRDdTsS9iYmL8mqY9H3+g/dq1aweVSoU///zT7z5msxlHjx4N+IUKcHieAIcIFYsxlmXBMAzWrVvn8zkQ91vq378/cnJy8OWXX+LOO+/E999/j5qaGrcvZWVlZRg6dCji4+Mxd+5ctG3bFjqdDnv37sUTTzwRMJon57Nm7Nix2L59Ox577DFccskliI2NBcuyuPbaayMeMfTE33tHDMuySE9Px7Jly3zezgstKe95Hl6IpaamhuFRRCcklAhJDBkyBFlZWVixYgUGDRqETZs2eVVHtWrVCn/++SdYlnX79syHwVu1auX3/ElJSSgrK/Pa7hnpadu2LViWxV9//YVLLrlE8vprszY5tGrVSojqiDl69Kjb723btgUApKenS7rYSUXqeflUmq+KMp60tDQYDAavtQOO502hUHhFimqLr+fu2LFjggGdX7darQ7r8wY4LtD9+/fHSy+9hOXLl2P8+PH44osvcN999+Hrr7+GTqfDjz/+6PaNe8mSJV7nUSgUGDZsGIYNG4Y33ngD8+fPx+zZs7F582a/a3799dfdIgPNmjUL62MLRExMDK688kps2rQJp0+f9vm38OWXX8JsNuOGG24IeK5OnToBAE6dOoXu3bsL29u2bQuO49C6dWt06NAh6JrGjh2LRYsWoaKiAitWrEBOTo6Q8gIcFWTFxcVYtWoVhgwZImw/depU0HPzEUXPzxvPz5rS0lJs3LgRL7zwAubMmSNs93yPpqWlIT4+PuDfki/45/no0aNeEeCjR4+G9JnUtm1b/Pzzz7j88st9FpB4Eug9z8M/p3z0vSlCHiVCEgqFArfeeiu+//57fP7557DZbG7f8ADg+uuvR35+vpuXyWaz4e2330ZsbCyGDh3q9/xt27ZFeXm527faCxcuCD4KnlGjRkGhUGDu3Lle3+gCRShqszY5XH/99di5cyd+//13YVtRUZHXN7wRI0YgPj4e8+fP9+kRCFTeHQip501LS8OQIUPw6aefenVd5p9HpVKJa665BqtXr3YbvVJQUIDly5dj0KBBklOEUvn222/dPEa///47du3aJTQHTU9PxxVXXIEPPvgAFy5c8Pv45FBaWur13uFFOJ9iUyqVYBjGLeqQm5uLb7/91u24kpISr/N7nssXffr0wfDhw4Ufuanl2vLMM8+A4zhMmjQJNTU1bredOnUKjz/+OLKysvDAAw8EPE+fPn2g0Wjwxx9/uG2/5ZZboFQq8cILL3g91xzHeZXbjxs3DmazGZ999hnWr1+PsWPHut3OR1fE57JYLFi8eHHQx9qqVSsolUr8+uuvbts9j/V1HwCwcOFCt98VCgVGjRqF77//3utx+zqep2/fvkhPT8f777/v9t5Yt24djhw5IlRSymHs2LGw2+148cUXvW6z2WyCOJTynufZs2cPEhIS3FLsTQ2KKBFYt26dT/PjwIED3Uy848aNw9tvv43nnnsO3bt39/qGcf/99+ODDz7ApEmTsGfPHuTk5OCrr77Ctm3bsHDhwoD+httvvx1PPPEERo8ejWnTpgkl7R06dHAzy7Zr1w6zZ8/Giy++iMGDB+OWW26BVqvF7t270axZM6FTsSe1WZscHn/8cXz++ee49tprMX36dKE9AB/R4omPj8d7772Hu+++G71798btt9+OtLQ05OXl4YcffsDll1+Od955R/b9yznvW2+9hUGDBqF37964//770bp1a+Tm5uKHH37A/v37AQDz5s0T+gI99NBDUKlU+OCDD2A2m/HKK6+E5TkT065dOwwaNAgPPvggzGYzFi5ciJSUFDz++OPCPu+++y4GDRqE7t27Y8qUKWjTpg0KCgqwY8cOnD17FgcOHJB1n5999hkWL16M0aNHo23btqisrMRHH32E+Ph4XH/99QAcBts33ngD1157Le68804UFhbi3XffRbt27dxe17lz5+LXX3/FyJEj0apVKxQWFmLx4sVo0aKFmxG5oTFkyBC89tprmDlzJnr06IFJkyYhKysLf//9Nz766COwLIu1a9d6mbQ90el0uOaaa/Dzzz9j7ty5wva2bdti3rx5eOqpp5Cbm4tRo0YhLi4Op06dwjfffIP777/frR9b7969hb91s9ns9aVs4MCBSEpKwsSJEzFt2jQwDIPPP/9cUjo3ISEBt912G95++20wDIO2bdtizZo1Xh6k+Ph4DBkyBK+88gqsViuaN2+On376yWfUav78+fjpp58wdOhQ3H///ejcuTMuXLiAlStXYuvWrT7bNajVarz88su45557MHToUNxxxx1Ce4CcnBzMmDEj6GPxZOjQoXjggQewYMEC7N+/H9dccw3UajWOHz+OlStXYtGiRbj11lslved5NmzYgBtvvLFJe5SoPUATJlB7AHiUyXKco8w1OzubA8DNmzfP5zkLCgq4e+65h0tNTeU0Gg3XvXt3r/NwnO/O3D/99BPXrVs3TqPRcB07duT++9//erUH4Pn000+5Xr16cVqtlktKSuKGDh3KbdiwQbjdsz2A1LXxJcKvvvqqpDX74s8//+SGDh3K6XQ6rnnz5tyLL77IffLJJz47c2/evJkbMWIEl5CQwOl0Oq5t27bcpEmTuD/++CPgfQTrqi71vIcOHeJGjx7NJSYmcjqdjuvYsSP37LPPuu2zd+9ebsSIEVxsbCxnMBi4K6+8ktu+fbuk9fCvn2e5vGfHaPHz/vrrr3PZ2dmcVqvlBg8ezB04cMDr8Z04cYKbMGECl5mZyanVaq558+bcDTfcwH311VdB1+RZpr13717ujjvu4Fq2bMlptVouPT2du+GGG7yeq08++YRr3749p9VquU6dOnFLlizxen9u3LiRu/nmm7lmzZpxGo2Ga9asGXfHHXdwx44d83oMtcFXZ25f+OrMHYhff/2Vu/nmm7nU1FROrVZzLVu25KZMmcLl5uZKPseqVas4hmG4vLw8r9u+/vprbtCgQVxMTAwXExPDderUiXv44Ye5o0ePeu07e/ZsDgDXrl07n/ezbds2rn///pxer+eaNWvGPf7440IrE3Hpv6/WI0VFRdyYMWM4g8HAJSUlcQ888AB36NAhr8+9s2fPCn8fCQkJ3G233cadP3/e52fB6dOnuQkTJnBpaWmcVqvl2rRpwz388MOc2WzmOM5/W4IVK1YIn2XJycnc+PHj3Vpk8I/B1+vo7/Pxww8/5Pr06cPp9XouLi6O6969O/f4449z58+f5zhO+nv+yJEjHADu559/9vUSNBkYjmvC7TYJgmgQ5ObmonXr1nj11VfdIgtE9GG329GlSxeMHTvWZwqIiB4effRR/Prrr9izZ0+TjiiRR4kgCIIIG0qlEnPnzsW7777r1guJiC6Ki4vx8ccfY968eU1aJAHkUSIIgiDCzLhx47x8RUR0kZKSQkLXCUWUCIIgCIIg/EAeJYIgCIIgCD9QRIkgCIIgCMIPJJQIgiAIgiD8ELVm7n//+9946qmnMH36dKFTqslkwv/93//hiy++gNlsxogRI7B48WJkZGQIx+Xl5eHBBx/E5s2bERsbi4kTJ2LBggWSZ2CxLIvz588jLi6uyVcCEARBEES0wHEcKisr0axZs4BDqj2JSqG0e/dufPDBB+jRo4fb9hkzZuCHH37AypUrkZCQgKlTp+KWW27Btm3bADj6e4wcORKZmZnYvn07Lly4gAkTJkCtVmP+/PmS7vv8+fNhn29FEARBEETdcObMGbehzcGIOjN3VVUVevfujcWLF2PevHm45JJLsHDhQpSXlyMtLQ3Lly/HrbfeCsAxuLNz587YsWMH+vfvj3Xr1uGGG27A+fPnhSjT+++/jyeeeAJFRUXQaDRB77+8vByJiYk4c+ZM2OdcEQRBEAQRGSoqKpCdnY2ysjIkJCRIPi7qIkoPP/wwRo4cieHDh2PevHnC9j179sBqtbpN5+7UqRNatmwpCKUdO3age/fubqm4ESNG4MEHH8Thw4fRq1cvr/szm81uQwIrKysBOOYAkVAiCIIgiOhCrm0mqoTSF198gb1792L37t1et+Xn50Oj0XgNH8zIyEB+fr6wj1gk8bfzt/liwYIFeOGFF8KweoIgCIIgoo2oqXo7c+YMpk+fjmXLlkGn09XZ/T711FMoLy8Xfs6cOVNn900QBEEQRP0SNUJpz549KCwsRO/evaFSqaBSqbBlyxa89dZbUKlUyMjIgMViQVlZmdtxBQUFyMzMBABkZmaioKDA63b+Nl9otVohzUbpNoIgCIJoWkRN6m3YsGE4ePCg27Z77rkHnTp1whNPPIHs7Gyo1Wps3LgRY8aMAQAcPXoUeXl5GDBgAABgwIABeOmll1BYWIj09HQAwIYNGxAfH48uXbqEdb12ux1WqzWs5ySIxoharYZSqazvZRAEQfgkaoRSXFwcunXr5rYtJiYGKSkpwvbJkydj5syZSE5ORnx8PB555BEMGDAA/fv3BwBcc8016NKlC+6++2688soryM/PxzPPPIOHH34YWq02LOvkOA75+flekS2CIPyTmJiIzMxM6k1GEESDI2qEkhTefPNNKBQKjBkzxq3hJI9SqcSaNWvw4IMPYsCAAYiJicHEiRMxd+7csK2BF0np6ekwGAz0wU8QAeA4DkajEYWFhQCArKysel4RQRCEO1HXR6m+qaioQEJCAsrLy738Sna7HceOHUN6ejpSUlLqaYUEEX0UFxejsLAQHTp0oDQcQRARIdD1OxBRY+aOBnhPksFgqOeVEER0wf/NkK+PIIiGBgmlCEDpNoKQB/3NEATRUCGhRBAEQRAE4QcSSkST5quvvsJXX31V38sgCIIgGigklIg6Izc3FwzDYP/+/XV2n7/88gsYhvHZruG3337DrFmzhPYRtaW4uBjp6enIzc0Ny/kaCkuXLnUbDfT888/jkksukXz8xYsXkZ6ejrNnz4Z/cQRBEBGGhBIBAJg0aRIYhvH6ufbaa+t7abVi4MCBuHDhgtek6KKiItx///347rvv0KJFi7Dc10svvYSbb74ZOTk5YTlfQ2XWrFnYuHGj5P1TU1MxYcIEPPfccxFcFUEQRGRoVH2UiNpx7bXXYsmSJW7bwtWIs77QaDQ+x9OkpaXhyJEjYbsfo9GITz75BD/++GOtzmO328EwDBSKhvsdJjY2FrGxsbKOueeee9CnTx+8+uqrSE5OjtDKCIIgwk/D/TRuJHAcB6PFVi8/cltkabVaZGZmuv0kJSUBAO68806MGzfObX+r1YrU1FT85z//AQCsX78egwYNQmJiIlJSUnDDDTfgxIkTfu/PM6UDAN9++61bBdSJEydw8803IyMjA7Gxsbj00kvx888/ux1jNpuFMTZarRbt2rXDJ598AsB36u3rr79G165dodVqkZOTg9dff93tfDk5OZg/fz7uvfdexMXFoWXLlvjwww8DPndr166FVqt1S+Px9/3DDz+gR48e0Ol06N+/Pw4dOuT1HHz33Xfo0qULtFot8vLyUFpaigkTJiApKQkGgwHXXXcdjh8/7nXcmjVr0LFjRxgMBtx6660wGo347LPPkJOTg6SkJEybNg12u93tuZo1axaaN2+OmJgY9OvXD7/88ovX69KyZUsYDAaMHj0axcXFbrd7pt5YlsXcuXPRokULaLVaXHLJJVi/fr3bMV27dkWzZs3wzTffBHweCYJoHBgttvpeQtigiFKEqbHa0WVO7aIMofLX3BEwaMLzEo8fPx633XYbqqqqhGjCjz/+CKPRiNGjRwMAqqurMXPmTPTo0QNVVVWYM2cORo8ejf3794ccIamqqsL111+Pl156CVqtFv/5z39w44034ujRo2jZsiUAYMKECdixYwfeeust9OzZE6dOncLFixd9nm/Pnj0YO3Ysnn/+eYwbNw7bt2/HQw89hJSUFEyaNEnY7/XXX8eLL76Ip59+Gl999RUefPBBDB06FB07dvR53t9++w19+vTxedtjjz2GRYsWITMzE08//TRuvPFGHDt2DGq1GoAjGvXyyy/j448/RkpKCtLT03HHHXfg+PHj+O677xAfH48nnngC119/Pf766y+349566y188cUXqKysxC233ILRo0cjMTERa9euxcmTJzFmzBhcfvnlgsidOnUq/vrrL3zxxReCcLn22mtx8OBBtG/fHrt27cLkyZOxYMECjBo1CuvXrw+aMlu0aBFef/11fPDBB+jVqxc+/fRT3HTTTTh8+DDat28v7HfZZZfht99+w+TJkwOejyCI6KfMaA3b9ae+aRyPgggLa9as8UqpPP3003j66acxYsQIxMTE4JtvvsHdd98NAFi+fDluuukmxMXFAYAwjJjn008/RVpaGv766y+vOX1S6dmzJ3r27Cn8/uKLL+Kbb77Bd999h6lTp+LYsWP48ssvsWHDBgwfPhwA0KZNG7/ne+ONNzBs2DA8++yzAIAOHTrgr7/+wquvvuomlK6//no89NBDAIAnnngCb775JjZv3uxXKJ0+fRrNmjXzedtzzz2Hq6++GgDw2WefoUWLFvjmm28wduxYAI7I3OLFi4XHyQukbdu2YeDAgQCAZcuWITs7G99++y1uu+024bj33nsPbdu2BQDceuut+Pzzz1FQUIDY2Fh06dIFV155JTZv3oxx48YhLy8PS5YsQV5enrDWWbNmYf369ViyZAnmz5+PRYsW4dprr8Xjjz8uPD/bt2/3ihCJee211/DEE0/g9ttvBwC8/PLL2Lx5MxYuXIh3331X2K9Zs2bYt2+f3/MQBNE4YFkO5TVWNEvU1/dSwgIJpQijVyvx19wR9Xbfcrjyyivx3nvvuW3j/SQqlQpjx47FsmXLcPfdd6O6uhqrV6/GF198Iex7/PhxzJkzB7t27cLFixfBsiwAIC8vL2ShVFVVheeffx4//PADLly4AJvNhpqaGuTl5QEA9u/fD6VSiaFDh0o635EjR3DzzTe7bbv88suxcOFC2O12YXxGjx49hNsZhkFmZqYwj8wXNTU10Ol0Pm8bMGCA8P/k5GR07NjRzR+l0Wjc7u/IkSNQqVTo16+fsC0lJcXrOIPBIIgkAMjIyEBOTo6b2M3IyBDWffDgQdjtdnTo0MFtfWazWRi5c+TIESFCKF6/P6FUUVGB8+fP4/LLL3fbfvnll+PAgQNu2/R6PYxGo8/zEATReDDZ7LDZOVjtLNTK6Hf4kFCKMAzDRE34MSYmBu3atfN7+/jx4zF06FAUFhZiw4YN0Ov1blVxN954I1q1aoWPPvoIzZo1A8uy6NatGywWi8/zKRQKLx+V5wiLWbNmYcOGDXjttdfQrl076PV63HrrrcI59frIfGPh01s8DMMIws8XqampKC0tDem+9Hp9SJ2pfa0x0LqrqqqgVCqxZ88er3lqcs3ZoVBSUoK0tLSI3w9BEPWLyco6/7U3CqEU/Y+AqDMGDhyI7OxsrFixAsuWLcNtt90mXJiLi4tx9OhRPPPMMxg2bBg6d+4cVDikpaWhsrIS1dXVwjbPHkvbtm3DpEmTMHr0aHTv3h2ZmZlufYq6d+8OlmWxZcsWSY+hc+fO2LZtm9d91HYYa69evfDXX3/5vG3nzp3C/0tLS3Hs2DF07tw54BptNht27dolbOOf3y5dutRqjXa7HYWFhWjXrp3bD18Z2LlzZ7f79Vy/J/Hx8WjWrJnP59RzrYcOHUKvXr1CXj9B1CeVJppDKJUaq6OAhBdM0U50hDqIOsFsNiM/P99tm0qlQmpqqvD7nXfeiffffx/Hjh3D5s2bhe1JSUlISUnBhx9+iKysLOTl5eHJJ58MeH/9+vWDwWDA008/jWnTpmHXrl1YunSp2z7t27fHqlWrcOONN4JhGDz77LNukZ2cnBxMnDgR9957r2DmPn36NAoLCwUPkJj/+7//w6WXXooXX3wR48aNw44dO/DOO+9g8eLFcp4qL0aMGIGnnnoKpaWlQqUgz9y5c5GSkoKMjAzMnj0bqampGDVqlN9ztW/fHjfffDOmTJmCDz74AHFxcXjyySfRvHlzr7ShHDp06IDx48djwoQJeP3119GrVy8UFRVh48aN6NGjB0aOHIlp06bh8ssvx2uvvYabb74ZP/74Y0B/EuAwqz/33HNo27YtLrnkEixZsgT79+/HsmXLhH2MRiP27NmD+fPnh7x+gqgvOI5DfrkJcTp18J0JmAShZA+yZ3RAESVCYP369cjKynL7GTRokNs+48ePx19//YXmzZu7+VIUCgW++OIL7NmzB926dcOMGTPw6quvBry/5ORk/Pe//8XatWvRvXt3/O9//8Pzzz/vts8bb7yBpKQkDBw4EDfeeCNGjBiB3r17u+3z3nvv4dZbb8VDDz2ETp06YcqUKW5RKjG9e/fGl19+iS+++ALdunXDnDlzMHfuXDcjdyh0795dOLcn//73vzF9+nT06dMH+fn5+P7776HRaAKeb8mSJejTpw9uuOEGDBgwABzHYe3atV6pNbksWbIEEyZMwP/93/+hY8eOGDVqFHbv3i1UEPbv3x8fffQRFi1ahJ49e+Knn37CM888E/Cc06ZNw8yZM/F///d/6N69O9avX4/vvvvOreJt9erVaNmyJQYPHlyr9RNEfcBxjuhImdG3jYBwp8biEEhmW+MQSgwnt9lOE6eiogIJCQkoLy9HfHy8220mkwmnTp1C69at/Rp7icbLDz/8gMceewyHDh2CQqHAL7/8giuvvBKlpaVe/aKaGv3798e0adNw5513+ryd/naIhozNzuLIhUpoVAp0yIgNyVPYVDDb7DiWXwUAYBiga7P4BvN8Bbp+B4JSbwQRJkaOHInjx4/j3LlzyM7Oru/lNBguXryIW265BXfccUd9L4UgQoKPJlhsLIqrLUiNje6JBZHEZHFZIzgOMNtY6GRWYDc0SCgRRBh59NFH63sJDY7U1FShLxNBRCPivEthhRlJBg2UioYRJWlomDzSbWZr9Asl8igRRIS44oorwHFck0+7EUS0w4qUkp3lcLHKXI+radjw/iTh90Zg6CahRBAEQRAyKKo0w2ZvHKXv4cYzotQYKt9IKBEEQRBEAFiPmieOAworKarkiZ3lYLW5P1eewikaIaFEEARBEAHwVRteUm1pNOXv4cJXms1q42Bno7u4noQSQRAEQQTA12We4xzGbsKFvzRbtKffSCgRBEEQRAA8U288ZUarl3m5KePvuSChRBARYMWKFfjmm2/qexl+WbFiBb799tv6XgZBEHVAoLbM+RWmultIA8dfKtJki27jO/VRqiMOni2v0/vr3iKhTu8vnKxfvx6zZ8/G1q1b63spPvnll1/Cur6cnBw8+uij1IOJIBoogQZYVJlsqDLbEKtt2pdTjuP8DsGN9qgbRZQIAMCkSZPAMAwYhoFarUZGRgauvvpqfPrpp25DaCPNqVOnMH36dKxdu1aYaF/XXHHFFX5Fy8WLFzF16lR8//339bY+giDqlmCDvoqoAg5mG+v3eYp20zsJJULg2muvxYULF5Cbm4t169bhyiuvxPTp03HDDTfAZrPVyRpat26No0ePokOHDnVyf3JJTU3FoUOH0Llz5/peioDdbq9TMUsQTY1gNVvVZluT76sUyIfEstEtlkgoEQJarRaZmZlo3rw5evfujaeffhqrV6/GunXrsHTpUmG/srIy3HfffUhLS0N8fDyuuuoqHDhwQLj9wIEDuPLKKxEXF4f4+Hj06dMHf/zxByoqKqDX67Fu3Tq3+/3mm28QFxcHo9GI3NxcMAyD/fv3C7dv2bIFl112GbRaLbKysvDkk08GFW5bt27F4MGDodfrkZ2djWnTpqG6ulq4ffHixWjfvj10Oh0yMjJw6623AnBE1rZs2YJFixYJEbbc3FzY7XZMnjwZrVu3hl6vR8eOHbFo0SK3+5w0aRJGjRqF1157DVlZWUhJScHDDz8Mq9Uq7FNYWIgbb7wRer0erVu3xrJly7zW/sYbb6B79+6IiYlBdnY2HnroIVRVVQm3L126FImJifjuu+/QpUsXaLVa5OXlBXw+CIIIHX9mbh6OAypMdfNlsqESrAO3v7RcNEBCiQjIVVddhZ49e2LVqlXCtttuuw2FhYVYt24d9uzZg969e2PYsGEoKSkBAIwfPx4tWrTA7t27sWfPHjz55JNQq9WIj4/HDTfcgOXLl7vdx7JlyzBq1CgYDAav+z937hyuv/56XHrppThw4ADee+89fPLJJ5g3b57fNZ84cQLXXnstxowZgz///BMrVqzA1q1bMXXqVADAH3/8gWnTpmHu3Lk4evQo1q9fjyFDhgAAFi1ahAEDBmDKlCm4cOECLly4gOzsbLAsixYtWmDlypU4cuQIXnjhBcyePRtffvml231v3rwZJ06cwObNm/HZZ59h6dKlbiJz0qRJOHPmDDZv3oyvvvoKixcvRmFhods5FAoF3nrrLRw+fBifffYZNm3a5DUrzWg04uWXX8bHH3+Mw4cPIz093e/zQRBE7QiWegOA8hpr8J0aMcGEkDmKK9+atvuMkESnTp3w559/AnBEan7//XcUFhZCq3VM0H7ttdfw7bff4quvvsL999+PvLw8PPbYY+jUqRMAoH379sK5xo8fj7vvvhtGoxEGgwEVFRX44Ycf/Fa4LV68GNnZ2XjnnXfAMAw6deqE8+fP44knnsCcOXOgUHhr/QULFmD8+PGCz6h9+/Z46623MHToULz33nvIy8tDTEwMbrjhBsTFxaFVq1bo1asXACAhIQEajQYGg8HNg6RUKvHCCy8Iv+fk5GDbtm348ssvMXbsWGF7UlIS3nnnHSiVSnTq1AkjR47Exo0bMWXKFBw7dgzr1q3D77//jksvvRQA8Mknn3il8cT+qJycHMybNw//+te/sHjxYmG71WrF4sWL0bNnTz+vGkEQ4YILmnxzpN/sLNdkh+UGM2xTRIlo1HAcB4Zx/PEfOHAAVVVVSElJQWxsrPBz6tQpnDhxAgAwc+ZM3HfffRg+fDj+/e9/C9sB4Prrr4darcZ3330HAPj6668RHx+P4cOH+7zvI0eOYMCAAcL9A8Dll1+OqqoqnD171ucxBw4cwNKlS93WN2LECLAsi1OnTuHqq69Gq1at0KZNG9x9991YtmwZjEZj0OfhtddeQ6dOnaDX68EwDN555x2vlFfXrl2hVLomZWdlZQkRoyNHjkClUqFPnz7C7Z06dfIamvvzzz9j2LBhaN68OeLi4nD33XejuLjYbY0ajQY9evQIumaCIGqPlIgSxwEVTTSqZLWzQbtvR/MoExJKRFCOHDmC1q1bAwCqqqqQlZWF/fv3u/0cPXoUjz32GADg+eefx+HDhzFy5Ehs2rQJXbp0ESJGGo0Gt956q5B+W758OcaNGweVKnzBzaqqKjzwwANu6ztw4ACOHz+Otm3bIi4uDnv37sX//vc/ZGVlYc6cOejZsyfKysr8nnPZsmV48cUX8eabb6KgoAAcx+Hxxx+HxWJx20+tVrv9zjCMLKN1bm4ubrjhBvTo0QNff/019uzZg3fffRcA3O6LF2sEQUQeKUIJACpMTVMoBfMnAYDZyoKN0lEmlHojArJp0yYcPHgQM2bMAAD07t0b+fn5UKlUyMnJ8Xtchw4d0KFDB8yYMQN33HEHlixZgtGjRwNwpN+uvvpqHD58GJs2bQroN+rcuTO+/vprt6jWtm3bEBcXhxYtWvg8pnfv3vjrr7/Qrl07v+dVqVQYPnw4hg8fjueeew6JiYnYtGkTbrnlFmg0Gtjt7n/4O3bswGWXXYbrrrtO2LZ9+3a/5/dFp06dYLPZsGfPHiH1dvToUTeBtmfPHrAsi9dff11IK3r6oAiCqFuCmbl5Kk1NM/0mtfO2yWaHQRN9soMiSoSA2WxGfn4+zp07h71792L+/Pm4+eabccMNN2DChAkAgOHDh2PAgAEYNWoUfvrpJ+Tm5mL79u2YPXs2/vjjD9TU1GDq1Kn45ZdfcPr0aWzbtg27d+928+EMGTIEmZmZGD9+PFq3bo1+/fr5XdNDDz2EM2fO4JFHHsHff/+N1atX47nnnsPMmTN9+pMA4IknnsD27dsxdepU7N+/H8ePH8fq1asFM/eaNWvw1ltvYf/+/Th9+jT+85//gGVZdOzYEYDDF7Rr1y7k5ubi4sWLwm07d+7EunXrcOzYMTz55JM4ePCgrOe3Y8eOuPbaa/HAAw9g165d2LNnD+677z7o9Xphn3bt2sFqteLtt9/GyZMn8fnnn+P999+XdT8EQYQXqXEQjgMqm2BUyWSRFjWPVp9S9Em7KCUaOmWvX78eWVlZUKlUSEpKQs+ePfHWW29h4sSJgihhGAZr167F7Nmzcc8996CoqAiZmZkYMmQIMjIyoFQqUVxcjAkTJqCgoACpqam45ZZb3IzQDMPgjjvuwCuvvII5c+YEXFPz5s2xdu1aPPbYY+jZsyeSk5MxefJkPPPMM36P6dGjB7Zs2YLZs2dj8ODB4DgObdu2xbhx4wAAiYmJWLVqFZ5//nmYTCa0b98e//vf/9C1a1cAwKxZszBx4kR06dIFNTU1OHXqlJDKu/POOwEAd9xxBx566CGsXbtW1nO8ZMkS3HfffRg6dCgyMjIwb948PPvss8LtPXv2xBtvvIGXX34ZTz31FIYMGYIFCxYIQpUgiLonUGduTypqbEg0aCK4moaHVP9RtM58Yzg57wACFRUVSEhIQHl5OeLj491uM5lMOHXqFFq3bg2dTldPKySI6IP+doiGzJkSI8qM0iJFDAN0yYqHoomk31iWw+HzFZL2jdEq0SYtNsIr8k+g63cgKPVGEARBEAGQE07gOKDS3HSaT8qpZovW1BsJJYIgCIIIgFQzN09TahMgR/zYWQ7WKBz1QkKJIAiCaBAE68VTX8hdVYXJKsvXFM1IaQ0gJhp9SiSUCIIgiAaB2WZvkMNl5Yoelm066Te5wkeusGoIkFCKAE3lmwRBhAv6myEAgOUAYwO8kIYS6CqXaP6OduQKJXMU+pRIKIURviuzlHEYBEG44P9mPDubE00LluNgNDc8oSQ/+dY00m9mmx0yBg8AiM7UG/VRCiNKpRKJiYnCbC+DwUBjJggiABzHwWg0orCwEImJiW5z8oimB8cB1ZaGl7IKRe+wLFBltiFO13jFv9RGk2LMNtZt0kI0QEIpzPAT53mxRBBEcBITE4W/HaLpwnEcaiz2BnchDdVjXl5jbdxCKYRBtxznEEs6dfR8KSKhFGYYhkFWVhbS09NhtTaNHDVB1Aa1Wk2RJAKA4yLKcYDRYkeMtuFcnrgQUm+Ao0s3l9iwRF84CTWNZrLaSSgRjjQcffgTBEFIh+9XVG2xNSihJNeHw2NnOVRb7IhtQI8lnIRawRZtjScb56tHEARBRB183MZotgNx9boUN0KNKAGO9FtDE0q5F6vx85EC7MsrQ2qsBq1SYpCTakCrlBhkJxmgUXnXeVWZbThXWoOzpUacLa3BhfIatEmNRecs6aNAeKKtRUDDevUC8N577+G9995Dbm4uAKBr166YM2cOrrvuOgCOWVH/93//hy+++AJmsxkjRozA4sWLkZGRIZwjLy8PDz74IDZv3ozY2FhMnDgRCxYsgEoVNU8DQRBEo0UcUWpI1KZ4raLGiuaJetnHsSyHgkoTzpeZ0CrFgNRYbchrsNlZ7M0rw8YjBdhwpAAni6r97qtggMwEHXJSYhCjVeFcaQ3OldWg3Ee38awEHT68u6/s9fApO6PFhuIqC0qqHT/F1RaUVJtRXG1BZrwO91zeWva5I0HUKIQWLVrg3//+N9q3bw+O4/DZZ5/h5ptvxr59+9C1a1fMmDEDP/zwA1auXImEhARMnToVt9xyC7Zt2wYAsNvtGDlyJDIzM7F9+3ZcuHABEyZMgFqtxvz58+v50REEQRB84IZlG5aPpTZC6dDZcry/5QTidSok6jVIMKgRr1MjXq9y/qtGhcmK3ItGnC6uxqmL1cgtrkZeidEtRdU8UY9e2Ym4pGUierVMRNdmCV7PD8dxqDTbUFhhQkGFGefLarDjRDE2HS10G+qrUjC4NCcZg9qnotJkQ25xNXIvVuN0sRE1VjvOlzkEmicJejVaJOnRPFGPn/4qwIVyE6pMNsTq5EmJhT8fxy9HC2G2+U/B9WqZ2GCEEsNFcaOH5ORkvPrqq7j11luRlpaG5cuX49ZbbwUA/P333+jcuTN27NiB/v37Y926dbjhhhtw/vx5Icr0/vvv44knnkBRURE0Go2k+wx1+jBBEAQRmPxyE4oqzQCAZok6pNQiihIuOI7DoXMVIR//yP/2Irc4tN56SgWD1FgNCirMPm/rkB6LFskGlFSZUVRlQVGl2W9aK0GvxpUd0zCscwaGdEhDgt67Go/jOBRVmXG62Ijci9UwWuxonqhHi2SHOBJX8A16eRPOltbgpVHd0KNFouTHVG224faPdgq/q5UMkgwapMRokBqnRUqMBskxWrRJi8Fd/VtJPq8UQr1+R01ESYzdbsfKlStRXV2NAQMGYM+ePbBarRg+fLiwT6dOndCyZUtBKO3YsQPdu3d3S8WNGDECDz74IA4fPoxevXr5vC+z2Qyz2fUmragI/Q+GIAiC8I/YC2S02JFSj2vhqU0oIb/chNxiI5QMg/sGt0aV2YaKGisq+X9NNpTXWKHXKNE6NQY5KTHISTEgx/n/5kl6qJUKVJis+PNMOQ6cLcOe06U4cKYMxdUWHMmvxJH8Sq/7jdWqkBGvRUa8Dl2bxWNY5wz0bZUElTJwj2mGYZAep0N6nA6X5iQH3Ldrs3icLa3BiaIqWULpZFEVAIcQ/vHRIYjVqhp8VWBUCaWDBw9iwIABMJlMiI2NxTfffIMuXbpg//790Gg0SExMdNs/IyMD+fn5AID8/Hw3kcTfzt/mjwULFuCFF14I7wMhCIIgvBD3KzJaGobhl62FUtp5qhgA0DcnCU9d3znk88Tr1BjUPhWD2qcCcER+zpXVYF9eGc6X1SArQYeMeMdPerwWBk3kL+3dmiXgx8OB/U6++McplHo0T4yaHlNRJZQ6duyI/fv3o7y8HF999RUmTpyILVu2RPQ+n3rqKcycOVP4vaKiAtnZ2RG9T4IgiKYIK1JKFhsLq52FOkgUJNLUxpuy66RDKF3dJSPInvJgGAYtkgxokWQI63nl0LW5I3V14qJMoVToEErdWySEfU2RIqqEkkajQbt27QAAffr0we7du7Fo0SKMGzcOFosFZWVlblGlgoICodtvZmYmfv/9d7fzFRQUCLf5Q6vVQqut/zw5QRBEU8NotiPBUM9CqRZduf+64LBqjOja+LrOd23mEDrnSo2yjPeCUGoePUIpqofisiwLs9mMPn36QK1WY+PGjcJtR48eRV5eHgYMGAAAGDBgAA4ePOg2WmTDhg2Ij49Hly5d6nztBEEQhDueaa6G0CYg1NTb7twSsBzQNi0G2cn1F/mJFOlxWiQa1GA54LREs3q12Ybz5Y5qumgSSlETUXrqqadw3XXXoWXLlqisrMTy5cvxyy+/4Mcff0RCQgImT56MmTNnIjk5GfHx8XjkkUcwYMAA9O/fHwBwzTXXoEuXLrj77rvxyiuvID8/H8888wwefvhhihgRBEE0ADw1ibEBCKVQ2elMuw1ql1rPK4kMDMOgfXosdueW4uTFKnTMDN4hlDdyZ8RrkRQjrdK8IRA1QqmwsBATJkzAhQsXkJCQgB49euDHH3/E1VdfDQB48803oVAoMGbMGLeGkzxKpRJr1qzBgw8+iAEDBiAmJgYTJ07E3Llz6+shEQRBECI8ozcmKwuW5aBQ1F9VVCgRJZPVjn1nygAAQzukhXlFDYcOGXHYnVuKExIN3cedabdOmdHVWidqhNInn3wS8HadTod3330X7777rt99WrVqhbVr14Z7aQRBEEQY8JQkHOdIv9VndVQombf9Z8pgsbFIj9OGNOIjWujkfGwnnJGiYPD7dcpqQPNpJBDVHiWCIAii8eCr/3F9twkIxaHEp936t0nxOTetsdDZmW47XVwNmz34oFveyN0lyiJKjfcVJAiCIKIKX9GbanP9+pTkpt7sLIffc0sAAP1aJwdt8hjNZCcboFcrYbVzOFtaE3BfsZG7SzMSSgRBEAQhG9aHJjFa7D4jTXWF3Ls+cqEClSYbYrUqdG2WALWyYXedrg1qpQJt0mIAACcvBk6/8Wm39DhtgxhNIwcSSgRBEESDgPOR6OI4uA2HrWvkijQ+7XZZTjKUCqbeG2ZGEiXDoE2qQygFM3Tzabd26bFQNvCRJZ403leQIAiCiCpYP3qoPvspydFJHMcJY0v6t0kGwwCqeqzYizRKJYM2abEAXKX//uBHl7RLi4UyyqJsJJQIgiCIBoGviBLg6NBdX8iJJ50uNqKgwgyNUoFeLZOgVDANfuBrbVAyDNryQulidUA/Fx9RaksRJYIgCIIIDX/X2fqMKMkxc/PRpEuyE6FTKxt12g0AFAogO0kPtZKB0WJHQYXJ537VZhsuOI3c7dJioYiypyXKlksQBEE0VvxpEpudg9lWP1ElOak3V1uAZABo1EZuwBFRUikVaJXsNHT78SmJjdzxejVFlAiCIAhCLqyvkjcR9ZV+85cO9KSo0owTRdVQMMBlrVMAoNFHlJRO/xVf+eav8aTYyA0g6lomRNdqCYIgiEZJMDlSX+k3qRGlXc60W6fMeCToHZ3EVY08osQwDBQKuAzdF31HlAQjd3r0pd0AEkoEQRBEAyCYF6i+OnRLFUqeaTcAUEejKpCJUsGgbSqfegsSUUqLFaJQ0UTjfxUJgiCIBk8wQWK2spLGZIQbKWbuKpMNB8+VAwD6OdNuAKBuxONLeJQMg5zUGCgYoNRoRWm1xe32KpGRu21a9FW8ASSUCIIgiAaAFEFSXQ9RJSkBpT9Ol4DlgJbJBjRL1AvbG3MPJR6FgoFOrURz5+M+4dGh28vIHYXPCQklgiAIIiqoj8o3KZ25xUNwxWiizLQcCnyEiPcpeXboPuFMu7V3GrlJKBEEQRBECEjqV1QPI9+CLctiY7EnrxQA0L+1y5+kUDiiLY0dofLNj0/puKjRJAAoKPVGEARBEPIJ0h1A8j7hJphQ2nemFCYri5QYjVD+DjT+1gA8vFASOnR7RpREo0uA6KwEbBqvJEEQBNGgkZLiktMlO1wEu8/v9p8HAAxun+Y2rqSpCSW+l1J+hQnVZkcrB08jNwAycxMEQRBEKEiLKNW9UAp0j8cKKvHnuXIoFQxu6tnM7bamYOQGXKm0OJ0aaXFaAK5+Snw0KSPeYeQGojMdSUKJIAiCqH+kWJTqJfXm/05X7TsHABjaPk0QCTxNJaIkFoRt09x9SuL+STwUUSIIgiCIEJASLaoPoeQv0nW+rAY7TlwEAIzu1dzr9sY+541HHCFqk+ruU/rHw8gNAMoofF5IKBEEUe/Y68OlSzQopLwD6iP15m9l3+4/B5YD+rZKQo6z4ktMtM0zCxWlj4gSn3Lj/22fHufanyJKBEEQ8rHaWdTU04gKomEgRQTVi0fJx12WGS3YeKQQAHBL7xY+j2sKPZQAd+HD91I6U2pESbVFZOR2CUnqo0QQBBECHFd/Q0+JhoEUDVQfgUdf97nmzwuw2Fl0yIhFt2bxPo+LxjL4UBALn5QYDeJ1KrAcsOlvh5DMiNciTqf2uX+0QEKJIIh6h+U4oaSYaJpIaQ9QHx0nOY/7rLHY8cPBCwCAW3q1cGsJwMMwTcfMLRY+DMMIUaWf/soH4G7kBij1RhAEERIsx6GKhFKTRppHKeLL8L5Pjzm8G47ko8psQ1aCzmtkCU9TiSYB3hEivl8Sn3ZrJ/InMQy1ByAIgggJlnNckMin1HRpsB4lkYSz2Vl862wwObpXc79pJJWiaV1axQ9X7EcC4NatPBrHlwAklAiCaADwaReKKjVdJHmU2OD7hBvxurb+cxFFlWYk6tUY1inD7zFNpTUAj9JHiwCeaDdyAySUCIJoAPApFSMZupsskvoo1YdHieP/5fD13rMAgBt7NoNG5f/y2VT8STzippNZiTro1UoAQGa8LuqN3AAJJYIgGgAsRZSaPFIiSnWdeRMbzPfllSG32AidWoHru2UFPK4peZQA95SagmGEvlLiRpMACSWCIIiQ4YUS+ZSaLlKFkrTquPAgvquv9zmiSSO6ZCJWpwp4XFPpocTjKYB6ZSe6/SvsF6UepcCvNkEQRB0gviBVmW3Qa5T1txiiXpBq1OY4R/VUXcCv6XhBJf486xx+e0mzIEc1na7cPJ4m7Vv7tECfVklo7xlRitJIW9N6NQmCaJCIL5LUT6lpIjVOVJeVb/w9fe0cfjukfSrS43RBj1NFaYopVDxTjWqlAh0y4rx6TEVrRImEEkEQ9Y64Pw516G6aSBVAddlLieU42OysMPx21CXew2990eRSbxIFULR2TYjSZRME0ZhgRVc/8ik1TaQGiuo0osQBJhsriLPsZEPQYxSK6GyqWBukPt5o7S8VnasmCKJRQ9VvTY+6NGnLwWJzNG9SMNJSak2tNQAgPaJEqTeCIIgQ8YwSkE+p6dEQPUosx8Fsc0Q3tSqlz7lunjRJoSTRpB2lASUSSgRB1D+evpNqi63BRhiIyNAQPUoc54ooBWowKaapGbkBGRGlKH1uSCgRBFHveF4kWRYwWethXgVRbzRIjxIAs1MoaSUKpSYZUZIogEgoEQRBhIiv6BH5lJoWcvoo1RUsx8FsdaTepEaUmtqcN0D6sFvyKBEEQYSIr3QK+ZSaFlIFUF135jbb5UWUmlqzSYAiSgRBEBHHVzSBfEpNC+mpt8iuQwzHcTBbeaEkrVt8U+uhBDgEULBgEcNAkhm+IdL0XlGCIBocrA87EssCNVbqp9QUkCOI67qPksUu08zdBFNvQPD0WzQ/LySUCIKod/xd/KrNJJSaAnKiRHVu5rZKT70xTNM0cwPB02rR6k8CSCgRBNEA8HftI59S00BWirWuzdxCH6Xgl8tojprUlmD6MJq7lZNQIgiiXmEDhBPIp9Q0kBdRitw6PBH3UZLiUYrWER3hIFjqjSJKBEEQIRIolUI+paYBJyNMVLceJU5WH6Wm2BqAJ5hIjNaKN4CEEkEQ9UywCAH1U2r8yNE+9dVwUoqZu6n6k4Dg40lIKBEEQYRIsAufkQzdjR5ZFqU6Tr2RR0kaQc3cJJQIgiAiA/mUGj9yokR13plbiCgF9yg1xR5KPME8SCSU6oAFCxbg0ksvRVxcHNLT0zFq1CgcPXrUbR+TyYSHH34YKSkpiI2NxZgxY1BQUOC2T15eHkaOHAmDwYD09HQ89thjsNkotE8Q9UWwiyT5lBo/crRPXafeLDI8Sk2xKzdPY24PoArloOrqamzZsgV5eXmwWCxut02bNi0sC/Nky5YtePjhh3HppZfCZrPh6aefxjXXXIO//voLMTExAIAZM2bghx9+wMqVK5GQkICpU6filltuwbZt2wAAdrsdI0eORGZmJrZv344LFy5gwoQJUKvVmD9/fkTWTRBEYKRUMVWb7TBoQvq4IqIAOeKn7s3cztSbWoJQiuKoSW0JJpSiuT2A7E+effv24frrr4fRaER1dTWSk5Nx8eJFIUITKaG0fv16t9+XLl2K9PR07NmzB0OGDEF5eTk++eQTLF++HFdddRUAYMmSJejcuTN27tyJ/v3746effsJff/2Fn3/+GRkZGbjkkkvw4osv4oknnsDzzz8PjUbjdb9msxlms1n4vaKiIiKPjyCaKlIufFa7j9bdRKOBk/Hy1mUSVtweQEparSmn3oIJoWgWkbJf1RkzZuDGG29EaWkp9Ho9du7cidOnT6NPnz547bXXIrFGn5SXlwMAkpOTAQB79uyB1WrF8OHDhX06deqEli1bYseOHQCAHTt2oHv37sjIyBD2GTFiBCoqKnD48GGf97NgwQIkJCQIP9nZ2ZF6SATRJJFykazLKAJR98hpD1DnQ3H51Js6sEdJoYjuqEltIY+SiP379+P//u//oFAooFQqYTabkZ2djVdeeQVPP/10JNboBcuyePTRR3H55ZejW7duAID8/HxoNBokJia67ZuRkYH8/HxhH7FI4m/nb/PFU089hfLycuHnzJkzYX40BNG0kSKCfM2CIxoPDbXhpNjMrQ0SLWrKrQEACam3puRRUqvVUDgbJqSnpyMvLw+dO3dGQkJCnYmIhx9+GIcOHcLWrVsjfl9arRZarTbi90MQTRVJQokiSo2aBjsUFyIzdxCPEgmlxhtRki2UevXqhd27d6N9+/YYOnQo5syZg4sXL+Lzzz8XojuRZOrUqVizZg1+/fVXtGjRQtiemZkJi8WCsrIyt6hSQUEBMjMzhX1+//13t/PxVXH8PgRB1C1SIgR2EkqNGjlRorrtoySe9RY49RbNHpxwECj1xjDRLZRkS+D58+cjKysLAPDSSy8hKSkJDz74IIqKivDhhx+GfYE8HMdh6tSp+Oabb7Bp0ya0bt3a7fY+ffpArVZj48aNwrajR48iLy8PAwYMAAAMGDAABw8eRGFhobDPhg0bEB8fjy5dukRs7QRB+EdKNCHQPDgi+mmoI0xYTnpnbimduxszCgUDf1opmtNuQAgRpb59+wr/T09P96pGixQPP/wwli9fjtWrVyMuLk7wFCUkJECv1yMhIQGTJ0/GzJkzkZycjPj4eDzyyCMYMGAA+vfvDwC45ppr0KVLF9x999145ZVXkJ+fj2eeeQYPP/wwpdcIop6QooFIJzVuGmpnbkD6rLemHlECHILIV/Q3mqNJQIh9lOqD9957DwBwxRVXuG1fsmQJJk2aBAB48803oVAoMGbMGJjNZowYMQKLFy8W9lUqlVizZg0efPBBDBgwADExMZg4cSLmzp1bVw+DIAgPpEQI7KSUGjUNVSjZWc7VHiCYUGriHiXAMcLF199qtD81koRS7969sXHjRiQlJaFXr15gAoTR9u7dG7bFiZESntfpdHj33Xfx7rvv+t2nVatWWLt2bTiXRhBELSAzNyH39WVZrk5K8floEhA8otSUeyjx+EuxKYNNzG3gSBJKN998s5CaGjVqVCTXQxBEE0PKNZLjHF+WAn1JI6IXuTKY5TgoEPn3gkk0OieombsJD8Tl8Zdii+bxJYBEofTcc8/5/D9BEERtkRpNYDmArkWNE7lm/brKxJosjoiSSsEE9NkwDLUHAPwLoigPKEXPUFyCIBonUi965FMieOoqFWsSWgME8yeRggcApZ/noUmYuZOSkiSHvEtKSmq1IIIgmhbBLnoHzpRh4cbjmDeqK67tllVHqyLqkobqQeNTb8F7KFHMAfAfUWoSQmnhwoXC/4uLizFv3jyMGDFC6E+0Y8cO/Pjjj3j22WcjskiCIBovwQo11h66gItVZmz6u5CEUiNFrk6qK2FltkrsoURpNwD+U2xNwqM0ceJE4f9jxozB3LlzMXXqVGHbtGnT8M477+Dnn3/GjBkzwr9KgiAaLYGueXaWw4GzZQCAarPd/45EVCO76q0OdBLHSe+h1NSbTfI01oiS7Ff3xx9/xLXXXuu1/dprr8XPP/8clkURBNF0CHTRO15YKQikaoutjlZE1DWhVL1FGk5GV25dkDlwTQW/VW9NTSilpKRg9erVXttXr16NlJSUsCyKIIimQ6CL3r68MuH/RoooNVrkDMV17B+hhYhg3ea8Bb5UBvMwNRUaq1CS3Zn7hRdewH333YdffvkF/fr1AwDs2rUL69evx0cffRT2BRIE0bgJKJTOlAn/p4hS40VuKk2usAoFDq6IklYdWAgFE1JNBX+CqMnNeps0aRI6d+6Mt956C6tWrQIAdO7cGVu3bhWEE0EQhFT8XfOqzTYcza8QfjeSUGq0yDdzR2Yd7vchGl8SwKytVjF10iU8GvDfmTu6n5+QZr3169cPy5YtC/daCIJoYnAc5/ci+ee5ckeTSYVjfhSZuRsv8s3cdeVRcqbeAniQdJR2E/AniKJ9YHBI8cITJ07gmWeewZ133onCwkIAwLp163D48OGwLo4giMZNoMjAvrxSAED35gkAgBoLCaXGilzdU1dtl/iIkjZARCmQiGpq+BJEDIOoHz0k+xXesmULunfvjl27duHrr79GVVUVAODAgQM03oQgCFkEigzsd/qTBrZ1FIkYLfY68aYQdY/cCFFdvA9YcXuAAB4lMnK7YBgGnpoo2tNuQAhC6cknn8S8efOwYcMGaDQaYftVV12FnTt3hnVxBEE0bvxdIC+U1+BCuQlKBYPLcpIBAHbRhYto2tRNHyVI6qNERm53PIVRkxRKBw8exOjRo722p6en4+LFi2FZFEEQTQN/gQE+mtQpMw6JBtcXsmozGbobG4F8av6oC4+SOKIUqI+SLkhFXFODhBKAxMREXLhwwWv7vn370Lx587AsiiCIpoG/Cx7fP6lXyyQoFYzwrd1IPqVGRyiapy4SsI72AIH7KKmUTKMQAuHEs/It2seXACEIpdtvvx1PPPEE8vPzwTAMWJbFtm3bMGvWLEyYMCESayQIopHiK4UiHlvSKzsRAKB3fmuvoohSoyOU6BBbB7k3jnOZuTV+fEiUdvPG09DdGISk7Fd5/vz56NSpE7Kzs1FVVYUuXbpgyJAhGDhwIJ555plIrJEgiEaKr4vksYJKGC12xGlVaJsWCwDQaxwXKuql1PgIRfLUhadfyqy3YI0omyKNMfUmu4+SRqPBRx99hGeffRaHDh1CVVUVevXqhfbt20difQRBNGI4H97svc62AD2zE4UPWV4oVVEvpUZHSBGluuqjZA2ceqOIkjeezTebpFDiadmyJVq2bBnOtRAE0cTgfMQTXP6kRGFbjMbxUUVm7sZHQ/YoWeyBI0pk5PbG05MU7eNLgBCEEsdx+Oqrr7B582YUFhaCZd2/EvJjTQiCIILhaTWpMtlwvLASAHCJ058EADFaEkqNlVCEUp1VvVl5oUQeJalQ6g3Ao48+ig8++ABXXnklMjIyor7jJkEQ9YfnBe/A2TKwHNAiSY/0OJ2wPVbruFBVmqx1uj4i8viKKgY9po5Sb3xEyVd7AIUCUAfo2N1UIaEE4PPPP8eqVatw/fXXR2I9BEE0ITyF0j5n/6ReomgSAMRq1QDIo9QYCaWArW4aToojSt6CiDpy+8Yz9dYYhJJsOZyQkIA2bdpEYi0EQTQxxDqJ4zhhvlvvlknCdoYB4nSO73TUHqDxEUp0qE6q3iDuo+Qtiijt5huFx9PSJPsoPf/883jhhRdQU1MTifUQBNGEEEeULpSbUFhphkrBoJtzEC7g+EYa40y9kUep8RFaRKmOqt4CdOYmI7dvVB5KqTFElGSn3saOHYv//e9/SE9PR05ODtRqtdvte/fuDdviCIJo3Igvknw0qUtWvNtFSK1kEKuliFKjpYEKJYvdDpvzDeoz9aamiJIvvCJKTVEoTZw4EXv27MFdd91FZm6CIGqFuMMy70+6RNQWAACUCoUglGiESeMjFNFTF6k3k9VV0e0rokSpN980Ro+SbKH0ww8/4Mcff8SgQYMisR6CIOqRGosdCkXdGVX5C57NzuLPs+UAgF7ZSW77qBQMYnWOyDWl3hofDbUzt0kkyj2FEsOQmdsfYmHkGV2KVmQLpezsbMTHx0diLQRB1DO5xdWw2TkwDKBTK6BVKaFVK6BTK6FTKQNOUQ8FPppwtKASNVY74nUqtEmLcdtHpWSE9gAklBofoabRWJbz6gIdTkxOI7dGpfBqmkjRJP8wDAOGcYhZT79StCL7Ubz++ut4/PHHkZubG4HlEARRX5htdtjsjosWxwE1FhZlRisKys04fdGIo/mVOFdWE9YeNvxFku/GfUl2ktdFSaVQwMB35qbUW6MjZKEU4bASn3rT+uiVREbuwKiUjr/hxtJmSnZE6a677oLRaETbtm1hMBi8zNwlJSVhWxxBEHVHtdkOO8sF9BSUVFlgtbFomWwIy7d53qK074zDyN3Lw58EOFJvfGfuGhJKjY8Q9U6keynx7zVfpm2KKAVGyTCwgmsU40uAEITSwoULI7AMgiDqm0U/H8P/dp/B+MtaYlSv5n4/5CpNNpy8WIVWKTG17kzMcZxjbElBFQDvRpOA49up0B7AQqm3xkaogieUjt5yEFJvPt7j5E8KDP8lqjEYuYEQq94IgmhccByHHw5egMXGYsn2XOw/U4YZwzsgKUbjc/8aC4sTRVXISYmpVRqC5YDCShM4AIkGNVJitV77qBQKYSguRZQaH6EKnkgbuk1WPqLko9kktQYICF/51liEEr3aBEHgRFEVLlZZoGAc5tV9Z8ow7Yt92HO61O8xVhuHE0VVtZq/xnKc4DvixZAnjoiS4zazjYXNzvrcj4hOQo0o1ZlHyWfFG106A6FsZBElerUJgsD2f4oBAO3T4/Dm2EuQk2JAWY0Vz39/GJ9sPQWrH3HCssDpYiNKqi0h3S/LcTA602l8es0TlagzNwAYrRRVakzwxQFWO4u5aw5j1d6zko6LtEfJLKp6E6NRKah/YBAEodRInicSSgRB4PdcRxFGt+bxaJlswOu3XYIbumcBAL7dfw6Pf/Unzpf5HlvEccC50hpcrDLLvl+Oc5jIAQiVbWKUCgYMw0CjVAgfvtQioHHBB4b+vlCB3bmlWLo9F6cuVkk4LrJKqYZPvXkIJYomBYciSgRBNDr48nx+GK1GpcADQ9ti9vWdEadV4Z+iKkxfsQ9b/7no9xxGs/xID8dBiCgZNN4RJb7MmGEY4fbqEO6HqDvkpkZ5vcOnYDkAS7fnBj0u4hElKz/nzf19SUbu4CjIo0QQRGPiTIkR58pqwAC4rnsWYnWuyE7/Nil4645e6NYsHiYri4U/H/ObhrPL/IbPjy8J5FFSiT5oXUKJIkoNGatd5vvA+b4Rj6fZm1cmzP7zR6QjSnzqzTOCpCMjd1B4gRTJhqB1ieyqNwD4448/8OWXXyIvLw8Wi7s3YdWqVWFZGEEQdcM2Z5SoTVoMkmM0iNc5IkhWm+NClBqrxbxR3XHHRztRY7XjQrkJLZMNXuexy/yKz18gawJFlESdfR2pOTO1CGjgWFkWekiPuvDvmhoP79nS7bnomZ3ot01F5Pso+TZzU0QpOE3eo/TFF19g4MCBOHLkCL755htYrVYcPnwYmzZtQkJCQiTWSBBEBNnt9Cf1cqbdVEoFWiYbIP6MUyoYtEjSAwDOlhp9nkduFRJ/oeNTaXxlmxg+9QaAUm9RgtUmL/Xmiig5BPBlOckwaJQ4ebEaW44V+T0u4hElO3mUQqXJe5Tmz5+PN998E99//z00Gg0WLVqEv//+G2PHjkXLli0jsUaCICII70/q1zpZ2GbQqJCVoHPbr7kglHybukONKAX0KIk+aHkhVW0OvR0BEXlsMt8HvN7he2RlJuhwa58WAIDPd56GxY/wqiuPkjiCpFYxjSadFEmafB+lEydOYOTIkQAAjUaD6upqMAyDGTNm4MMPPwz7AgmCiBwFFSaculgNALi8XarbbSmxWiQaXCOKWiQ50m3nwiSUPE28Pj1Koq7IMU4hVWmi1FtDxp+w8Qfn4VHSa5S4qWczpMZqUFRpxpo/zwc8LlK4zNyu9yCl3aTBZ8ybbOotKSkJlZWVAIDmzZvj0KFDAICysjIYjb5D8gRBNEy2n7gIDkCLJD2aJeq9bm+eqBfMqy2ct58t8/13znHyLl5CRMlpztYHqHoDXBGlKkq9NWhkR5Sc/wqRRbUSWpUS4/u1AgB8+ccZVNR4RxEjGVHiOA5mm7dHiYzc0lApFGCYxmPmlv2qDxkyBBs2bAAA3HbbbZg+fTqmTJmCO+64A8OGDQv7AgmCiBy/n3JUFl3iY8Ya4Piga5ligEIBkUepxq8gkhNV4oWSEFHy5VESp940vFCi1FtDxl9VpD88q954wXxlx3TkpBhQbbFj5Z4zXsdFctYbx4mr3lwCniJK0lAqmEaTdgNCEErvvPMObr/9dgDA7NmzMXPmTBQUFGDMmDH45JNPwr5AgiAiB1+CfWlOkt99tColspMNaJaoh4JxXNBKjb7FipwWAbym4i+Qware+LYFZOZu2MgWSs7dayzujUeVCgb3DGwNAFjz5wXkV5jcj4tgRInlOCGF6J56o4iSVGo7MLshIbs9QHKyy/CpUCjw5JNPhnVBBEHUDSXVZhwvdHRA9vQneRKvU6N5kh4Z8TpcKDfhbKkRyT4G5rIyrpGch5lbah+lKuqj1KBhWUdkUWpEgY8M8aNpxIK5V8tEXJKdiP1nyvDfnacx65qOovuJYEQJ8Jl6I6Ekncb0XMl+JHv37sXBgweF31evXo1Ro0bh6aef9uqpRBBEw2XXyRLYWQ5psVq0TYsNun96nNYt/eYLuRElluNckQSPWW+eHoc4Z0TJSEKpwcKnXuWkYD2r3sRCiWEYTBqYAwDYcqwI/xRWeR0XCViO82o4qVQwbsUFRGAaU0RJ9iN54IEHcOzYMQDAyZMnMW7cOBgMBqxcuRKPP/542BdIEERk2HXS0T+pZ3aCpCGfDMMIjSb99VKS61GqsdgFp4lnRMnzgzZWMHOTUGqo8K+/nJ5anJCC9d0mom1aLK7omAYAWLLtlBCJjLRHyeIRUSIjtzw8hwlHM7IfybFjx3DJJZcAAFauXImhQ4di+fLlWLp0Kb7++utwr8+NX3/9FTfeeCOaNWsGhmHw7bffut3OcRzmzJmDrKws6PV6DB8+HMePH3fbp6SkBOPHj0d8fDwSExMxefJkVFUFH8BIEI2NfWcc/qS+AfxJnriEUu1bBLAcJ3TZVikYqJXuYk3l8XusztGqQDzqgmhY8AJJqlASFwW4zNzeKdi7+7WCSsHgz3Pl2HemzHkftVxsEITUm1rp9i8hDc+/52hGtlDiOA6s04jw888/4/rrrwcAZGdn4+JF/wMzw0F1dTV69uyJd9991+ftr7zyCt566y28//772LVrF2JiYjBixAiYTC4T4Pjx43H48GFs2LABa9aswa+//or7778/ousmiIZGRY0VRy442nwMbBvYnySmVUoMAOBcWe2FEse5BukaNEqvqJbKw+MS60zN0QiThgsvkKS+D/jd7KyrHN/gQ5Ckx+swtIMjqnToXLnbfUUCNzO3M7LZmDw3dUFjiijJNnP37dsX8+bNw/Dhw7Flyxa89957AIBTp04hIyMj7AsUc9111+G6667zeRvHcVi4cCGeeeYZ3HzzzQCA//znP8jIyMC3336L22+/HUeOHMH69euxe/du9O3bFwDw9ttv4/rrr8drr72GZs2aRXT9BNFQ+CO3BBY7i3idCl2z4iUf1zrVEVEqrDTDZLVD53FRk5ty4Q28vseXuH/Q8tVQRqp6a7AIqTeJpn7XvD/Xa+qrnxbgaIAKuCJPkWw46WgPwEeUSCiFgqYpe5QWLlyIvXv3YurUqZg9ezbatWsHAPjqq68wcODAsC9QKqdOnUJ+fj6GDx8ubEtISEC/fv2wY8cOAMCOHTuQmJgoiCQAGD58OBQKBXbt2uXzvGazGRUVFW4/BBHt7Dzl8Cf1aJEIpYwPtNQ4nWCqPu8jqiQ39cYbs4ONLwFcHiWjlYRSQ4UXSFJN/Z7+JLWS8WsC5juz8xHFSKbe7CwrmLn5C77nlwIiMFJ8j9GC7IhSjx493KreeF599VUolfX3RsrPzwcAr6hWRkaGcFt+fj7S09PdblepVEhOThb28WTBggV44YUXIrBigqg/+P5JfVpJ9ycBDvHSIsmAIxcqcLa0Bm08quXke5QCjC/xEEq8mKKqt4aLXI+SEFGyuvdQ8gUfdeQjipGserPaOUGIadVKMEzjquIi5BHyK2+xWHD27Fnk5eUhLy8PhYWFuHDhQjjX1iB46qmnUF5eLvycOePdIZYgoolqsw2HzzsiowPapsg6VqlgRC0CvCvfZKfe+EonbeBmk4ArolRjtUd8zhcRGnwkSW6Po0BNR3kMXhGlyL0HxFFLrcoxjoNousiOKB07dgyTJ0/G9u3b3bZzHAeGYWC3109YPDMzEwBQUFCArKwsYXtBQYFQpZeZmYnCwkK342w2G0pKSoTjPdFqtdBqtZFZNEHUA/vPlMJosUOvVqKXn9El/lApGNHMt9qn3vgu2wa1L4+SR0TJKZRYDjBZWb9eFqL+4AWS1NSbv/ElvuCjjtXmyAslk3M9CsbxnvcU7UTTQrZQuueee6BSqbBmzRpkZWU1mDxk69atkZmZiY0bNwrCqKKiArt27cKDDz4IABgwYADKysqwZ88e9OnTBwCwadMmsCyLfv361dfSCaJO2ensn9S1ebzskmeVUoEWSf5bBMi5eLFBIkqenZ3F1VDVFhsJpQaIXWbVm1cPpQDvRyH1Zol86o03l2tVjmpMyro1bWQLpf3792PPnj3o1KlTJNYTkKqqKvzzzz/C76dOncL+/fuRnJyMli1b4tFHH8W8efPQvn17tG7dGs8++yyaNWuGUaNGAQA6d+6Ma6+9FlOmTMH7778Pq9WKqVOn4vbbb6eKN6LJsPe005/UUp4/CeA9So6I0rnSGrAcB4Xoy5KcMV8sxwkXPV8eJU9PiELBQK9WosZqR7XZhtRYivQ2NHh9JLfqzWgJ7lEyeLSHiKhQcqbe+BJ3RQMJCBD1g2yh1KVLl4j3S/LHH3/8gSuvvFL4febMmQCAiRMnYunSpXj88cdRXV2N+++/H2VlZRg0aBDWr18PnU4nHLNs2TJMnToVw4YNg0KhwJgxY/DWW2/V+WMhiPqgxmLDIac/qV8bef4kwBHlyYjXQaVgYLGzKKo0IyPe9fclr4+Sq+GkpzeFYbwjSvx+DqFElW8NEVZmZ25+rxoZqbcai10Q6CzLuY25CRe8UBKPLyGaLrKF0ssvv4zHH38c8+fPR/fu3aFWq91uj4+X3pNFLldccUVAEyfDMJg7dy7mzp3rd5/k5GQsX748EssjiAbP3/mVKK+xQqNUoK/MijfAEVFSKhhkJepxpsSIc6U1bkJJdurN7LuPkqc/iUevUQLV1HSyoWKX6VHinJEnf+NLxPC3OTxqdhg0KodgQvhFjMlDKFFEqWkjWyjxfYqGDRvmtr2+zdwEEW4sNrZRdZcFgN25Dn9Sx8w4xOvVQfb2xuHXcBi6z5QYcbbMiN4iwcVxkPwtnw0QUfJsDcDjaeglGhZyq974eW2u9gD+hZJWpYBKwcDGOooADBpVxKa9mTxSbxRRatrIFkqbN2+OxDoIosFhsTc+obQvrwwA0KtlYsjnUCnFLQK8Dd02loNGilBi/XtT/FUZ8RdSGozbMOEj/tKr3hz/BprzxsMwDAwaJSpMNmcEShuxyrcaKz8Q1/F+I6HUtJEtlIYOHRqJdRBEg4LjOFhtLNDI/MJ7nY0mL2udHPI5lM6mk0DtKt8c7QEcgifGI5Lg78LEp+iqTCSUGiK8mV961ZuHmTtIFWaMVoUKk01oVBopQzffHoDM3AQQYsPJ3377DXfddRcGDhyIc+fOAQA+//xzbN26NayLI4j64lxpDfadKa3vZYSVs6VGFFSYoVQw6N8mdKGkCtJ0Uk5pOG/iNXh4lPx1QeYjSpVmq+T1EnUH/9pLFTCeEaVAqTeg7nop1djcPUr+UsFE00C2UPr6668xYsQI6PV67N27F2azGQBQXl6O+fPnh32BBFEfPLR8L+5d+gdyL1aHdLxVTp28B3Iqx+TAp93apMYgJSb0UJmjl5JDKJUarV5pMClpF5bl3KrepEaU+O7cVPXWMOGFC+9VC4bgUZJg5gZELQLMkW0RYPJIvUWiso6IHmQLpXnz5uH999/HRx995Fbxdvnll2Pv3r1hXRxB1Be5xQ6BdLrEO2IiBYstdKFUZbahqNIc8vH+4M/ZPElfq0axKgUDg0aFZIMGgCP6JkbaBdIxnZ3f1dOjpPZT9cZfKCn11vDgOM5NuEgRzJwMjxLgiijx+0cqouRZ9UYepaaNbKF09OhRDBkyxGt7QkICysrKwrEmgqhX7CyHyhrHhbjMaAnpHOZaCCU7yyG/3ITymvCml8qc5+MFTqjwFw1/6TcpETGxP0nBADq1+0eRvwtTnNbx5YzaAzQ8PF93qe8DwDVbLWhESeMeUYpQ8BVmT6FEHqUmjWyhlJmZ6dYdm2fr1q1o06ZNWBZFEPVJpckqlB2HIlasdhYHzpSFlEKz2Vl8uvUU/r5QgTMlRsHDEw540ZcaVzuHutpZkdac79DtMfNNUupN1JXboFF5Rbj8epSE1Aul3hoanq+7lGAPv4+UhpOAy8zvMnNHtupNMHM3ruJXQiayX/4pU6Zg+vTp2LVrFxiGwfnz57Fs2TLMmjVLmKlGENFMmdHq8/9S+fDXk7hn6W6s2H1G9rHbTxTjnc3/4KlvDmJPbilyi6tr5XcSwz+WtFqO/lAq+YiS78o3KeMrOA5+eygBgSJK1EepoeKpWaQKZo7jJM16A1xeNmOEx5hQRIkQI7s9wJNPPgmWZTFs2DAYjUYMGTIEWq0Ws2bNwiOPPBKJNRJEnVJWUzuhdKygEgBwoqhK9rGFTh+RjeXw0tojmHNDF6iVDNqkxtbaUFrqjCglx9Qu9aYKlnqTHVHyvjj6qzISzNyUemtwhJJ647jAXjVPDB5m/oh5lPiqNzX1USJCiCgxDIPZs2ejpKQEhw4dws6dO1FUVIQXX3wxEusjiDpH7EsKxaNUWm1xHitfZPH3p2AcDS/n/vAXfj9ZgjM+yvBlr8u5nkSD/I7cYjw9ShfKTbCJol5SzNws5zLkeo4vUSoYv2bzWJ1j7cYwpiSJ8OApkCWZ+kUtIhh4e9U84SNKvFCOnEfJmXpTKsAwqFXxAxH9hJx51Wg0iIuLQ1ZWFmJjY8O5JoKoV8S+pLIQPEq8QArF31ThPGZY5wz0bZUEi43FC2v+wo4TxcgvN8k+n/u6HCIssZZmbj7akxqrhValgI3lUFDhqtKzyTRze0aU/FW8AUAMeZQaLJ7CSFLVG9wji8EECS+qjUJ7gEhHlBQUTSLkCyWbzYZnn30WCQkJyMnJQU5ODhISEvDMM8/AaqUmcET04+5RCiGiZOQjSvKP5cVVaqwGT13XGb2yE2G2sXjh+7/w67EilFSHVoUnPndtI0r8vDcFw6B5ojP9VuaKeElKubAun0mMxjui5A/+QllDqbcGh+fLLiUt5ogsOl7LYEZuQNRwUmgPIHOREhFHlKjZJCFbKD3yyCP48MMP8corr2Dfvn3Yt28fXnnlFXzyySeYNm1aJNZIEHWKWCiVhpI+qwk9osQfm5MSg6QYNWaP7IyeLRJQY7Xjue8OY/PfhcKFRQ42O4tKZ++hpFpGlADHvDcAPme+SbtAcsLFTmpXbsD7Qkk0HDwFsjRTPye0BgjWQwlwRR8FM3eExuLy7T20aiU1myTkm7mXL1+OL774Atddd52wrUePHsjOzsYdd9yB9957L6wLJIi6pqzGFbWRK3bEgiQUocQfkxSjQevUGGhUCjwzsgte+P4wDp2vwJzVh5AWp8WQDmkhnRcA4nWy/+y9cPmU+Mo3eRElluOE9IlnpVPgiJJjX37aPNFw8BTI0kz9ojE2QSreAFF7AHNkI0rihpNU8UbIjihptVrk5OR4bW/dujU0mtp/UyWI+qZcFEUqr7HK8kGIPU0hRZSc952gV4NhHMNnW6UaMOeGruiSFY9qix1Tl+/FGZkdw/nIWJxOBVWAiI1U+F5KviJK0oQSRBEl9wukKpBHyRl1sNhYNwM5Uf94R5Sk/N0Ern70REi9Wu2ws5zE+5CP2c6PMCGPEhGCUJo6dSpefPFFYcYbAJjNZrz00kuYOnVqWBdHEPWBWOzYWc5rllnAY0W+JLONFb6ZSkXwEeldPqL0OB06Zsbh+Zu6oHVqDCpMNqw/lC/zvBav89YGpY/UGy8oOS64yZbjOCGS4OlRUgfo7ieukKP0W8PCK6IkUTBLnfPmuU+NxV4HfZQo9UaEkHrbt28fNm7ciBYtWqBnz54AgAMHDsBisWDYsGG45ZZbhH1XrVoVvpUSRB3hacIuM1oRp5MmMDxbApTXWKGTkFIQ7w8ACR6G6wSDGt2aJ6Bni0SculiNi9XyZsGVVvNG7vBEfXmDa1aCHgwc8+kqTDYkOIWYneUCRobYAA0nlQGO06gUUCsZWO2OqrmEMAk/ovZ4epKkeNU4UZuIYD2UAId/TaNUwGJnUWWxRd6jRKk3AiEIpcTERIwZM8ZtW3Z2dtgWRBD1jafYKTNakZ0s7VhP83d5jRUZ8TpJx3Ic5xJKPgSAQaNC61SHJ6ikSl71mzDnrZbNJnn4dIROrURanBaFlWacLTUiQZ8AwOFPCfTh4vAo+e6jFCiiBAB6tRJWuy0kUzsRObz6KMlsPCql6g1w+NQsRhZGsy1iHiV+qLVGpaDxJYR8obRkyZJIrIMgGgy8qFApGNhYzs3cHYxSH9EoqVRb7EK6IlHvW9CkO0WX5/0Ew9VDKTwRGLGYaZFkcAqlGnRt5hBKwSqeHFVvfiJKQVIdBo0KFSYbqqiXUoPCuzN38GM4TvpAXB6DRoVSoxXVFntEOnNzHOcWUVKRUmry0DuAIESIozq8/0aO2PFM28kxdPPHqpWM3w7FfESoWGY/Jf4xhKM1AOCeHvM1yiRYxVOglEughpOO/Z0l4jTvrUHh6UuTXP3I91GSmKLmKx+NFltEGk6KfYUaSr0RCEEoFRcX4+GHH0aXLl2QmpqK5ORktx+CiGaqzDbhAz4nNQaAvO7cvlJvUnEZuTV+OxSnOIWS3NQbH4EKl6dH3IQvlMo3cWfuGFEkQaEIPi6Cr5Lj2zAQDYNQUm+AqD2ABI+SeL9qsy0iZm5xkYDDzB3++yCiC9mpt7vvvhv//PMPJk+ejIyMDJqBQzQq+MiLVqVApjPNVS4jzeVtBJd+bCB/Ek9SrSNKERBKiT6aTgYRSiYrK4w6ETecDNRskoe/UFaaaRJAQ8JTHPPVj/6uERzHuc16k5p6E/dSioRHiY9UqhSODvTUHoCQLZR+++03bN26Vah4I4jGhFis8JVnclJvfHWZUsHAznLC7DZJ9230XfEmho8oVZltMNvs0KqkXVzCNeeNR+kWUXIYzAsqTLDYWGic898CUSUSOeKUi5SLUqxTKMlp20BEHl/RnUDVj/z+cvooAa4IpNFii4hHySTyJwGAgoIBTR7ZQcVOnTqhpqYm+I4EEYWIvTy8oVrOGBPe+J3N+5tCSr35F0rxOrUgJuQIuJIwm7n5eW/8OWM0SnAALpQ7PhuCXcD4tJlerXQTR8Eq3gBX6o0G4zYcWJbzLZQCvA/494icWW+AKPUWITM3vx7+SwhFlAjZQmnx4sWYPXs2tmzZguLiYlRUVLj9EEQ0UyoSFLyoKJdT9eaMKLVKiXEeK0dkBU+9KRSMkD4rluFT4qNV4YooAa4O2nwHccCVfgvmUapyCqUYrfQeSjx86qWKPEoNBn+CKFD1I3+Eq+pNWoIjRhDKkfEo8alAjTOiRGZuIqQ+ShUVFbjqqqvctvO5aLudvuUR0QsvVhINaiGyIyv15hRaOSkGbJF5LC+q4oMYrlNitLhYZUGJDJ9SaU14PUqA+zft5kl6HC2oFCrfggolMx9F8OyhJEEoOSMPlHprOPh7vQNFfFwRJbmpN1dEKRJCyWR1pd4YBtSZm5AvlMaPHw+1Wo3ly5eTmZtodPDG7US9RrZHieM4QWi5Kubkm7mDpceSYpwRJYnduc02u/At2V9/plBwpMkc5xUM3WXSUm9VPireAGlpDr5LOjWcbDj4e70Dpd44ziGw+OaOstsDON9DLMuFVcwIqTe1gvxJBIAQhNKhQ4ewb98+dOzYMRLrIYh6pczoEit8zyGpYqfGahc+9HOcqTdZESVj8NQb4IgoAZAcUeLPq2AcQ3HDhThNlhrnviapESXPdIuUgb28R4kiSg0Hfy93oOpHccUbEIpHyfH6hzuoxEeUNEpFwDE8RNNBtkepb9++OHPmTCTWQhD1Tplo1prLo2SV1NiON32rlAyaOSMssqreJEaU+KaTpRKFUpkopRfOb97iFgHJBvc1BYsoCT2UPDxKKikRJadHyUhDcRsM/oRxIMEsbjapUSoktYYA3NsD8OcJJ66IkpIiSgSAECJKjzzyCKZPn47HHnsM3bt3h1rt/qHeo0ePsC2OIOoaIaKkd1W9We2OeVSeM8m8j+XTdi6RVVFjC9hLxtfxwSJKcrtz8+IlXF25ecSihu/v5Ioo+T+O4zjhIucdUZLQHkDrajhINAz8RY4Cpt4g358EuLcHAMIvlPj2ABqlgireCAAhCKVx48YBAO69915hG8MwZOYmGgV8hVuiQQ2dWgGNSgGLjUWp0SJBKLkqy3ixY+c4VJltgq8m4PESqt4AICXWXZRIPW+gtgOhIJ6BxYu3aosdZps94AWG5VwXOU+PkpS5Wi6PEn3WNBT8CaJAGoblOKHiTWraDXA1KOU7aIfb0M2nA7VqGl9COJAtlE6dOhWJdRBEg8AVUVKDYRgk6NUoqjSjzGhFi6TAx/IVb0kGNXRqJTRKBSx2FuU1VklCqUIQSoEjP3xkSGpEiY9U8VGfcCH2KMVoXI+3tNoKXQBjrmMgrnckgWGkmbn5Y6pJKDUY/Jq5g3iUjH4GIweCF9cWGwurnQ1/RMkp3mh8CcEjWyi1atUqEusgiAZBmUd37ESnUJLSD6nUY/BsgkG6yLKzHCqcfYGCm7llRpSMkYoouUQNwzBIilGjoMKM4mozMhN0fquRWI4TKpbEqTepxlk+sldDVW8NBn/9kgILJU72nDfPfY0RaBHgEkqUeiMchFQCc+LECSxcuBBHjhwBAHTp0gXTp09H27Ztw7o4gqgNJqs9YGTDE0d5v/uoD6HyTUL1WpmHF4iPRkkxdFeaXPsE9SjFyjNzl0ag2STgbbxOjtGioMIs3J+d46CA94XGEUlwXIzEZm4paTfHMWTmbmj4bTgZpD0A/xpKbQ0AOKKOerUSNVY7qs3hH2NSIxZKlHojEELV248//oguXbrg999/R48ePdCjRw/s2rULXbt2xYYNGyKxRoIIiZJqS9DhrGJqrHZY7Y79+egLb8qW0iJAECQxrmiU41gJIst5rEGjFDoC+0OoejNKe3xi31U48fy2new8f7AWAY5qJ+9IgpSKN8AlrmosdknViETk8Wvmllj1Jif1Jt7faAn/YFyhPQBFlAgnsiNKTz75JGbMmIF///vfXtufeOIJXH311WFbHEHUhvIaK1JjtdBI/LDjxYpayQgfxIkymk7yYoqPKInbC0hZK+CY5RYM/vws5xBhyUG8R/xYlXB25QZc8974i6F35Zs/oeTqgSM2c0tOvTnFFQeHuJWTtiEig7+oTiARw8FlnJZj5gYchu7iaotzjEmkPEoklAgHsiNKR44cweTJk72233vvvfjrr7/CsiiCqC1Giw02OwdboGFTHpSJGj7y5fx8ukqK2PH0AvGmbDlCSUrUR61UIN7ZOLJEQnduXsAlhDn1BriLG8/+Tv4roTgY+fYAWnFESdrHkV6tFBJ6NBi3YRDqCBNfkUUpxAqG/vDPe3M3c5NQIkIQSmlpadi/f7/X9v379yM9PT0cayKIWsMLDz6VJgXBnySqOuP9QlL8QK6Bui6PEiA1GiWtNQBPSqyjE7aUwbguk3l4I0qA76aTJc7nwV86RhxRMoQQUVIoGMF7Rr2UGgahVL2BEw/ElR9RAgCj2R65PkrkUSKcyI5ZT5kyBffffz9OnjyJgQMHAgC2bduGl19+GTNnzgz7AgkiFPhGj7ZAnQ89KDd6R3VcHiUJVW/VrvYAgEv0hDuiBDiiN6cuVkuqfBPaA0QioiSa9yY19Wax2WF2XoxC8SgBjjEmNVa7ILiI+sXfn1lgj1JoDScB0WBkiy0CHiVKvRHuyBZKzz77LOLi4vD666/jqaeeAgA0a9YMzz//PKZNmxb2BRKEXExWO0qqLJj11QF0yozDJ5MulXRcmQ+xwkeXyqVEhfjITYynRym4mKmQGVHi01x89EbKuqSeWw7iXkopElNvVaJ0mbtHSXqA26BWohiUemso+IvqBAr2cOCEFg/yzdx8RCn8HiWz08ytVdFQXMKBbKHEMAxmzJiBGTNmoLKyEgAQFxcX9oURRKiU11jx6/EinCurQX65CXaWk/TN0CUoXJEXqVVvdpZDucldaMlKvUkcX8Ij9FIKknozWV3Rm3A3nAQ8xpg4I1aVZpujEaCfKAMvCjUqhZs4khdRcnx0VZmCP7dE5AkUOfL39yeOKMlpDwCI5r1Z7OEfimtzeZQookQAIXiUTp06hePHjwNwCCReJB0/fhy5ublhXRxBhEJFjRWbjxYCcEQ1iquCG54BkUfJV+otiNipqLEK3575KFSCjIo5V+pNmphJkjjvjfdNqRSM17iQcCAWN3E6lfB7abXFb0SJ7xnlPb5EhlByHltJHqV6h+O4gJEjv0ZvNnQzt3jeW8Q6c6sp9UY4kC2UJk2ahO3bt3tt37VrFyZNmhSONRFEyJhtdpy6WI2/8yuFbfkVJknHlvvoYM0Ll7Iaa8AQP5+2E/dBkuNR4sVUvNyIUhChVCbyXUkZzCsXcaUawzCulGCAHlaVJu+u3AwjL/XGtwioIqFU7wTzCAUSMjUhzHoDRPPezOHvoySk3tQ0v4RwIPudsG/fPlx++eVe2/v37++zGo4g6pLyGit+OVrkti2/XJpQKvNl5nYKF4uNFRrR+aLUh2E6MRQzt1yPksSIUmKQ+XGhovSoVEsSVb75iyRUml2iUjiPzG/ufNPJKhMJpfomYGVbgNtr03AyRtQeQE5TWSnwqeoY6s9FOJEtlBiGEbxJYsrLy2G3k7GSqF/Kja60Gx/ZKZAYUfLVb8igUULtFAOlAYzTZUb3ijfAFVGqMtuCXkzKQzVzS4woJcWE38gN+Bpj4jJ024JElGJEPZTUMqJJgOsiRu0B6p9gqS+/zSjZ0Ga9AaIxNhEw85uEKBdFlAgHst8JQ4YMwYIFC9xEkd1ux4IFCzBo0KCwLo4g5GCxsdifV4YL5SZoVQoMaZ8KADhXViPpeF/DYxmGkWTKFrpfx3j3YAIQdN6b3Mq0lBhHHyWpQikhQhElf0KpuNri9wLpSr25oggauUJJS6m3hkKwLwH+TP1GqyttFuoIk+owe5RsdlYQ+Ho1RZQIB7LfCS+//DKGDBmCjh07YvDgwQCA3377DRUVFdi0aVPYF0gQUqkwWbH5mCPtNqBtCpol6gEAFySm3vz1Mko0aHCxyhKw8s2z2STg8NzEaJWoNttRVmMNWHVWYfJ93/7gI0TF1WZwHOfXf1TqI9IVTjx9RUmiOXT+LqB8FEic2lCrQku9VdNg3HonmFDxZ+rn3wcKxlGKLwdxRDGcmTe+2aTjPsJf/EBEJ7IjSl26dMGff/6JsWPHorCwEJWVlZgwYQL+/vtvdOvWLRJrjAjvvvsucnJyoNPp0K9fP/z+++/1vSSilhRXmfGbUyhd2SEdLZIcQkm2R8kj+iJ4jQJElMr8dL9O0AX3KVlsrFD9IzeiZLVzAaMqchtZhoLSrTs3PxjX6lcoVYUhohTnfF4p9Vb/BJsSFEww6zVK2YUGQurNYoddxpiiYPBpNwBC93eCCCm22KxZM8yfPz/ca6kzVqxYgZkzZ+L9999Hv379sHDhQowYMQJHjx6lMSxRis3O4rfjF1FptiHJoEbP7EQUO+egFVYEbw9gstqFCpwEHxElIHB3bldrAXeRlWBQ43y5SfAw+UIsouIkDMUFHBcXvdrRnbqk2uL3OL75o9S2A6GgUroG4yYLKUEzOA4+o128sHPzKMmMKIhTL0T94i9ixOMv4sQ3Cw0lxcVHFG0sJ1SphQPeM+XZ44to2oT0Tvjtt99w1113YeDAgTh37hwA4PPPP8fWrVvDurhI8cYbb2DKlCm455570KVLF7z//vswGAz49NNP63tpRIhUmGzY9LfDxD20QxpidUrkpMYAAAorg0eUeA+RggHitO4f3FJ6KZX68Dc5fg8+GJe/LV6nklX9JcXQ7avbeLhxm/fmTAnyz4evaEKVKJLAIz+iFDkzLyGPoB4lf0IpxIo3wBHt4d914fSpCT2UlNRDiXAhWyh9/fXXGDFiBPR6Pfbu3Quz2fFtvby8PCqiTBaLBXv27MHw4cOFbQqFAsOHD8eOHTu89jebzaioqHD7IRoe50qN+P1UCQDgyo7pSI7RIjNeB8DhYwn2YVoqMlN7TgznxU8gj5JQ9RbjGY0KnnrjR5xI7aHEkxIrQShFcM4bj7iXEn8/5TVW2Oysz2iDEFGqhVCKFTozU0Spvgk2QiRY6i0UoaRgGOG4ijC2iDCJeijR+BKCR7ZQmjdvHt5//3189NFHUKtdH+yXX3459u7dG9bFRYKLFy/CbrcjIyPDbXtGRgby8/O99l+wYAESEhKEn+zs7LpaKiERO8vhx8MFsLEcWiUb0DY9Bol6NWK0KiFEH8ynFGiEiBBRqg5e9eaVepPgbwrVR8SLkkDduX1V8oUbcS+leL1a+CZearT69K/wKRe+JFypYLzEaTD4VKORzNz1TtDUm5/MmOt9EJoXyFX5GL4xNjVW1/gSOZ3iicaNbKF09OhRDBkyxGt7QkICysrKwrGmBsVTTz2F8vJy4efMmTP1vSTCg0qTq3fSFc5oEn/hTY9zRJWC9VLiU1S+KtMSBI9S8Ko3z8hNgoSIkj8TeTCkdOf2VY0XbsQXFAXDCIb2UqPvMSZ8k0H+QqeRWfEGuC6ulHqrf4I2nAySetOH2NhR8KmZwvce4FNvGpVCtngnGi+yhVJmZib++ecfr+1bt25FmzZtwrKoSJKamgqlUomCggK37QUFBcjMzPTaX6vVIj4+3u2HaFj8nV+Bw+crwAC4omOa4N0BgAxn+i1YRMnX+BKeRAl9lPxWvQlpu+ARJakVbzzBPEocx9VJ1ZvnN2+hO3e17xYBnpEEuc0mAVfqrcZKqbf6JtSqN2OYIkqVEYkokUeJcCH7E2rKlCmYPn06du3aBYZhcP78eSxbtgyzZs3Cgw8+GIk1hhWNRoM+ffpg48aNwjaWZbFx40YMGDCgHldGhALLcvjhT0fKtHuLBLRKMbiV9WYmOKqwgs1781e15tgWOCokrpjzm3qTIpRkiplkp0epuMq3UKq22GG1Oy5SdeVRAhB03hsfSeB74YQilAyi8nCifgnWR8mfh4nvgWUIsQxfiCiFMaoojigpyaNEOJEd83zyySfBsiyGDRsGo9GIIUOGQKvVYtasWXjkkUciscawM3PmTEycOBF9+/bFZZddhoULF6K6uhr33HNPfS+NkEmFySpUu13ZMR0psVq327MSnE0ng3TnDtQZmxcZ/iJKvNBRKhjE6zwq5vT8scF9RHIjSimi5o6+z+vYrlEpoIvggE/PeW+CUPKRenMfW6EU1ieXWKfIsto5WGxsSOcgwkMwj5Kv21nWNedN7kBcnhitqOkky4UlVWYSRZQU9JYinMgWSgzDYPbs2Xjsscfwzz//oKqqCl26dEFsbCxqamqg1+sjsc6wMm7cOBQVFWHOnDnIz8/HJZdcgvXr13sZvImGz++nSnCurAYapQKD26d6CRWp3bkDldEnBKl644VKvE7l1TNISkSpQuZAXJ5gZm4hHahXy27oJwd/qbdSH6m3CpMV/BaDNvTUG38s4PA8aVSRi5gRgQk2lNZX6o2DK80VcupN44oqhqs5Nx+h1KqUFFEiBELWzBqNBl26dMFll10GtVqNN954A61btw7n2iLK1KlTcfr0aZjNZuzatQv9+vWr7yURMjHb7Pj+z/MAgP5tktEy2eAlCPgWAcFSbwE9Sk7xZLKybp17eXzNefM8NqC/KUSPkqs9gO+GmoJJPIL+JMD/vDdfHiVeFKoUjNASQG5rAMAhrvhhxTTGpH4JpeqN5UIfiMvjSr2Fb95bjTj1Rh4lwonkTyiz2YynnnoKffv2xcCBA/Htt98CAJYsWYLWrVvjzTffxIwZMyK1ToLw4myJEb8euwgAuLJTuk+hwgulwlp4lGK1rkaQvgRPoF5FvPgJNBQ3dDO3swu2H49SXVS8Ad7z3txSb14RJVfvHF7Uhpo2M4jmfRH1h5QJIp5RJ45zRW9CjSiJe2mFTSg516RTKyIahSWiC8lSfs6cOfjggw8wfPhwbN++Hbfddhvuuece7Ny5E2+88QZuu+02KJU0G4eoG6rNNmw5dhHlNVYk6tUY2iHNZwonw2nmLq62wGZn/Y4lEHxCPqIvDMMgQa9GSbVjMG5mgs7t9lI/FW/i85lsjmiUr/lRQg8nuWZupyCptth9nrsuunLzKBWuMSbi1JvnBYwXjLy/RKFAyN/cDRolymusJJTqGSkixc5xUMD1OrNc7T1KBnHqLUy5Nz6ipFPRtYxwIVkorVy5Ev/5z39w00034dChQ+jRowdsNhsOHDhAypuocy6U12DjEUeLhyEd0oQ2AJ6kxmiFi3hRlVkwd3sSrDFjosEplHxElAJFbmI1KigYgOUcIsGXUAo1ohSvU0GlYGBjOZQaLV6Praw68l25edznvbm6c1ts7uGGCo+BuKGk3Xj4C2xlGDszE/JgWU6SSLGzHDzf+sZapt74ZrLVZlvYhBKfWg9VvBGNE8mfUmfPnkWfPn0AAN26dYNWq8WMGTNIJBF1Tmm1BftOl2HbiWIAwPXdM90GrIpRKBikOr08gXopufoN+RYVgXop8cf6iigpFIzQRdqXodu915E8QcMwjJBu9NUioCzE84aC2KeUoFcL4rDYwz9VYXJGlGrRGoCHP0c4Z30R8pCa8vLcz82jFHJ7AD71Zo9A6o2EEuFC8qeU3W6HRuP6wFWpVIiNjY3IogjCHyzL4Xx5DT749SQAYHjndFyakxzwmMwgTSetdla42PqLKLlmmHkLktLqwF6gxABNJ2usrl5HciNKQODu3K5IV+RTb+JeSkoFI7RFuFjpvq5K53Ogr0VrAB6DEFEKX8NBQh7BjNzCfqynUHJFlEJvDxB+Mzc/6y2S7TSI6ENyzJPjOEyaNAlarcPzYTKZ8K9//QsxMTFu+61atSq8KyQIERerzFj7Zz7+KaqCQaPEpMtzgkZMMhN0OHC23G/lmzjS428wbUKA6rXSINVlgea9iXswxYRwwQjUnbs8gHcq3Hj2UkqKUaPEaEFRlWdEqfbNJnlcF0qqeqsvpBi5AYcwEmOx2WGxOw4OR3uAIB0KJCO0LFCHlg4kGieS3w0TJ050+/2uu+4K+2KIpoXFxqKgwgStWiHMZAuE1c7iRFEV/rMzFwBw52Ut0To1NqgZmPfu+BNKvPiJ16n8nktoHOkjKhSo6g0QtQjwcazYnxRKGpsXSr56KZUKg34jn3pT+2gRcKKo2islyEfu+D5ItfEoGSj1Vu9IjSh5Vr1VicStvpaduY0WG7gwKSXeo6TTUESJcCFZKC1ZsiSS6yCaEKzTWF1UaRZMmGYrixZJ+oBioaDChP/uzEOlyYaWyQbc0CNL8B8FIishcOqtPEBrAB5XPyT5Ka4Eg8vc7EmoXbl5eKFU6kMolQXwToUbT4GZLJr3Ju6aXOkZUQphIC6PuDMzUT9ITXl5Cqoq5/tAo1L4rUQNBv/6s5xDLCf6aA8iF8HMTRElQgTJ5kbCrJUHcN2i33AuyKiO+qa02oKjBZUorDC7VaqUGa04ebEaNrvvWL7Jasfe06VYd+gCAOCBIW2QlaiHVkIZb2YQoSSlMWOgxpGugbiBPUrlPkRWeYhduXkCRZTKquvSzO3+UZIkbjopeqF5P1E4qt74VCVFlOqPYF25/e3n+T4IBfHg2oow+dRc3cLp0ki4oHdDI8BktWPV3rM4cqEC9yz5PeC4jPrCaLHhn8IqnC2tgc1pXi6oMOGj307iv7tOw2pnYTTb8U9Rlc/u1+dKjfjg15NgOeDydqnom5OM9Dit136+yAjSnVtKVCfBT9Ubx3GiyI1vQRJojEl5gP5NUnCZud29QCzLCU0068Oj5K87Ny9qYrQqMIx3s0o5xNJg3HrH13gSn/t5RpT4FGwtqssYhhGEVkWYWkSYrbxviiJKhAt6NzQCThcbBTPjsYIqPPD5H/js3sskRVsijdFiQ3GVe/+hwgoTvtxzFj8fKRA+aP/ILcHjIzqhWaIe/xRWITvZ4OpqbbJi7cF8HD5fAa1KgXsvz0HzIGk6MXzVW0GFCRzHeR0npYyev83TZ1RptgmPIaiZO4hHKRSE7tweEaVKs014T4QqwuTgd4yJ0b3pZJWoj1JtB9nG6sijVN94CiCO41BcbUFKjMbt78xTT1XyQqmWgiRGo0KlyRa2ykdXRIkujYQLiig1Ak4WVQEAmiXoEKNRYufJEjz+1Z+Sw+LhhmU5lFRb8E9hJU4UVgsiqbDShHc3/4MH/rsHPx7Oh53l0L15AuJ0KpwoqsajK/bjt+NF4Dggr9iIwkqHsDlZVIUl23MBALf1zUaHjDghmiAFPvVmsrI+v3nyKbFA6S9/6TM+vaVTK/z2XglUMRep1BvvpTJolHUimAMNxrX5iCgZNKpaVbwBLo8K3+GZqHs8LUobjxTinqW78f2fF9y2e34WVZtq15Wbh698DFfTUVfDSbo0Ei5INjcCTl6sBgD0a5OC0b2a496lu7F6/3k0S9TjiWs71ercRosNpUYrrDYWOrUSerUSWrUCGiWDwkoLTl6swpkSIzQqBQwalWNIAQPEqFWIcc5IK6o0Y+WeM9jwV4Fw0ezZIgF3XNYSXZsl4GKVGa/9dBSHz1fglR+P4sDZckwZ3BoF5WaUG634fMdplFRbkBmvw629WwjmbKno1ErE61SoMNlQUGHyit5IGfWR5CeiVBqk4g0Qpe18mblrLG77yMWfmTtYp/Fwo1IqwDCuCyefEiw1Wtx8Z7zxOiYcESXBzE2pt/rCM/V24FwZAODguTLc1LOZ3/2qze4d2kOFLwoIV0TJ7Owk76+BLdE0oXdDI+CEM6LUJjUGQzqkYcEt3fHYV3/ivV9OoHmiHnf1byXrfBYbi7IaR7qstNqCMyU1OFtqxLmyGpwvq8H5chPOl9UIHyqBiNEqYbaygkDq0SIBdzoFEk9qrBYvjeqO//2ehy//OIMfD+fjaH4FHr+2ExgAq/efBwBMGdwaLVMMIflaMhN0qDBV4UK5CR0y4txuk+RRcoooo8UOs80uRGmkDJ51dfX2ZeZ2XDD89W8KBi+UymqssLOcYG6tq4G4YhQMI6RiEg0aMHCkXC5WmoUUoas9gApqZe26+sc5L2Y15FGqNzwF0NlSRzHJmRL3ohIvj1It57zx8G0mKsMgljmOEyJKtRVwROOChFIj4GSRI6LUJs3RKf22vtk4X2bCmz8fw5zVh5AZr8PwLhkBz2Gy2HHwXBkOnC3H0fxKnC42Ire4GoWVZr/HKBmgeZIBOakxsNlZXKwyo8xoRZXZJhhs+W/7PZo7Ikjdmie4nUOvUcLGsoANuKt/K3RtFo83NhxDbrERM1bsR1aCDjaWQ99WSRjaMU0QBnLJiNfhWEEVCnxUvknxKMVpXTPbyo1WpMc7PkjLJDR15EWWr7RfWS0FDX+/HOcQR6mxDkFSLiFKFm7UonlvSoVjkHBZjRWFlWZ0yHRciPj3Q4xGWauKNwCIc4rLakq91Rti/xnHcTjnFEoXymtgtbNCetWrj5IpPB4lQxgjSlY7J3ipYsijRIigd0OUw3t4AKBNmqtL+rRh7XC+rAYr/jiDqf/biy/uH4BLshOFY3KLjdh3uhS7ckuwP68M/xRV+a1gSTKokZ1sQPNEPZon6tE+IxY9WiSiXXqsl8/EaLHhQrkJFU7BVGm2QckwaJboGtjKMI7oTWqsFnqNEizL4UKFCSVVFvRqmYS3bu+F1zYcxZ9ny5FbbIRKwWDKkDZokWQI+XkSein5qHyT4lFSOC/8pUYrymqsSHcaxKWk3vhmleVGq5eZvLZmbpVSgUSDGmVGK0qqXUKptA4H4vJ49VKK0QhCCXAYZfnIQjg8Svy3fooo1R/ij4ziaotghmY5R3SpdWqM136A6wtUbareAFf6tSoMHqUaUbUtCSVCDL0bopziagsqTDYwDIQPJcBROjtvdDdcqDDh12NFmLx0N+7q3woHzpZhf16ZT7+MQaNEq2QDWqXEoFWKAa2SDWiZEuPsGu3ojZMaqwloDjZoVGibFotyoxX5FSYkitJzSgWDlFgNkmM0bhdJhYJB80Q9EvVqnC2tQVKMBnNv6oaVe85g1d5zuOOybPRskVirQZWZAbpzS/EoOW7XOISSyJQtpQcTL4LsHIdqi93NiB6OyE9yjAZlRqujC7YzcMg/prqoeONx9FJyXWySYjTARVdUkjfcKhiH+T1cHiVqD1B/iL9c8Wk3njMlRuEzyfNLWFWYPEqGMPbS4tNuCgbQ0qw3QgQJpSiHT7s1S9B7CQm1UoHF43tj3Ac7cPh8BRZtPC66jUHnrHj0bJGIS7IT0atlIpol6gCHHRsc5wirc3BEoHRqpawIQIJBjXi9CsXVFpTXWJFs0CDREHhMR4xWhfbpsSioNKG4yoLbL22JcX2zoVUrJfdM8ofQIsBX6k2C2AHEvZRcXqMyCYNndWoF1EoGVjuH8hqrm1CqbWduwNEF+ySq3VoESEkJhhuvXkoGfjAuL5RcA3EVCiYMESXH82iy2t26fxN1hzj1dqbE6HZbXqnR536AK10aPjN3+ISSVqUMaZwQ0XghoRTl+Eq7iYnVqrBk0qV45ttD0GuU6JWdiEtaJqFzVlzEy8YZhkFqrFZIB0lBoWCQlaBHgl6Nc6U1MFlZNEvU1foimJngWMMFD6FkZzmhq2+wmWi+ZraVBunKDTiehwS9xunhsqC5Mw3JspwgHmollEQ9i3gEAVcHc954POe98d25L1a5R5RiwpB2A1wRJQ6OtIm/SqUqs01WOwlCOm4RJedUAINGCaPF7iacOA5uYpaveguXmTscY2z41BtFkwhP6NMjyuFbA7R1Grl9kR6vw4cT+tbVksKCQaNCu/RYVNTYEKerfVQkQ9R0UkxFjVUoaQ8mVngxVG4UCyVpZuwEvQoXq8xuTSfdmkLWQiilOOfdlYgG0JZKjJKFE89qRF7AFXkIJYNGWeuKN8ARqeMN9tUWm0+hVFhhQmGlGV2y4iniFAHEkaKzTmF0aU4ythwr8oowsRwHhTNizadL9WFoOAmEK/XmsAloa5kSJhof9I6IcviIUls/EaVohmGYsHls+NRbcbUFFpFvio8OSenr4+qHJD/FlehDZFU471ur8t+sUgrJPsaYSKnkCzeeaZRk53NS7BRwQkRJq6q1PwlwvD/4yfOevZQ4jsOZEiMKnDMFjT7G4hC1hxV1COE9SgPbpgAAzpebYBX10BK3CAhbH6UwDkbmiwJ0DWCiAdGwIKEU5Xi2BiB84zCQO77NFla6okpyyvP56ExpCBGlRB9jTGpb8cbD9ygqrvZOvdWlR0mnVkIlihSJB+MC7oNQa9sagIdP3YgvlHaWw6mL1W6me6qMCz/itFu12Sakfnu2SIRerYSd5dxS3WJRxUeUalv1FgkzN6XeCE/oHRHFWO0s8pzhbX8eJcIBwzBIj3O2CBB9eEuteAPEY0y8q96CCZIEH/6mcBi5ASA5xnG8LzN3XabeALh5gcSDcTmOE6XewuNR4s8FuMrDzTY7ThRVeUWYSCiFH18Vb8kxGsRoVchOdvjwxOk3t4iSJTx9lPjUW3UYXl9eKNUmuks0TkgoRTF5JUbYWA4GjVJILRH+8dVLqVyGoHANxnUIEqudFb7JButX5GswbrgjSrxQEhvU6zL1BgBxOteFj39ObM7Zf24RpTD5QPiIQqXZimqzDScKq4UJ8GKMVmpKGW7c/EnOCrfsJIdAapns6HmWJxZKTmHFcRyM5vB0wOZnvdVY7H77wEmFN3PrSSgRHpBQimL4tFvr1BgqZ5UAPxzXLaIkozrMc7gt/y/DBB9B4mot4C2UaitmUjxSXHIM6uFGbKhWKxWCcMovNwmdycNV9Qa4LrQFFWaculjt92JptXFuM+eI2uPWGsAZUeKbwmY7/z1TKq58c+xvtNjBH1n7obiu91tt02+CmZtSb4QH9I6IYlytAcifJIVMH5VvchozJuo9hZJDmMTr1F5dqf0dWyFOvdVyIC5PsmgALcdxgm8qVhs+QSIVtVIBnehCw4u4/AqTEFGK0Yan6g1wpW7yy01ek+w9IUN3eHFPvfmJKBV7R5R4QaNgal9hplYqhPdShY8munKgiBLhDxJKUYxg5E4lf5IUhIhShag6jE+9SRArQnsA5wdyqYymji6PkstHFK55bLxQsto5VJhsgvhLiqnbaBJPrI/0W0GFK6IUp1OFLQLKp15MEkQQ+ZTCi6+KNyGi5BRK58pqBIHEe5SqRD2UwvE+4KNKFbWc92YioUT4gYRSFHPyYuBmk4Q7GT66c8sRK/w+VWYbLDZWcsUb4ErtuaXewmTm1qmVQgqqpNpSL80mxYgN3XzlW0GFOSzNNT3hzbw1JJTqHD71ZrWzuFDOCyVHRCktTgutSgEbywm38cIq1IG4Bq3Sp/jn3wMVNbVNvfG9nUgoEe6QUIpi+IhSoGaThItMH2ZuOaIiTueYeQc4BJacEvz4CJq5AfcKs/qqeOOJ0aiE54lPvRVWmoWqt3A0EBXuS+saYxIMmgkXXvgI0YVyE1jOEYnh34cKhnH5lJyGbs+IktTWAAoF0DxJj7ZpsT6/lPBfEspF0dpQ4IU0RZQIT0goRSnlRqvQN6c1pd4kwXuU8itMgrFUjkdJqWAQr+MFj0XUGkB6DyZfQikcgkZs6HZ15a6fiJJCwQgXL/65KawwCUIpnAKOT71JEUF2lnNrNkrUDtaZUuP9SS2S9G6pNL5FQF5pjdv+4g7twUg0qNExI04QYAa1Ep7ZOl4sl9fSo2SyUUSJ8A0JpSjlhDPtlhmv8zvjinAnPd5RRm+xsYLIKZfhUQJE896MVlmChI8aVZpsgmeDT90Fq5iTgrg7d3k9NJv0hPcpiceY8JGEcAq4WBkRJYDSb+GEjxDx/iQ+gsTD+5T4iBKfqqsShiP7/9zSqBTISTUgO9ngNhpHoWDcigUAR1d9oPaDcWssDhFd295OROODhFKUcqKQ/Ely0aqUgnjgOwbLHfUhrnxzdfWWYOYWiSG+OkeIKIVFKLm6c5fKFH+RIE6rdq7LNRiX96bw28IBL5SkeJQA6qcUTviitzOiiJKYlh5Cif+CUBEgosQwDn9T+/RYvylaTyFjcL4HaiuUeLFd295OROODhFKUwg/DJaEkj6wEx4d5QYUJLMvJEjsAkCA0nbQKESEpkRu1UiHyUrgLpfB4lJzduass9TLnzRO9RgmlgnEzc1ucfYzCGelyeZSkpdQoohQ+XKk3p5E72T2ixAuls6WOyjfPiJIvQRKvUyMzQRdwgLHncXxEqbbtAUgoEf4goRSlCD2UUsnILQexobvKYhO+FUsVK0lC6k2+F0jcndtmZ4UxG+ERSq7u3HLFX6SI1aqQ7HxuxD13pHi65NwHEFgAnSiqEkQtGbrDh53lwHEczpW6V7zxpMfpoFEqYLGzKKw0ge/3WWn2b5oWd3b3h1dESROe9gA1NMKE8AMJpSjFNQyXIkpy4FsE5JebBH+STq2Q/OHoK/Um9cIvdOeusQrpB/H22iCYuY0WUaSr/iJKgMOnpFEp3NoF6NVKN89JbeEvrP5Sb9/uP4dHV+zHnNWHwHEcOE66n4kIjJ3jUFxtQY3VDqWCQZbHGCWlghHE05kSoyuiZPYfUYqVIJQ0KoXb8GU+qlj7ztwklAjfkFCKQuwsh9POjrfUGkAe4u7crmaT0gVFgmjem9wy/ERRRIkXWTHa8AgHX+0BpFTyRRJeICWJPEl8lVrY7sPpY/EllL7dfw6fbD0FAMgtNuJoQaVjX4oqhQWO4wT/UVaCzuf7mDd0ny4xujpz++mjpFMrJHeSF4ussJm5qeEk4QcSSlHI2VIjLHYWGpUCzRL1wQ8gBDITHCmq/AqT0CVbToqKFzulRqurPYBEczKfois3WsLqTwKA5FjHuYur5LUtiCQalQIalQLJouc3NswVmrF8Z24P8bNaJJJ4EbnxSCEAGmUSLuysuCO3788hceUbxznElbgztxg5/bXEIitcZm6hjxJ5lAgPSChFIcIw3JSYoDPGCHfEqbeyEDpj86LqQlmNYE6WWl0m9iiVhVsoGXyU4ddj1RtPrE7lVuUWzmaTgOuCKY4ofXfgHD52iqRxfbMxc3gHAMBvx4tgttlRY6HKt3BgZzmcLfPdGoCnpZB6qxGOERpOeggSKWk3Ht8Rpdr2UXL8PetUJJQId0goRSEnnEbutunkT5ILb+YuqDCJqsPkC6VcZ+pTI6pmC0aCqAdTRY38tF8g+IgS31CRYcLTn6m2xGo9hVJ4I0q8P8XGcrDaWXx34Bw++s0hksb2zcb4fi3RvUUC0uK0qLbYsetkCUxWVmg4SoQOy3E4W+K7NQCPEFEqdXiUWE7UmVsUFVIoXIJHCgaNq/Fk2DxKQkSJLouEO/SOiEKE1gBU8SYb3qNUarQKM99keZT0Li8Q4BBOUgd7iiNK4ezKDQBxWpUwRR1wlFk3hGijp1CKD3NESXxxXfnHGUEk3danBe7q1xIMw0DBMLiqUzoAYOPfBeA46X2XCN/wxnjPYbieZCXooVIwMNtYFFWawXKcyKPkeu1itfIGJTMMI5iu+VlvtRZKzs7cWoooER6QUIpChNYAVPEmmwS9GlqV423Pm3vliBXPHkByfEDiqrdQ0n6BYBjGTZDUZ1duMUoFI6Q7ASBOH96Ikkrp8EEBwP92nwHgEEl392/lduEd5hRK+8+UobjKTIbuWmJnOVSbbShxFiX4iygpFQyaJ7oq38SpN7FpOhTvGl8YwAsuk5WF1R7aiBqW5YReXORRIjwhoRSFuFoDUERJLgzDCOm3o/kOoSSnOsyzZ1IoabtyozXsZm7A1UsJcFXnNQTEF9FI+KbEw1V9iSTAEdno2iweLAdsOlpI/ZRqiZ3jhGhScowm4NgPPv2WV2KEneOE514cUQrFu2ZQO+5TPMIpVEO3WTQDkKreCE9IKEUZlSYrCivNACiiFCp8+i3P6a+Qk3qL9/DYhBZRikwJP9+d27GuhhFRAlwdmoHwp94A1wy/W3v7Fkk8fFRp45FCGMnQXSs4zjW6JNtPNImnpcinZLbaBVHCiyut2hUVlIPBGVFSiua/hWroFvfWoj5KhCcklKKMU05/UmqsNiIXnaYAH1HikRMVUikVbobkpBgZESWnIBN7lCIVUWoIFW88rVJcQincZm4AmHtzVzx/Y9f/b+/e45o877+Bf5KQhENIOISjIoJYrIrHthZsrU5+gPPX6bpWZ32cts5Wp11trVVr56F9dXa2XedcZ7t1U5+tqz08HrZqVaZSW4taLYigUqFYUAmoCOF8yvX8gbklQiCBQAh83q9XXpD7vu47Vy7vmC/X4XvjF7HWgyQAGB+lh9pNjiul1ci4XGaRLZzs02gS7c5PMrt9z7dqix4f8xBXR1NGKBVyKN2a/r2l7NzVHQuAzXPWlApZj5jbRz0LAyUXw4zcnRd8RwZhe4OK5oGVzq6J4E3HGavrUWbO4eSgVW/A7ezcgHPv83YnL7VSmnTt6PQAADDAzwtjw33bnQzsqXJD3CB/AE29SpzQ3XFNQ2+29Sg1H3oz/4GgdpNLAUlngmfzRO7OpghgVm5qCwMlF2OeyD2IgVKHBd0RKNk7/NU8uLFniMscKFXXm6ThU8f2KDUPlHpOjxIA6L2beru6okfJnh6AyXcHAWjKqVRSWevwuvQVJjt6lEJ07lDIZaiub5T+0DPPT5LJbgc7HWHulTLPUzJ2cI4S7/NGbWGg5GJymRqg01oOvdnX+9I8CLFnjpK3uxvMX+lXbyXqc2Sg5Gux6q3n9CgBwKz7BmBoiBb3Rfg5/Nx2rCpHTD8dAm/lVPrvuWKH16WvqG0wobCs7azcZkqFHKG3PnMZV0oB3B4q81K7Qd6JoS5zkGU+X2d7lDiRm1rDQMnFcOit8+7sUbJ/6K1jPTdyuUxaHl/fKOw+vj3+PbhHaeFDg7DzV3FdMiSosCNSap5T6bOMqw6vS19x6XolTKIpsPCz4RY+5uG3zCtGALcDks72MLor5U29Urcmdne0R8mcGsA8KZyoOZe5Kl577TXExcXB09MTPj4+rZbJz8/H1KlT4enpicDAQCxfvhwNDZYfnJSUFIwZMwZqtRpRUVHYtm1b11feQUwmgbzr5hxK7FHqqOY9SkqFzObM2mbNAytb7/N2+1jL8o7Mnu3XQ+comXXVsIbcni4lQAqU0vJLUVBS2RVV6vXMi0r6+3rYlCjSHCidL2wKlDw7OZHbTCaTwUOl6HSPknSfN/YoUStcJlCqq6vDY489hkWLFrW6v7GxEVOnTkVdXR2+/vprbN++Hdu2bcOaNWukMnl5eZg6dSomTZqE9PR0LF26FL/85S9x4MCB7nobnVJorEFNvQlKhazdCZRkXaC3Whqu0Xmo7MoIDNw59GZfoNN8qE0ua8qo7Sj+PTDhZHewN1Ay51QSAD45fblrKtXLme8OYO0eb3cacKtcVbMbzyrdZA4Jnr1UbtLNkTuaR8mclZtzlKg1LhMorV+/Hs899xxiYmJa3X/w4EGcO3cO//znPzFq1ChMmTIFr776Kt555x3U1TWtMHr33XcRERGBt956C3fffTeWLFmCRx99FG+//XZ3vpUOM0/kHuDnCTeFy/zT9ThKhRz+t5bSd2SIqnmwY8+qtztfz9td2an5GXey6FFy4Gq6nk7egY9C/JCmSd27067yvm8d8MON2z1KtgjzswyoPFUKh62A9FQ7sEeJWbmpFb3m2zY1NRUxMTEICgqStiUmJsJoNCIrK0sqEx8fb3FcYmIiUlNTrZ63trYWRqPR4uEsucUcdnOUkFvDbx3peenoHCXgziDLsb0+Pp4q+HupoFG7IcBb3f4BvUR7PUohPu7o5+sBt2b3wouL8ofaTY78kip8m1/axTXsfX64dVPo/n629Sj19/VA878JPFVunR52k86lVEjpATqaR4mTuaktvSZQMhgMFkESAOm5wWBos4zRaER1dXWr592wYQN0Op30CAsL64La20a6GS4ncneaeUK3vT1CwO05Sk03orXvI9Q8OHJ0UkiFXIadv4rD7sVxfeov47bSA+i9VdBr1PDzUiE6yBtBOjXk8qYv6vGD9ACATzn8ZhchxO1AycYeJaVCjhDd7bKeKoXDhp3dFHIpxUd5bUdXvZknc/edzw3ZzqmB0sqVKyGTydp8XLhwwZlVxKpVq1BWViY9CgoKnFYX84q3QUwN0GnBuo4PvZmDrKA70gzYwiJZZRfMIwr390JUoLfDz9uTWetQ0nkoLb6c5XIZAr3dMSRYiwBvNeKHNk3q/s+Zqxa3sKC2GYw1qK5vhEIuQ4jW9s9AmN/tfwudh2OHnc3pMDo6R4l5lKgtjs/+Zodly5Zh3rx5bZaJjIy06VzBwcE4efKkxbaioiJpn/mneVvzMlqtFh4erf9lpFaroVb3jGEM8xwl9ih13j3hfvjn8XzE9NPZfezwflqsfXgohnfgWIsepR64Ms0VtZYewFOtaPOO9sE6d/xsTH/88VAODMYavLw7Ey8kRLfIsdWWRpNAdX2jw4aQXEXOrSkAITp3u+ZKhvl64jhKAMCmlAL20Guazmes7mxm7l4zyEIO5NRPeEBAAAICAhxyrtjYWLz22msoLi5GYGDTX4rJycnQarUYOnSoVGbfvn0WxyUnJyM2NtYhdehKVXUNuFpWA4BzlBxh+uh+GB+l79BcHplMhifGR3TodZtPstZ59K0v2K5y5xwllZsc4X6e7fZYqJUKLJo4CGv/nYVPT1/GnvQr+Onoflj40CBE6L1arIZsaDShsrYRlXUNqKipxwVDOc5cLsMDUXpMupVyoC8wz5W0ddjNrPnNkf01jg2UArybAtzO9ihxjhK1xmX+p87Pz0dJSQny8/PR2NiI9PR0AEBUVBQ0Gg0SEhIwdOhQzJkzBxs3boTBYMDLL7+MxYsXSz1CCxcuxJ/+9Ce8+OKLePLJJ3H48GF8/PHH2Lt3rxPfmW3MeUt8PJUO/2usr3LGhGdtF07m7qvkchlksqY72ivkMgzU274q9Bex4YgK1OAP//0O31y6iY9PXcbOb69g8t2B+D/3D0DErWHuqrpGVNQ04OzlMpy4VIKTeSW4XtF0C5T/m3oJv/nfofhF7MCueos9Ss6tnm1bUwOYNV/55ujM8eZb5LQVKJVV1aPBZIK7UgF3pcJibhsnc1NbXCZQWrNmDbZv3y49Hz16NADgyJEjmDhxIhQKBT777DMsWrQIsbGx8PLywty5c/HKK69Ix0RERGDv3r147rnnsGnTJvTv3x/vv/8+EhMTu/392Euan8TeJJfWfI5SX1rC39XMnT/h/p5Qu9n+ZSeTyTA+So/xUXoc//4G3jyQjVM/3MSBrCIknyvCpOhADA3V4tSlm0gvKLW4ka7KTY4gbzUKblZjzZ4sXC2txoqkIXbn5XI1ucX2pQYw6+fjARkAAUDj4Hv+mTN81zWakG0worC0Bt9fr0DOtUrkFlcg51oFblTUWRzjJpdBrZRD7aZAVV1TgMU5StQalwmUtm3b1m4W7fDw8BZDa3eaOHEi0tLSHFgzx6msbYDBWAND2a2HsQaFZdUwlNVKGW0j9Zyf5Mq6Mj1AX9Y0sdhDujlqR9wf6Y9PF8Uh5UIx/nj4Ir7NL8WhC8U4dOH2PeH8vFS4d6Af7hvoh3sjfOHnpcJbB7OxK+0q3v3ie1y+WY23Z46yezVkdzHW1OObvBJkXTFiRJgOcYP0ULnZV9fca+ahN/t6lNyVCgzUeyHveiX6+9h3bHs0KjcpCEv6w5ewJTNWg0mgobYRlbW3g99Bgfz/lVpymUCpt/vy4jXM+dvJdsuNi/TvhtpQV7EIlPpQ9uyuFqLzcFjgOXFIIO4f5I8DmQbs+KYAJZV1GD3AB+Mi/DE4SANfLxV8PJRSUPbmY6MQ7ueFPx6+iM8yCmEw1uBvc+9ttz5VdQ2QyxyTnbo1QghcvlmNUz80DRV+c+kmcosrLIIIjdoNk6IDMCUmBA/dFWA10LxeUYu0/FKc/uEmisubhhzt7VECgJen3g0vtRsG+Ds2UJLLZQj398SlG1UQaOphitR7YUiwN2L6+2BYqBZ3BXnDXalAbUMjaupNqKlvvPUwobahaVL+4KC+tWKUbMNAqYcIvDUZUaN2Q7DOHcFadwTr3BGic0eQtulnuL9nn1v63dtYpAdgj5LDOLot3ZUK/O/IUIwM80FFbQO07kroPJXQuru1GFpTyGVY+j93ITLACyv+31mcunQT0/70Ff4xf1yLjNR1DSaUVtWhtLoetbdy9/h4KhGoVds1ZNicySRQVF6DvOuVyLteiUu3fmZcLpOCmub6+XhgUKAXMi+XoaSqHv/JKMR/MgqhUsjxQJQ/EoYFY0iIFmcvl+Lb/FJ8+8NN/FBSZXGOMD9PKRu2PYJ17hgWav9qUVv8a8H9SMkuxt0hWgwO1EBjJfO3p8oNXHBK9pAJ5u+3i9FohE6nQ1lZGbRarcPO29BoQnV9o8PS+lPPJITA4NWfo8Ek8PmzD+LuEMddQ9Q1Gk2izaSWzaUXlOKX27/B9Yo6+Hoq8f7cexHorcYFgxHfGcpx6UbVrSH1GhSV1cBDpcB9A/1w/yB/PBDlj1AfzzaHwkwmgfMGI766eB3pBaVNgdGNSilh4p3c5DIMC9XinoF+uHegL8aE+0p/lDWaBNILbmLfWQMOZhlQcLP1pLtmgwM1GDPAF2PCfdDPx6NDyVo9VApEBXbdPEuTSTg0PxP1Lh39/magZKeuCpSo73juo3RcMBixZ/EDds8PoZ7PUFaDX/z9BL4rqrDrOI3aDfcO9MX/DA3C1BEhUiBypbQaX128hqPfXcfXuddxs6plriA3uQz9fT0QoffCQL0XIvReiA7yxsgwH5uG9oQQ+K6oAgezDDhwzoCrpTUYFqq9FRj5YlSYj0WvXU5xOarrWg/O2uLrpbR7bhORozBQ6iYMlKizahsaUV3XyISTvVhlbQN+/WEaDl0ohkIuQ6C3WhpOD741lB6sc8e18jocz7uBk3klKGuWLFGlkGP0AB9cLatBwR3DXh4qBWIj/REb6Y+oQA0i9F7o5+vRrRPIC0qqUNpKwNaeYJ17n7oPIfUsHf3+5hwlom6mkMlsHsoh1+SldsPf5t2Lm5V18HZ3g5tCjvpGExpNAvWNJjQ0CtSbmn7GDw1ETb0JGZdLcSznOlK/v4EiYy1O5DVlsZbLgJh+Oky4KwAPDg7AqDAfp/dENvVS2R8oqZn5mlwQAyWibqaQM1DqK3ybJYdVKuRQKqzn6okO9sajY/ujrsGErKtGHP/+BiL0Xhg/WA9tD5u72NGAx72DE9aJnImBElE3k8lkUPXQPDvkXDKZDGqlAmPCm+YG9VQdCXhkMji9J4yoI3jVEjmBPTcTJeppVG5yyO28hHnDWXJVvHKJiMhu9uZ96mieKCJnY6BERER2s7eHiBO5yVXxyiUiIruxR4n6CgZKRERkN3t7lDhHiVwVr1wiIrKbPTfzlcnAlZ7ksnjlEhGR3ZQK21e+qd3kLW4mTOQqGCgREVGH2NqrZE/vE1FPw0CJiIg6RG1jAklbyxH1RLx6iYioQ2ztKeKKN3JlDJSIiKhDbO5R4oo3cmG8eomIqENs6VGSyTj0Rq6NVy8REXWIUiGHQt72ajYVV7yRi2OgREREHdbesJo75yeRi2OgREREHdbe8BvnJ5Gr4xVMREQd1t78I85PIlfHK5iIiDqsvR4lJpskV8dAiYiIOsy9jR4j3uONegNewURE1GFubax8a7ofHFe8kWtjoERERJ3ibmXCtrXtRK6EVzEREXWK2so8JN66hHoDBkpERNQp1uYpccUb9Qa8iomIqFOsrWzjijfqDRgoERFRp1jrOWKPEvUGvIqJiKhT3BRyuCksV7cp3WRc8Ua9AgMlIiLqtDt7jziRm3oLBkpERNRpd85HYmoA6i14JRMRUaexR4l6KwZKRETUaexRot6KVzIREXXanYESe5Sot2CgREREnaaQy6SVb24KmdX7vxG5GgZKRETkEOZeJeZPot6EVzMRETmEOUBiRm7qTRgoERGRQ7BHiXojXs1EROQQ5pVu7FGi3oSBEhEROYR5pRt7lKg34dVMREQOoZDL4KGSw03BrxbqPXg1ExGRw2g9lM6uApFDMVAiIiKH0TFQol6GgRIRETkMM3JTb8NAiYiIiMgKlwiULl26hPnz5yMiIgIeHh4YNGgQ1q5di7q6OotyGRkZePDBB+Hu7o6wsDBs3Lixxbk++eQTDBkyBO7u7oiJicG+ffu6620QERGRi3GJQOnChQswmUx47733kJWVhbfffhvvvvsuXnrpJamM0WhEQkICwsPDcfr0abzxxhtYt24d/vKXv0hlvv76a8yaNQvz589HWloapk+fjunTpyMzM9MZb4uIiIh6OJkQQji7Eh3xxhtvYMuWLfj+++8BAFu2bMHq1athMBigUqkAACtXrsTu3btx4cIFAMDMmTNRWVmJzz77TDrP/fffj1GjRuHdd99t9XVqa2tRW1srPTcajQgLC0NZWRm0Wm1XvT0iIiJyIKPRCJ1OZ/f3t0v0KLWmrKwMfn5+0vPU1FRMmDBBCpIAIDExEdnZ2bh586ZUJj4+3uI8iYmJSE1Ntfo6GzZsgE6nkx5hYWEOfidERETUU7lkoJSTk4PNmzfj6aeflrYZDAYEBQVZlDM/NxgMbZYx72/NqlWrUFZWJj0KCgoc9TaIiIioh3NqoLRy5UrIZLI2H+ZhM7MrV64gKSkJjz32GBYsWNDldVSr1dBqtRYPIiIi6hvcnPniy5Ytw7x589osExkZKf1+9epVTJo0CXFxcRaTtAEgODgYRUVFFtvMz4ODg9ssY95PRERE1JxTA6WAgAAEBATYVPbKlSuYNGkSxo4di61bt0Iut+wMi42NxerVq1FfXw+lsikzbHJyMqKjo+Hr6yuVOXToEJYuXSodl5ycjNjYWMe8ISIiIupVXGKO0pUrVzBx4kQMGDAAb775Jq5duwaDwWAxt+jxxx+HSqXC/PnzkZWVhY8++gibNm3C888/L5V59tlnsX//frz11lu4cOEC1q1bh1OnTmHJkiXOeFtERETUwzm1R8lWycnJyMnJQU5ODvr372+xz5zdQKfT4eDBg1i8eDHGjh0LvV6PNWvW4KmnnpLKxsXF4V//+hdefvllvPTSSxg8eDB2796N4cOHd+v7ISIiItfgsnmUnKWjeRiIiIjIefpcHiUiIiKirsZAiYiIiMgKBkpEREREVrjEZO6exDyly2g0OrkmREREZCvz97a9U7MZKNmpvLwcAHjPNyIiIhdUXl4OnU5nc3muerOTyWTC1atX4e3tDZlMZtexRqMRYWFhKCgo4Io5G7HN7MP2sg/by35sM/uwvezXVW0mhEB5eTlCQ0NbJK1uC3uU7CSXy1vkcrIX7xlnP7aZfdhe9mF72Y9tZh+2l/26os3s6Uky42RuIiIiIisYKBERERFZwUCpG6nVaqxduxZqtdrZVXEZbDP7sL3sw/ayH9vMPmwv+/W0NuNkbiIiIiIr2KNEREREZAUDJSIiIiIrGCgRERERWcFAiYiIiMgKBkrd6J133sHAgQPh7u6OcePG4eTJk86uksOtW7cOMpnM4jFkyBBpf01NDRYvXgx/f39oNBr87Gc/Q1FRkcU58vPzMXXqVHh6eiIwMBDLly9HQ0ODRZmUlBSMGTMGarUaUVFR2LZtW4u69MT2Pnr0KB5++GGEhoZCJpNh9+7dFvuFEFizZg1CQkLg4eGB+Ph4XLx40aJMSUkJZs+eDa1WCx8fH8yfPx8VFRUWZTIyMvDggw/C3d0dYWFh2LhxY4u6fPLJJxgyZAjc3d0RExODffv22V2X7tBem82bN6/FNZeUlGRRpi+12YYNG3DvvffC29sbgYGBmD59OrKzsy3K9KTPoS116Uq2tNfEiRNbXGMLFy60KNNX2gsAtmzZghEjRkgJIWNjY/H555/bVUeXai9B3WLHjh1CpVKJv//97yIrK0ssWLBA+Pj4iKKiImdXzaHWrl0rhg0bJgoLC6XHtWvXpP0LFy4UYWFh4tChQ+LUqVPi/vvvF3FxcdL+hoYGMXz4cBEfHy/S0tLEvn37hF6vF6tWrZLKfP/998LT01M8//zz4ty5c2Lz5s1CoVCI/fv3S2V6anvv27dPrF69WuzcuVMAELt27bLY//rrrwudTid2794tzpw5I37yk5+IiIgIUV1dLZVJSkoSI0eOFMePHxdffvmliIqKErNmzZL2l5WViaCgIDF79myRmZkpPvzwQ+Hh4SHee+89qcyxY8eEQqEQGzduFOfOnRMvv/yyUCqV4uzZs3bVpTu012Zz584VSUlJFtdcSUmJRZm+1GaJiYli69atIjMzU6Snp4sf//jHYsCAAaKiokIq05M+h+3VpavZ0l4PPfSQWLBggcU1VlZWJu3vS+0lhBD//ve/xd69e8V3330nsrOzxUsvvSSUSqXIzMy0qY6u1l4MlLrJfffdJxYvXiw9b2xsFKGhoWLDhg1OrJXjrV27VowcObLVfaWlpUKpVIpPPvlE2nb+/HkBQKSmpgohmr4U5XK5MBgMUpktW7YIrVYramtrhRBCvPjii2LYsGEW5545c6ZITEyUnrtCe9/5pW8ymURwcLB44403pG2lpaVCrVaLDz/8UAghxLlz5wQA8c0330hlPv/8cyGTycSVK1eEEEL8+c9/Fr6+vlJ7CSHEihUrRHR0tPR8xowZYurUqRb1GTdunHj66adtroszWAuUpk2bZvWYvt5mxcXFAoD44osvpDr1lM+hLXXpbne2lxBNgdKzzz5r9Zi+3F5mvr6+4v333++V1xeH3rpBXV0dTp8+jfj4eGmbXC5HfHw8UlNTnVizrnHx4kWEhoYiMjISs2fPRn5+PgDg9OnTqK+vt2iHIUOGYMCAAVI7pKamIiYmBkFBQVKZxMREGI1GZGVlSWWan8NcxnwOV23vvLw8GAwGi3rrdDqMGzfOon18fHxwzz33SGXi4+Mhl8tx4sQJqcyECROgUqmkMomJicjOzsbNmzelMm21oS116UlSUlIQGBiI6OhoLFq0CDdu3JD29fU2KysrAwD4+fkB6FmfQ1vq0t3ubC+zDz74AHq9HsOHD8eqVatQVVUl7evL7dXY2IgdO3agsrISsbGxvfL64k1xu8H169fR2NhocVEAQFBQEC5cuOCkWnWNcePGYdu2bYiOjkZhYSHWr1+PBx98EJmZmTAYDFCpVPDx8bE4JigoCAaDAQBgMBhabSfzvrbKGI1GVFdX4+bNmy7Z3ub311q9m7/3wMBAi/1ubm7w8/OzKBMREdHiHOZ9vr6+Vtuw+Tnaq0tPkZSUhEceeQQRERHIzc3FSy+9hClTpiA1NRUKhaJPt5nJZMLSpUsxfvx4DB8+HAB61OfQlrp0p9baCwAef/xxhIeHIzQ0FBkZGVixYgWys7Oxc+dOAH2zvc6ePYvY2FjU1NRAo9Fg165dGDp0KNLT03vd9cVAiRxqypQp0u8jRozAuHHjEB4ejo8//hgeHh5OrBn1Vj//+c+l32NiYjBixAgMGjQIKSkpmDx5shNr5nyLFy9GZmYmvvrqK2dXxSVYa6+nnnpK+j0mJgYhISGYPHkycnNzMWjQoO6uZo8QHR2N9PR0lJWV4dNPP8XcuXPxxRdfOLtaXYJDb91Ar9dDoVC0mGlfVFSE4OBgJ9Wqe/j4+OCuu+5CTk4OgoODUVdXh9LSUosyzdshODi41XYy72urjFarhYeHh8u2t7lubdU7ODgYxcXFFvsbGhpQUlLikDZsvr+9uvRUkZGR0Ov1yMnJAdB322zJkiX47LPPcOTIEfTv31/a3pM+h7bUpbtYa6/WjBs3DgAsrrG+1l4qlQpRUVEYO3YsNmzYgJEjR2LTpk298vpioNQNVCoVxo4di0OHDknbTCYTDh06hNjYWCfWrOtVVFQgNzcXISEhGDt2LJRKpUU7ZGdnIz8/X2qH2NhYnD171uKLLTk5GVqtFkOHDpXKND+HuYz5HK7a3hEREQgODraot9FoxIkTJyzap7S0FKdPn5bKHD58GCaTSfrPOzY2FkePHkV9fb1UJjk5GdHR0fD19ZXKtNWGttSlp7p8+TJu3LiBkJAQAH2vzYQQWLJkCXbt2oXDhw+3GFLsSZ9DW+rS1dprr9akp6cDgMU11lfayxqTyYTa2treeX3ZPO2bOmXHjh1CrVaLbdu2iXPnzomnnnpK+Pj4WMz67w2WLVsmUlJSRF5enjh27JiIj48Xer1eFBcXCyGalmoOGDBAHD58WJw6dUrExsaK2NhY6XjzstGEhASRnp4u9u/fLwICAlpdNrp8+XJx/vx58c4777S6bLQntnd5eblIS0sTaWlpAoD4/e9/L9LS0sQPP/wghGhaXu7j4yP27NkjMjIyxLRp01pNDzB69Ghx4sQJ8dVXX4nBgwdbLHUvLS0VQUFBYs6cOSIzM1Ps2LFDeHp6tljq7ubmJt58801x/vx5sXbt2laXurdXl+7QVpuVl5eLF154QaSmpoq8vDzx3//+V4wZM0YMHjxY1NTUSOfoS222aNEiodPpREpKisVy9qqqKqlMT/octleXrtZee+Xk5IhXXnlFnDp1SuTl5Yk9e/aIyMhIMWHCBOkcfam9hBBi5cqV4osvvhB5eXkiIyNDrFy5UshkMnHw4EGb6uhq7cVAqRtt3rxZDBgwQKhUKnHfffeJ48ePO7tKDjdz5kwREhIiVCqV6Nevn5g5c6bIycmR9ldXV4tf/epXwtfXV3h6eoqf/vSnorCw0OIcly5dElOmTBEeHh5Cr9eLZcuWifr6eosyR44cEaNGjRIqlUpERkaKrVu3tqhLT2zvI0eOCAAtHnPnzhVCNC0x/81vfiOCgoKEWq0WkydPFtnZ2RbnuHHjhpg1a5bQaDRCq9WKJ554QpSXl1uUOXPmjHjggQeEWq0W/fr1E6+//nqLunz88cfirrvuEiqVSgwbNkzs3bvXYr8tdekObbVZVVWVSEhIEAEBAUKpVIrw8HCxYMGCFgFxX2qz1toKgMVnpCd9Dm2pS1dqr73y8/PFhAkThJ+fn1Cr1SIqKkosX77cIo+SEH2nvYQQ4sknnxTh4eFCpVKJgIAAMXnyZClIsrWOrtReMiGEsL3/iYiIiKjv4BwlIiIiIisYKBERERFZwUCJiIiIyAoGSkRERERWMFAiIiIisoKBEhEREZEVDJSIiIiIrGCgRERERGQFAyUicgnz5s3D9OnTnV0NIupj3JxdASIimUzW5v61a9di06ZNcPaNBObNm4fS0lLs3r3bqfUgou7DQImInK6wsFD6/aOPPsKaNWuQnZ0tbdNoNNBoNM6oGhH1cRx6IyKnCw4Olh46nQ4ymcxim0ajaTH0NnHiRDzzzDNYunQpfH19ERQUhL/+9a+orKzEE088AW9vb0RFReHzzz+3eK3MzExMmTIFGo0GQUFBmDNnDq5fvy7t//TTTxETEwMPDw/4+/sjPj4elZWVWLduHbZv3449e/ZAJpNBJpMhJSUFAFBQUIAZM2bAx8cHfn5+mDZtGi5duiSd01z39evXIyAgAFqtFgsXLkRdXV27r0tEzsVAiYhc1vbt26HX63Hy5Ek888wzWLRoER577DHExcXh22+/RUJCAubMmYOqqioAQGlpKX70ox9h9OjROHXqFPbv34+ioiLMmDEDQFPP1qxZs/Dkk0/i/PnzSElJwSOPPAIhBF544QXMmDEDSUlJKCwsRGFhIeLi4lBfX4/ExER4e3vjyy+/xLFjx6DRaJCUlGQRCB06dEg654cffoidO3di/fr17b4uETmZICLqQbZu3Sp0Ol2L7XPnzhXTpk2Tnj/00EPigQcekJ43NDQILy8vMWfOHGlbYWGhACBSU1OFEEK8+uqrIiEhweK8BQUFAoDIzs4Wp0+fFgDEpUuXWq3bnXUQQoh//OMfIjo6WphMJmlbbW2t8PDwEAcOHJCO8/PzE5WVlVKZLVu2CI1GIxobG9t9XSJyHs5RIiKXNWLECOl3hUIBf39/xMTESNuCgoIAAMXFxQCAM2fO4MiRI63Od8rNzUVCQgImT56MmJgYJCYmIiEhAY8++ih8fX2t1uHMmTPIycmBt7e3xfaamhrk5uZKz0eOHAlPT0/peWxsLCoqKlBQUICRI0fa/bpE1D0YKBGRy1IqlRbPZTKZxTbzajqTyQQAqKiowMMPP4zf/e53Lc4VEhIChUKB5ORkfP311zh48CA2b96M1atX48SJE4iIiGi1DhUVFRg7diw++OCDFvsCAgJseh8deV0i6h6co0REfcaYMWOQlZWFgQMHIioqyuLh5eUFoCm4Gj9+PNavX4+0tDSoVCrs2rULAKBSqdDY2NjinBcvXkRgYGCLc+p0OqncmTNnUF1dLT0/fvw4NBoNwsLC2n1dInIeBkpE1GcsXrwYJSUlmDVrFr755hvk5ubiwIEDeOKJJ9DY2IgTJ07gt7/9LU6dOoX8/Hzs3LkT165dw9133w0AGDhwIDIyMpCdnY3r16+jvr4es2fPhl6vx7Rp0/Dll18iLy8PKSkp+PWvf43Lly9Lr11XV4f58+fj3Llz2LdvH9auXYslS5ZALpe3+7pE5DwceiOiPiM0NBTHjh3DihUrkJCQgNraWoSHhyMpKQlyuRxarRZHjx7FH/7wBxiNRoSHh+Ott97ClClTAAALFixASkoK7rnnHlRUVODIkSOYOHEijh49ihUrVuCRRx5BeXk5+vXrh8mTJ0Or1UqvPXnyZAwePBgTJkxAbW0tZs2ahXXr1gFAu69LRM4jE4LrT4mIuhIzehO5Lg69EREREVnBQImIiIjICg69EREREVnBHiUiIiIiKxgoEREREVnBQImIiIjICgZKRERERFYwUCIiIiKygoESERERkRUMlIiIiIisYKBEREREZMX/B8OVaY2EM0PUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agustin/Desktop/CEIA UBA/Aprendizaje por Refuerzo II/CEIA-AprendizajeRefuerzoII/.venv/lib/python3.12/site-packages/gymnasium/envs/box2d/bipedal_walker.py:619: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"BipedalWalker-v3\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = Monitor(gym.make(\"BipedalWalker-v3\"))\n",
    "eval_env = Monitor(gym.make(\"BipedalWalker-v3\"))\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./models/ppo/\",\n",
    "    log_path=\"./logs/ppo/\",\n",
    "    eval_freq=5000,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "best_model_path = os.path.join(model_dir, \"best_model.zip\")\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./ppo_tensorboard/\")\n",
    "model.learn(total_timesteps=300_000, callback=eval_callback)\n",
    "model.save(\"./models/ppo/best_model\")\n",
    "\n",
    "# === Graficar recompensas ===\n",
    "eval_file_npz = \"./logs/ppo/evaluations.npz\"\n",
    "\n",
    "if os.path.exists(eval_file_npz):\n",
    "    data = np.load(eval_file_npz)\n",
    "    timesteps = data[\"timesteps\"]\n",
    "    results = data[\"results\"]\n",
    "\n",
    "    plt.plot(timesteps, results.mean(axis=1), label=\"Evaluación (promedio)\")\n",
    "    plt.fill_between(\n",
    "        timesteps,\n",
    "        results.mean(axis=1) - results.std(axis=1),\n",
    "        results.mean(axis=1) + results.std(axis=1),\n",
    "        alpha=0.2,\n",
    "        label=\"Desvío estándar\",\n",
    "    )\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Recompensa media\")\n",
    "    plt.title(\"Evolución de recompensas - PPO (evaluaciones)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No se encontró evaluations.npz — el callback puede no haber guardado evaluaciones.\")\n",
    "\n",
    "\n",
    "# === Cargar y evaluar ===\n",
    "model = PPO.load(\"./models/ppo/best_model\")\n",
    "obs, _ = env.reset()\n",
    "for step in range(1500):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    if done or truncated:\n",
    "        obs, _ = env.reset()\n",
    "env.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b97f6ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./a2c_tensorboard/A2C_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 833      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.61    |\n",
      "|    explained_variance | 0.334    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -1.81    |\n",
      "|    std                | 0.984    |\n",
      "|    value_loss         | 0.291    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 166      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 840      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.61    |\n",
      "|    explained_variance | -46.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.643    |\n",
      "|    std                | 0.983    |\n",
      "|    value_loss         | 0.0763   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 166      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 844      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.6     |\n",
      "|    explained_variance | -2.71    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.995    |\n",
      "|    std                | 0.98     |\n",
      "|    value_loss         | 0.0573   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 166      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 848      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.54    |\n",
      "|    explained_variance | -6.3     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.77    |\n",
      "|    std                | 0.967    |\n",
      "|    value_loss         | 0.036    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 405      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 849      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.52    |\n",
      "|    explained_variance | -0.0763  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.511    |\n",
      "|    std                | 0.961    |\n",
      "|    value_loss         | 0.0361   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 405      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 850      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.49    |\n",
      "|    explained_variance | 0.306    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.225   |\n",
      "|    std                | 0.954    |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 405      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 850      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.46    |\n",
      "|    explained_variance | 0.328    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.468   |\n",
      "|    std                | 0.948    |\n",
      "|    value_loss         | 0.0122   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 405      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 849      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.42    |\n",
      "|    explained_variance | -4.65    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.358   |\n",
      "|    std                | 0.938    |\n",
      "|    value_loss         | 0.00934  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 575      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 849      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.39    |\n",
      "|    explained_variance | -0.575   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0519  |\n",
      "|    std                | 0.932    |\n",
      "|    value_loss         | 0.00412  |\n",
      "------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-118.26 +/- 3.16\n",
      "Episode length: 1309.60 +/- 580.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.31e+03 |\n",
      "|    mean_reward        | -118     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.36    |\n",
      "|    explained_variance | -0.818   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0782   |\n",
      "|    std                | 0.924    |\n",
      "|    value_loss         | 0.0108   |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | -119     |\n",
      "| time/              |          |\n",
      "|    fps             | 573      |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 5000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 575      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 591      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.36    |\n",
      "|    explained_variance | -0.275   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.362    |\n",
      "|    std                | 0.923    |\n",
      "|    value_loss         | 0.00654  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 704      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 607      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.35    |\n",
      "|    explained_variance | 0.23     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.65     |\n",
      "|    std                | 0.922    |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 704      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 621      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.33    |\n",
      "|    explained_variance | -0.161   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.671    |\n",
      "|    std                | 0.917    |\n",
      "|    value_loss         | 0.0201   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 704      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 633      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.32    |\n",
      "|    explained_variance | -3.3     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.166    |\n",
      "|    std                | 0.915    |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 803      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.32    |\n",
      "|    explained_variance | -1.07    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.324    |\n",
      "|    std                | 0.914    |\n",
      "|    value_loss         | 0.00814  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 803      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.3     |\n",
      "|    explained_variance | 0.209    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -1.46    |\n",
      "|    std                | 0.91     |\n",
      "|    value_loss         | 0.0684   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 803      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.28    |\n",
      "|    explained_variance | 0.848    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -1.58    |\n",
      "|    std                | 0.906    |\n",
      "|    value_loss         | 0.0984   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 883      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.28    |\n",
      "|    explained_variance | 0.593    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.601    |\n",
      "|    std                | 0.905    |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 883      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.26    |\n",
      "|    explained_variance | -0.303   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -1.3     |\n",
      "|    std                | 0.903    |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-57.08 +/- 4.06\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -57.1    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.23    |\n",
      "|    explained_variance | -0.814   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.266   |\n",
      "|    std                | 0.896    |\n",
      "|    value_loss         | 0.00459  |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 883      |\n",
      "|    ep_rew_mean     | -114     |\n",
      "| time/              |          |\n",
      "|    fps             | 556      |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 948      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.2     |\n",
      "|    explained_variance | 0.614    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.549   |\n",
      "|    std                | 0.888    |\n",
      "|    value_loss         | 0.0194   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 879      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 575      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.16    |\n",
      "|    explained_variance | 0.291    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.166   |\n",
      "|    std                | 0.88     |\n",
      "|    value_loss         | 0.00212  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 879      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 584      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.14    |\n",
      "|    explained_variance | 0.193    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.477    |\n",
      "|    std                | 0.874    |\n",
      "|    value_loss         | 0.0137   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 879      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.1     |\n",
      "|    explained_variance | 0.146    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -1.72    |\n",
      "|    std                | 0.865    |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 889      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 599      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.07    |\n",
      "|    explained_variance | -0.513   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 3.73     |\n",
      "|    std                | 0.86     |\n",
      "|    value_loss         | 0.747    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 889      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 606      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.05    |\n",
      "|    explained_variance | -0.00702 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.818   |\n",
      "|    std                | 0.855    |\n",
      "|    value_loss         | 0.0339   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 889      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 613      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.03    |\n",
      "|    explained_variance | -0.262   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.859    |\n",
      "|    std                | 0.851    |\n",
      "|    value_loss         | 0.0353   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 889      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 619      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5       |\n",
      "|    explained_variance | -1.87    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.237    |\n",
      "|    std                | 0.844    |\n",
      "|    value_loss         | 0.00698  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 936      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 625      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.96    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.341   |\n",
      "|    std                | 0.837    |\n",
      "|    value_loss         | 0.00884  |\n",
      "------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-28.66 +/- 5.06\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -28.7    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.94    |\n",
      "|    explained_variance | -0.501   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.838    |\n",
      "|    std                | 0.833    |\n",
      "|    value_loss         | 0.0354   |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 936      |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    fps             | 550      |\n",
      "|    iterations      | 3000     |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 15000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 936      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.89    |\n",
      "|    explained_variance | -2.99    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.849    |\n",
      "|    std                | 0.823    |\n",
      "|    value_loss         | 0.0323   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 926      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.86    |\n",
      "|    explained_variance | -0.298   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0519  |\n",
      "|    std                | 0.817    |\n",
      "|    value_loss         | 0.00421  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 926      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.83    |\n",
      "|    explained_variance | -0.875   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.102   |\n",
      "|    std                | 0.81     |\n",
      "|    value_loss         | 0.0117   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 926      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.82    |\n",
      "|    explained_variance | 0.325    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -1.25    |\n",
      "|    std                | 0.808    |\n",
      "|    value_loss         | 0.0561   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 874      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.81    |\n",
      "|    explained_variance | -0.218   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.0131  |\n",
      "|    std                | 0.805    |\n",
      "|    value_loss         | 0.0169   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 718      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.79    |\n",
      "|    explained_variance | -2.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 2.37     |\n",
      "|    std                | 0.803    |\n",
      "|    value_loss         | 0.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 544      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 587      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.81    |\n",
      "|    explained_variance | 0.842    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.589   |\n",
      "|    std                | 0.805    |\n",
      "|    value_loss         | 0.0144   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 483      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.78    |\n",
      "|    explained_variance | -0.353   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.544   |\n",
      "|    std                | 0.8      |\n",
      "|    value_loss         | 0.0211   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 483      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 597      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.76    |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.312    |\n",
      "|    std                | 0.796    |\n",
      "|    value_loss         | 0.0057   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-98.96 +/- 0.25\n",
      "Episode length: 144.80 +/- 4.49\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 145      |\n",
      "|    mean_reward        | -99      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.72    |\n",
      "|    explained_variance | -0.218   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.914   |\n",
      "|    std                | 0.789    |\n",
      "|    value_loss         | 0.0343   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 483      |\n",
      "|    ep_rew_mean     | -103     |\n",
      "| time/              |          |\n",
      "|    fps             | 595      |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 500      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 600      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.68    |\n",
      "|    explained_variance | 0.294    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.388   |\n",
      "|    std                | 0.782    |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 446      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 604      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 0.748    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.0438  |\n",
      "|    std                | 0.783    |\n",
      "|    value_loss         | 0.00562  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 405      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 608      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.72    |\n",
      "|    explained_variance | -29.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.602    |\n",
      "|    std                | 0.789    |\n",
      "|    value_loss         | 0.0743   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 360      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 612      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | -38.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -2.36    |\n",
      "|    std                | 0.784    |\n",
      "|    value_loss         | 0.538    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 325      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 616      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 0.414    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 1.74     |\n",
      "|    std                | 0.783    |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 298      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 619      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.7     |\n",
      "|    explained_variance | -8.7     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -2.68    |\n",
      "|    std                | 0.784    |\n",
      "|    value_loss         | 0.435    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 282      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 623      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.71    |\n",
      "|    explained_variance | -2.38    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 5.52     |\n",
      "|    std                | 0.786    |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 266      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 626      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | -34.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 5.22     |\n",
      "|    std                | 0.783    |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 266      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 630      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.66    |\n",
      "|    explained_variance | -6.27    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.936    |\n",
      "|    std                | 0.775    |\n",
      "|    value_loss         | 0.0964   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-111.63 +/- 0.06\n",
      "Episode length: 46.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 46       |\n",
      "|    mean_reward        | -112     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.63    |\n",
      "|    explained_variance | 0.321    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.0456   |\n",
      "|    std                | 0.771    |\n",
      "|    value_loss         | 0.00039  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 266      |\n",
      "|    ep_rew_mean     | -104     |\n",
      "| time/              |          |\n",
      "|    fps             | 632      |\n",
      "|    iterations      | 5000     |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 25000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 266      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 635      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.57    |\n",
      "|    explained_variance | 0.355    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.00815 |\n",
      "|    std                | 0.759    |\n",
      "|    value_loss         | 0.004    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.51    |\n",
      "|    explained_variance | 0.191    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.339    |\n",
      "|    std                | 0.748    |\n",
      "|    value_loss         | 0.0158   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.47    |\n",
      "|    explained_variance | 0.0819   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.0778  |\n",
      "|    std                | 0.741    |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.42    |\n",
      "|    explained_variance | -1.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.561   |\n",
      "|    std                | 0.731    |\n",
      "|    value_loss         | 0.0377   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 295      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 647      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.36    |\n",
      "|    explained_variance | -0.435   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.339   |\n",
      "|    std                | 0.722    |\n",
      "|    value_loss         | 0.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 295      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 650      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.35    |\n",
      "|    explained_variance | -53.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.248   |\n",
      "|    std                | 0.718    |\n",
      "|    value_loss         | 0.00643  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 295      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.33    |\n",
      "|    explained_variance | 0.667    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.029   |\n",
      "|    std                | 0.715    |\n",
      "|    value_loss         | 0.00398  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 655      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.3     |\n",
      "|    explained_variance | -0.522   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.699   |\n",
      "|    std                | 0.712    |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 270      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 658      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.31    |\n",
      "|    explained_variance | 0.541    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.599    |\n",
      "|    std                | 0.712    |\n",
      "|    value_loss         | 0.0344   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-99.09 +/- 1.66\n",
      "Episode length: 683.00 +/- 748.73\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 683      |\n",
      "|    mean_reward        | -99.1    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.3     |\n",
      "|    explained_variance | -0.0191  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -1.1     |\n",
      "|    std                | 0.711    |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | -104     |\n",
      "| time/              |          |\n",
      "|    fps             | 639      |\n",
      "|    iterations      | 6000     |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 164      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.29    |\n",
      "|    explained_variance | 0.777    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.342    |\n",
      "|    std                | 0.71     |\n",
      "|    value_loss         | 0.008    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 134      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.25    |\n",
      "|    explained_variance | 0.34     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 1.79     |\n",
      "|    std                | 0.703    |\n",
      "|    value_loss         | 0.171    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 137      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 646      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.22    |\n",
      "|    explained_variance | -0.39    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.346   |\n",
      "|    std                | 0.698    |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 137      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 648      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.17    |\n",
      "|    explained_variance | 0.809    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.584    |\n",
      "|    std                | 0.69     |\n",
      "|    value_loss         | 0.0217   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 145      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.13    |\n",
      "|    explained_variance | 0.353    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0.119   |\n",
      "|    std                | 0.682    |\n",
      "|    value_loss         | 0.0302   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 146      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.14    |\n",
      "|    explained_variance | -2.75    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 0.684    |\n",
      "|    value_loss         | 0.295    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 655      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.11    |\n",
      "|    explained_variance | 0.0143   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 1.25     |\n",
      "|    std                | 0.679    |\n",
      "|    value_loss         | 0.171    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.08    |\n",
      "|    explained_variance | 0.0241   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0.779   |\n",
      "|    std                | 0.674    |\n",
      "|    value_loss         | 0.0686   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 659      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.06    |\n",
      "|    explained_variance | -4.62    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 1.54     |\n",
      "|    std                | 0.672    |\n",
      "|    value_loss         | 0.33     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-65.05 +/- 35.37\n",
      "Episode length: 585.80 +/- 521.58\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 586      |\n",
      "|    mean_reward        | -65.1    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.07    |\n",
      "|    explained_variance | -57.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.363   |\n",
      "|    std                | 0.673    |\n",
      "|    value_loss         | 0.0807   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 163      |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 645      |\n",
      "|    iterations      | 7000     |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 35000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 648      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.05    |\n",
      "|    explained_variance | 0.632    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -5.97    |\n",
      "|    std                | 0.67     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 650      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.05    |\n",
      "|    explained_variance | -0.799   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 0.658    |\n",
      "|    std                | 0.669    |\n",
      "|    value_loss         | 0.0674   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 652      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.04    |\n",
      "|    explained_variance | 0.13     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 0.668    |\n",
      "|    value_loss         | 0.0793   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.04    |\n",
      "|    explained_variance | -2.49    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.604    |\n",
      "|    std                | 0.668    |\n",
      "|    value_loss         | 0.0657   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 165      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 656      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4       |\n",
      "|    explained_variance | 0.163    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -306     |\n",
      "|    std                | 0.662    |\n",
      "|    value_loss         | 6.21e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 168      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 658      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 0.882    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.245   |\n",
      "|    std                | 0.661    |\n",
      "|    value_loss         | 0.00437  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 170      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 660      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.97    |\n",
      "|    explained_variance | -8.32    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.271    |\n",
      "|    std                | 0.657    |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 172      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 662      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.96    |\n",
      "|    explained_variance | -0.649   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -2.31    |\n",
      "|    std                | 0.657    |\n",
      "|    value_loss         | 0.309    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 174      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 663      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.94    |\n",
      "|    explained_variance | -14.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -2.28    |\n",
      "|    std                | 0.653    |\n",
      "|    value_loss         | 0.254    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-7.23 +/- 45.96\n",
      "Episode length: 1301.20 +/- 597.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.3e+03  |\n",
      "|    mean_reward        | -7.23    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.92    |\n",
      "|    explained_variance | -7.37    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    std                | 0.651    |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 176      |\n",
      "|    ep_rew_mean     | -103     |\n",
      "| time/              |          |\n",
      "|    fps             | 635      |\n",
      "|    iterations      | 8000     |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 176      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 636      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.91    |\n",
      "|    explained_variance | 0.175    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -1.2     |\n",
      "|    std                | 0.648    |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 176      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.9     |\n",
      "|    explained_variance | -0.413   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -0.616   |\n",
      "|    std                | 0.646    |\n",
      "|    value_loss         | 0.0484   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 191      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.87    |\n",
      "|    explained_variance | 0.8      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.68    |\n",
      "|    std                | 0.641    |\n",
      "|    value_loss         | 0.028    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 195      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 641      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.85    |\n",
      "|    explained_variance | 0.645    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.607   |\n",
      "|    std                | 0.639    |\n",
      "|    value_loss         | 0.0786   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 196      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 643      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.84    |\n",
      "|    explained_variance | -1.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 0.637    |\n",
      "|    value_loss         | 0.169    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 196      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 645      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.84    |\n",
      "|    explained_variance | -3.27    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.159    |\n",
      "|    std                | 0.636    |\n",
      "|    value_loss         | 0.0079   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 204      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 647      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.82    |\n",
      "|    explained_variance | -5.1     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 0.439    |\n",
      "|    std                | 0.633    |\n",
      "|    value_loss         | 0.0199   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 204      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 648      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.8     |\n",
      "|    explained_variance | 0.199    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.2     |\n",
      "|    std                | 0.631    |\n",
      "|    value_loss         | 0.0143   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 218      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 650      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.78    |\n",
      "|    explained_variance | -0.0911  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    std                | 0.627    |\n",
      "|    value_loss         | 0.084    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-107.61 +/- 0.06\n",
      "Episode length: 47.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 47       |\n",
      "|    mean_reward        | -108     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.79    |\n",
      "|    explained_variance | 0.079    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -0.664   |\n",
      "|    std                | 0.629    |\n",
      "|    value_loss         | 0.0398   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 218      |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    fps             | 651      |\n",
      "|    iterations      | 9000     |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 45000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 219      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 652      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.79    |\n",
      "|    explained_variance | 0.455    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 0.878    |\n",
      "|    std                | 0.629    |\n",
      "|    value_loss         | 0.049    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 219      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.76    |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.0297  |\n",
      "|    std                | 0.625    |\n",
      "|    value_loss         | 0.0265   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 219      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 656      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.71    |\n",
      "|    explained_variance | -1.71    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.541   |\n",
      "|    std                | 0.617    |\n",
      "|    value_loss         | 0.0231   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 233      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.69    |\n",
      "|    explained_variance | -0.696   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -1.77    |\n",
      "|    std                | 0.613    |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 187      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 659      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.68    |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.371    |\n",
      "|    std                | 0.612    |\n",
      "|    value_loss         | 0.0179   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 189      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.67    |\n",
      "|    explained_variance | -3.46    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 2.37     |\n",
      "|    std                | 0.611    |\n",
      "|    value_loss         | 0.458    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 193      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 662      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.65    |\n",
      "|    explained_variance | -1.8     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.582   |\n",
      "|    std                | 0.607    |\n",
      "|    value_loss         | 0.0254   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 198      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.62    |\n",
      "|    explained_variance | -15.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -1.83    |\n",
      "|    std                | 0.603    |\n",
      "|    value_loss         | 0.235    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 202      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 665      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.6     |\n",
      "|    explained_variance | 0.942    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0.71    |\n",
      "|    std                | 0.6      |\n",
      "|    value_loss         | 0.0236   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-131.03 +/- 1.02\n",
      "Episode length: 177.20 +/- 11.82\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 177      |\n",
      "|    mean_reward        | -131     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.6     |\n",
      "|    explained_variance | -2.17    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.0968  |\n",
      "|    std                | 0.601    |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 202      |\n",
      "|    ep_rew_mean     | -101     |\n",
      "| time/              |          |\n",
      "|    fps             | 663      |\n",
      "|    iterations      | 10000    |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 202      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 665      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.57    |\n",
      "|    explained_variance | -0.718   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -0.163   |\n",
      "|    std                | 0.597    |\n",
      "|    value_loss         | 0.023    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 202      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 666      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.54    |\n",
      "|    explained_variance | 0.771    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.0928   |\n",
      "|    std                | 0.592    |\n",
      "|    value_loss         | 0.00292  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 217      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 667      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.52    |\n",
      "|    explained_variance | -0.736   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.0217  |\n",
      "|    std                | 0.589    |\n",
      "|    value_loss         | 0.00156  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 224      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 669      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | 0.497    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -0.61    |\n",
      "|    std                | 0.588    |\n",
      "|    value_loss         | 0.0758   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 226      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 670      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | -0.984   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 1.54     |\n",
      "|    std                | 0.589    |\n",
      "|    value_loss         | 0.296    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 225      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 671      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.52    |\n",
      "|    explained_variance | -3.81    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 4.3      |\n",
      "|    std                | 0.589    |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 222      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.52    |\n",
      "|    explained_variance | -0.467   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.169    |\n",
      "|    std                | 0.59     |\n",
      "|    value_loss         | 0.00614  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 215      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | -5.64    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 2.11     |\n",
      "|    std                | 0.587    |\n",
      "|    value_loss         | 0.692    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 215      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.49    |\n",
      "|    explained_variance | 0.179    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.0644   |\n",
      "|    std                | 0.585    |\n",
      "|    value_loss         | 0.158    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-94.08 +/- 8.35\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -94.1    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.48    |\n",
      "|    explained_variance | -3.33    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.0483  |\n",
      "|    std                | 0.584    |\n",
      "|    value_loss         | 0.00376  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | -99.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 648      |\n",
      "|    iterations      | 11000    |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 55000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 208      |\n",
      "|    ep_rew_mean        | -99.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 649      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.47    |\n",
      "|    explained_variance | -1.72    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 0.0261   |\n",
      "|    std                | 0.583    |\n",
      "|    value_loss         | 0.000923 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 208      |\n",
      "|    ep_rew_mean        | -99.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 650      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.44    |\n",
      "|    explained_variance | -23.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.858    |\n",
      "|    std                | 0.579    |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 223      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.43    |\n",
      "|    explained_variance | 0.13     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    std                | 0.577    |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 223      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.43    |\n",
      "|    explained_variance | -3.78    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.187   |\n",
      "|    std                | 0.578    |\n",
      "|    value_loss         | 0.0111   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 230      |\n",
      "|    ep_rew_mean        | -99.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.4     |\n",
      "|    explained_variance | 0.125    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.00351  |\n",
      "|    std                | 0.574    |\n",
      "|    value_loss         | 0.0269   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 230      |\n",
      "|    ep_rew_mean        | -99.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 656      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.38    |\n",
      "|    explained_variance | 0.885    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 0.0233   |\n",
      "|    std                | 0.57     |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 235      |\n",
      "|    ep_rew_mean        | -99.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.34    |\n",
      "|    explained_variance | -3.11    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 0.565    |\n",
      "|    value_loss         | 0.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 235      |\n",
      "|    ep_rew_mean        | -99.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 658      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.34    |\n",
      "|    explained_variance | 0.634    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 0.591    |\n",
      "|    std                | 0.565    |\n",
      "|    value_loss         | 0.0555   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 241      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 659      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | -8.37    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.73     |\n",
      "|    std                | 0.564    |\n",
      "|    value_loss         | 0.0821   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-116.46 +/- 5.67\n",
      "Episode length: 128.00 +/- 31.40\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 128      |\n",
      "|    mean_reward        | -116     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | -2.96    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -2.28    |\n",
      "|    std                | 0.564    |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 245      |\n",
      "|    ep_rew_mean     | -99.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 659      |\n",
      "|    iterations      | 12000    |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 245      |\n",
      "|    ep_rew_mean        | -99.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 660      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.34    |\n",
      "|    explained_variance | -0.246   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 0.903    |\n",
      "|    std                | 0.565    |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 235      |\n",
      "|    ep_rew_mean        | -99.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.34    |\n",
      "|    explained_variance | 0.876    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -0.487   |\n",
      "|    std                | 0.566    |\n",
      "|    value_loss         | 0.0356   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 232      |\n",
      "|    ep_rew_mean        | -99.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 662      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.32    |\n",
      "|    explained_variance | 0.354    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -1.34    |\n",
      "|    std                | 0.563    |\n",
      "|    value_loss         | 0.152    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 236      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 663      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | -3.87    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.499    |\n",
      "|    std                | 0.564    |\n",
      "|    value_loss         | 0.0569   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 236      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 665      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.31    |\n",
      "|    explained_variance | -6.07    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.152   |\n",
      "|    std                | 0.561    |\n",
      "|    value_loss         | 0.0564   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 236      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 666      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.3     |\n",
      "|    explained_variance | 0.515    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.53    |\n",
      "|    std                | 0.561    |\n",
      "|    value_loss         | 0.0357   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 247      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 667      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.26    |\n",
      "|    explained_variance | -0.0488  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 0.699    |\n",
      "|    std                | 0.556    |\n",
      "|    value_loss         | 0.0542   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 247      |\n",
      "|    ep_rew_mean        | -99.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 668      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.23    |\n",
      "|    explained_variance | 0.136    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.198    |\n",
      "|    std                | 0.553    |\n",
      "|    value_loss         | 0.00979  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 258      |\n",
      "|    ep_rew_mean        | -99.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 670      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.17    |\n",
      "|    explained_variance | 0.731    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    std                | 0.545    |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-106.38 +/- 0.06\n",
      "Episode length: 47.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 47       |\n",
      "|    mean_reward        | -106     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | -105     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 0.742    |\n",
      "|    std                | 0.545    |\n",
      "|    value_loss         | 0.0487   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | -99.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 670      |\n",
      "|    iterations      | 13000    |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 65000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 260      |\n",
      "|    ep_rew_mean        | -99.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 671      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | -0.575   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    std                | 0.543    |\n",
      "|    value_loss         | 0.145    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 260      |\n",
      "|    ep_rew_mean        | -99.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.12    |\n",
      "|    explained_variance | -3.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.186   |\n",
      "|    std                | 0.538    |\n",
      "|    value_loss         | 0.0102   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 268      |\n",
      "|    ep_rew_mean        | -99.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.12    |\n",
      "|    explained_variance | -0.0284  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 0.454    |\n",
      "|    std                | 0.539    |\n",
      "|    value_loss         | 0.0543   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 251      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.14    |\n",
      "|    explained_variance | -2.92    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -1.36    |\n",
      "|    std                | 0.541    |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 244      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 676      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | -0.474   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 0.111    |\n",
      "|    std                | 0.543    |\n",
      "|    value_loss         | 0.0255   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 231      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | -0.417   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -2.61    |\n",
      "|    std                | 0.543    |\n",
      "|    value_loss         | 0.559    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 235      |\n",
      "|    ep_rew_mean        | -99.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.14    |\n",
      "|    explained_variance | -3.16    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 0.431    |\n",
      "|    std                | 0.541    |\n",
      "|    value_loss         | 0.0567   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 237      |\n",
      "|    ep_rew_mean        | -99.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | -155     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -1.24    |\n",
      "|    std                | 0.54     |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 237      |\n",
      "|    ep_rew_mean        | -99.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.12    |\n",
      "|    explained_variance | -0.984   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -0.454   |\n",
      "|    std                | 0.539    |\n",
      "|    value_loss         | 0.0436   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-120.00 +/- 2.76\n",
      "Episode length: 127.40 +/- 11.57\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 127      |\n",
      "|    mean_reward        | -120     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | -1.18    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    std                | 0.544    |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 231      |\n",
      "|    ep_rew_mean     | -99.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 679      |\n",
      "|    iterations      | 14000    |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 70000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 234      |\n",
      "|    ep_rew_mean        | -99.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.16    |\n",
      "|    explained_variance | -7.67    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.398   |\n",
      "|    std                | 0.545    |\n",
      "|    value_loss         | 0.0163   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 233      |\n",
      "|    ep_rew_mean        | -99.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | -0.202   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -0.7     |\n",
      "|    std                | 0.543    |\n",
      "|    value_loss         | 0.092    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 230      |\n",
      "|    ep_rew_mean        | -99.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0.656    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0.214   |\n",
      "|    std                | 0.541    |\n",
      "|    value_loss         | 0.0188   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 233      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.12    |\n",
      "|    explained_variance | -0.513   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 0.572    |\n",
      "|    std                | 0.538    |\n",
      "|    value_loss         | 0.0928   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 233      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | -5.38    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    std                | 0.536    |\n",
      "|    value_loss         | 0.336    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 233      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.09    |\n",
      "|    explained_variance | 0.0381   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.0751  |\n",
      "|    std                | 0.534    |\n",
      "|    value_loss         | 0.0196   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 246      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.09    |\n",
      "|    explained_variance | -2.3     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 0.986    |\n",
      "|    std                | 0.534    |\n",
      "|    value_loss         | 0.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 687      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | -14.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -0.395   |\n",
      "|    std                | 0.532    |\n",
      "|    value_loss         | 0.0322   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 250      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | -0.362   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 0.481    |\n",
      "|    std                | 0.531    |\n",
      "|    value_loss         | 0.0617   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-96.31 +/- 1.39\n",
      "Episode length: 108.60 +/- 16.21\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 109      |\n",
      "|    mean_reward        | -96.3    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0.948    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 0.041    |\n",
      "|    std                | 0.538    |\n",
      "|    value_loss         | 0.00674  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 231      |\n",
      "|    ep_rew_mean     | -101     |\n",
      "| time/              |          |\n",
      "|    fps             | 687      |\n",
      "|    iterations      | 15000    |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 75000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 231      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0.634    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -0.355   |\n",
      "|    std                | 0.541    |\n",
      "|    value_loss         | 0.0153   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 231      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.1     |\n",
      "|    explained_variance | -3.35    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    std                | 0.537    |\n",
      "|    value_loss         | 0.202    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 241      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | -0.258   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 0.752    |\n",
      "|    std                | 0.535    |\n",
      "|    value_loss         | 0.141    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.06    |\n",
      "|    explained_variance | -1.86    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 0.768    |\n",
      "|    std                | 0.533    |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0.433    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -0.0813  |\n",
      "|    std                | 0.529    |\n",
      "|    value_loss         | 0.00215  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | -1.62    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.332   |\n",
      "|    std                | 0.531    |\n",
      "|    value_loss         | 0.045    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | -99.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | -0.395   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 0.689    |\n",
      "|    std                | 0.533    |\n",
      "|    value_loss         | 0.0965   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 258      |\n",
      "|    ep_rew_mean        | -99.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 694      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0.316    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.495    |\n",
      "|    std                | 0.534    |\n",
      "|    value_loss         | 0.0536   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 262      |\n",
      "|    ep_rew_mean        | -99.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 695      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | -0.32    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -2.7     |\n",
      "|    std                | 0.533    |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-72.27 +/- 17.06\n",
      "Episode length: 999.00 +/- 736.07\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 999      |\n",
      "|    mean_reward        | -72.3    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | -5.96    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 0.347    |\n",
      "|    std                | 0.531    |\n",
      "|    value_loss         | 0.0245   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 262      |\n",
      "|    ep_rew_mean     | -99.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 682      |\n",
      "|    iterations      | 16000    |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 262      |\n",
      "|    ep_rew_mean        | -99.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | -27.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -0.234   |\n",
      "|    std                | 0.525    |\n",
      "|    value_loss         | 0.0935   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | -98.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 0.677    |\n",
      "|    std                | 0.525    |\n",
      "|    value_loss         | 0.0685   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | -98.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -0.779   |\n",
      "|    std                | 0.528    |\n",
      "|    value_loss         | 0.0567   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -99      |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0.153    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -0.09    |\n",
      "|    std                | 0.524    |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | -99.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 687      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | -1.88    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -2       |\n",
      "|    std                | 0.521    |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | -99.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | -1.61    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -0.112   |\n",
      "|    std                | 0.52     |\n",
      "|    value_loss         | 0.00463  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | -99.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | -0.457   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.16     |\n",
      "|    std                | 0.516    |\n",
      "|    value_loss         | 0.00547  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | -99      |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | -0.179   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 0.331    |\n",
      "|    std                | 0.514    |\n",
      "|    value_loss         | 0.0306   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | -99      |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0.78     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.254    |\n",
      "|    std                | 0.507    |\n",
      "|    value_loss         | 0.0203   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-120.30 +/- 1.24\n",
      "Episode length: 81.20 +/- 4.66\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 81.2     |\n",
      "|    mean_reward        | -120     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | -0.781   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 0.589    |\n",
      "|    std                | 0.506    |\n",
      "|    value_loss         | 0.0592   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 264      |\n",
      "|    ep_rew_mean     | -98.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 690      |\n",
      "|    iterations      | 17000    |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 85000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | -98.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | 0.891    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 0.315    |\n",
      "|    std                | 0.505    |\n",
      "|    value_loss         | 0.0354   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | -98.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | -5.36    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.947   |\n",
      "|    std                | 0.503    |\n",
      "|    value_loss         | 0.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 256      |\n",
      "|    ep_rew_mean        | -98.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.8     |\n",
      "|    explained_variance | -0.111   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 0.502    |\n",
      "|    value_loss         | 0.159    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 265      |\n",
      "|    ep_rew_mean        | -98.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.77    |\n",
      "|    explained_variance | -6.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -0.808   |\n",
      "|    std                | 0.499    |\n",
      "|    value_loss         | 0.036    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | -98.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 694      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.76    |\n",
      "|    explained_variance | 0.569    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    std                | 0.498    |\n",
      "|    value_loss         | 0.476    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 269      |\n",
      "|    ep_rew_mean        | -98.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 695      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.75    |\n",
      "|    explained_variance | -105     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -0.0286  |\n",
      "|    std                | 0.497    |\n",
      "|    value_loss         | 0.0984   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | -98      |\n",
      "| time/                 |          |\n",
      "|    fps                | 696      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.75    |\n",
      "|    explained_variance | -2.81    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    std                | 0.496    |\n",
      "|    value_loss         | 0.241    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | -98      |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.75    |\n",
      "|    explained_variance | -9.21    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -0.191   |\n",
      "|    std                | 0.496    |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | -98      |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.75    |\n",
      "|    explained_variance | -1.58    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -0.53    |\n",
      "|    std                | 0.497    |\n",
      "|    value_loss         | 0.0494   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-81.08 +/- 2.93\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -81.1    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.73    |\n",
      "|    explained_variance | -38.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 1.35     |\n",
      "|    std                | 0.494    |\n",
      "|    value_loss         | 0.569    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 283      |\n",
      "|    ep_rew_mean     | -97.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 680      |\n",
      "|    iterations      | 18000    |\n",
      "|    time_elapsed    | 132      |\n",
      "|    total_timesteps | 90000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 283      |\n",
      "|    ep_rew_mean        | -97.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.71    |\n",
      "|    explained_variance | 0.655    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 0.0038   |\n",
      "|    std                | 0.493    |\n",
      "|    value_loss         | 0.000883 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 283      |\n",
      "|    ep_rew_mean        | -97.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.73    |\n",
      "|    explained_variance | -1.01    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -0.317   |\n",
      "|    std                | 0.496    |\n",
      "|    value_loss         | 0.0253   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 283      |\n",
      "|    ep_rew_mean        | -97.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.7     |\n",
      "|    explained_variance | 0.116    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.108    |\n",
      "|    std                | 0.493    |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 297      |\n",
      "|    ep_rew_mean        | -97.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.7     |\n",
      "|    explained_variance | 0.516    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 0.382    |\n",
      "|    std                | 0.492    |\n",
      "|    value_loss         | 0.0309   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 297      |\n",
      "|    ep_rew_mean        | -97.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.68    |\n",
      "|    explained_variance | -7.01    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 0.149    |\n",
      "|    std                | 0.491    |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 297      |\n",
      "|    ep_rew_mean        | -97.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.65    |\n",
      "|    explained_variance | 0.589    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -0.236   |\n",
      "|    std                | 0.488    |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 301      |\n",
      "|    ep_rew_mean        | -96.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.62    |\n",
      "|    explained_variance | 0.0184   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -0.422   |\n",
      "|    std                | 0.485    |\n",
      "|    value_loss         | 0.0602   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 301      |\n",
      "|    ep_rew_mean        | -96.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.62    |\n",
      "|    explained_variance | -0.985   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 0.107    |\n",
      "|    std                | 0.485    |\n",
      "|    value_loss         | 0.0109   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 301      |\n",
      "|    ep_rew_mean        | -96.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.6     |\n",
      "|    explained_variance | -20.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.659   |\n",
      "|    std                | 0.483    |\n",
      "|    value_loss         | 0.0949   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-29.36 +/- 37.45\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -29.4    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.58    |\n",
      "|    explained_variance | -24.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 0.266    |\n",
      "|    std                | 0.481    |\n",
      "|    value_loss         | 0.0373   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 305      |\n",
      "|    ep_rew_mean     | -95.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 670      |\n",
      "|    iterations      | 19000    |\n",
      "|    time_elapsed    | 141      |\n",
      "|    total_timesteps | 95000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | -95.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 671      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.57    |\n",
      "|    explained_variance | -2.13    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 1.85     |\n",
      "|    std                | 0.48     |\n",
      "|    value_loss         | 0.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 315      |\n",
      "|    ep_rew_mean        | -95.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.57    |\n",
      "|    explained_variance | 0.319    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -0.33    |\n",
      "|    std                | 0.48     |\n",
      "|    value_loss         | 0.0385   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | -95.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.56    |\n",
      "|    explained_variance | -1.15    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 1.22     |\n",
      "|    std                | 0.478    |\n",
      "|    value_loss         | 0.246    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 312      |\n",
      "|    ep_rew_mean        | -95.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | -0.753   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -0.474   |\n",
      "|    std                | 0.474    |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | -95.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | -3.39    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 0.474    |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | -94.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | 0.905    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.0189  |\n",
      "|    std                | 0.474    |\n",
      "|    value_loss         | 0.00768  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 315      |\n",
      "|    ep_rew_mean        | -94.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.51    |\n",
      "|    explained_variance | -2.56    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -2.16    |\n",
      "|    std                | 0.472    |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 319      |\n",
      "|    ep_rew_mean        | -94.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.51    |\n",
      "|    explained_variance | 0.493    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -0.00594 |\n",
      "|    std                | 0.472    |\n",
      "|    value_loss         | 0.019    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 320      |\n",
      "|    ep_rew_mean        | -93.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 676      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.51    |\n",
      "|    explained_variance | -11      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -9.48    |\n",
      "|    std                | 0.473    |\n",
      "|    value_loss         | 14.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-111.78 +/- 0.73\n",
      "Episode length: 60.60 +/- 1.62\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 60.6     |\n",
      "|    mean_reward        | -112     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | -0.347   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.879   |\n",
      "|    std                | 0.475    |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | -94      |\n",
      "| time/              |          |\n",
      "|    fps             | 676      |\n",
      "|    iterations      | 20000    |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 306      |\n",
      "|    ep_rew_mean        | -94.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 676      |\n",
      "|    iterations         | 20100    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 100500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | -0.909   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20099    |\n",
      "|    policy_loss        | -0.254   |\n",
      "|    std                | 0.476    |\n",
      "|    value_loss         | 0.0275   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 308      |\n",
      "|    ep_rew_mean        | -93.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 20200    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 101000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | 0.793    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20199    |\n",
      "|    policy_loss        | -0.316   |\n",
      "|    std                | 0.477    |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 310      |\n",
      "|    ep_rew_mean        | -93.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 20300    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 101500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.55    |\n",
      "|    explained_variance | -1.89    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20299    |\n",
      "|    policy_loss        | 3.07     |\n",
      "|    std                | 0.479    |\n",
      "|    value_loss         | 0.844    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 310      |\n",
      "|    ep_rew_mean        | -93.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 20400    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 102000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.55    |\n",
      "|    explained_variance | -72.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20399    |\n",
      "|    policy_loss        | 0.979    |\n",
      "|    std                | 0.479    |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 317      |\n",
      "|    ep_rew_mean        | -92.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 20500    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 102500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.53    |\n",
      "|    explained_variance | -21.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20499    |\n",
      "|    policy_loss        | 0.325    |\n",
      "|    std                | 0.476    |\n",
      "|    value_loss         | 0.137    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 321      |\n",
      "|    ep_rew_mean        | -92      |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 20600    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 103000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.52    |\n",
      "|    explained_variance | -12.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20599    |\n",
      "|    policy_loss        | 3.65     |\n",
      "|    std                | 0.476    |\n",
      "|    value_loss         | 3.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | -91.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 20700    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 103500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.51    |\n",
      "|    explained_variance | 0.454    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20699    |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    std                | 0.474    |\n",
      "|    value_loss         | 0.278    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | -91.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 20800    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 104000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | -11.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20799    |\n",
      "|    policy_loss        | 0.0762   |\n",
      "|    std                | 0.473    |\n",
      "|    value_loss         | 0.0366   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | -91.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 20900    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 104500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.51    |\n",
      "|    explained_variance | -10.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20899    |\n",
      "|    policy_loss        | -0.709   |\n",
      "|    std                | 0.475    |\n",
      "|    value_loss         | 0.336    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=163.19 +/- 59.42\n",
      "Episode length: 1505.20 +/- 189.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.51e+03 |\n",
      "|    mean_reward        | 163      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 105000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.49    |\n",
      "|    explained_variance | 0.846    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20999    |\n",
      "|    policy_loss        | 0.248    |\n",
      "|    std                | 0.473    |\n",
      "|    value_loss         | 0.035    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 342      |\n",
      "|    ep_rew_mean     | -88.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 668      |\n",
      "|    iterations      | 21000    |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 105000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 342      |\n",
      "|    ep_rew_mean        | -88.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 669      |\n",
      "|    iterations         | 21100    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 105500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.49    |\n",
      "|    explained_variance | 0.795    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21099    |\n",
      "|    policy_loss        | 0.184    |\n",
      "|    std                | 0.473    |\n",
      "|    value_loss         | 0.00845  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 342      |\n",
      "|    ep_rew_mean        | -88.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 670      |\n",
      "|    iterations         | 21200    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 106000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.49    |\n",
      "|    explained_variance | 0.572    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21199    |\n",
      "|    policy_loss        | 0.586    |\n",
      "|    std                | 0.471    |\n",
      "|    value_loss         | 0.0649   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 342      |\n",
      "|    ep_rew_mean        | -88.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 670      |\n",
      "|    iterations         | 21300    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 106500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | -5.39    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21299    |\n",
      "|    policy_loss        | -0.262   |\n",
      "|    std                | 0.469    |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 360      |\n",
      "|    ep_rew_mean        | -85.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 671      |\n",
      "|    iterations         | 21400    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 107000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.48    |\n",
      "|    explained_variance | 0.673    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21399    |\n",
      "|    policy_loss        | 0.301    |\n",
      "|    std                | 0.471    |\n",
      "|    value_loss         | 0.0235   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 362      |\n",
      "|    ep_rew_mean        | -85      |\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 21500    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 107500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | -4.16    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21499    |\n",
      "|    policy_loss        | -0.362   |\n",
      "|    std                | 0.47     |\n",
      "|    value_loss         | 1.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 334      |\n",
      "|    ep_rew_mean        | -84.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 21600    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 108000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | -346     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21599    |\n",
      "|    policy_loss        | 0.0546   |\n",
      "|    std                | 0.469    |\n",
      "|    value_loss         | 0.0252   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 334      |\n",
      "|    ep_rew_mean        | -83.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 21700    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 108500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | -51.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21699    |\n",
      "|    policy_loss        | -1.22    |\n",
      "|    std                | 0.468    |\n",
      "|    value_loss         | 0.677    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 337      |\n",
      "|    ep_rew_mean        | -83.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 21800    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 109000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | 0.421    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21799    |\n",
      "|    policy_loss        | -61.1    |\n",
      "|    std                | 0.468    |\n",
      "|    value_loss         | 2.46e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 328      |\n",
      "|    ep_rew_mean        | -82.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 21900    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 109500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.44    |\n",
      "|    explained_variance | -0.191   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21899    |\n",
      "|    policy_loss        | -1.28    |\n",
      "|    std                | 0.466    |\n",
      "|    value_loss         | 0.216    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-105.11 +/- 0.04\n",
      "Episode length: 45.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 45       |\n",
      "|    mean_reward        | -105     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | -1.47    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21999    |\n",
      "|    policy_loss        | 0.847    |\n",
      "|    std                | 0.465    |\n",
      "|    value_loss         | 0.179    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 311      |\n",
      "|    ep_rew_mean     | -83.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 674      |\n",
      "|    iterations      | 22000    |\n",
      "|    time_elapsed    | 162      |\n",
      "|    total_timesteps | 110000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | -84.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 22100    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 110500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | -4.93    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22099    |\n",
      "|    policy_loss        | -0.148   |\n",
      "|    std                | 0.469    |\n",
      "|    value_loss         | 0.472    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | -84.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 676      |\n",
      "|    iterations         | 22200    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 111000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | -4.13    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22199    |\n",
      "|    policy_loss        | 1.93     |\n",
      "|    std                | 0.467    |\n",
      "|    value_loss         | 0.282    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | -84.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 22300    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 111500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | 0.547    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22299    |\n",
      "|    policy_loss        | -0.353   |\n",
      "|    std                | 0.467    |\n",
      "|    value_loss         | 0.0535   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 312      |\n",
      "|    ep_rew_mean        | -81.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 22400    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 112000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | 0.611    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22399    |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    std                | 0.467    |\n",
      "|    value_loss         | 0.745    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | -81.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 22500    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 112500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | -1.8     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22499    |\n",
      "|    policy_loss        | 1.92     |\n",
      "|    std                | 0.467    |\n",
      "|    value_loss         | 0.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | -81.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 22600    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 113000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.44    |\n",
      "|    explained_variance | -1.98    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22599    |\n",
      "|    policy_loss        | 0.836    |\n",
      "|    std                | 0.465    |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | -81.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 22700    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 113500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | -10.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22699    |\n",
      "|    policy_loss        | 0.39     |\n",
      "|    std                | 0.466    |\n",
      "|    value_loss         | 0.0998   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | -81.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 22800    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 114000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | -0.147   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22799    |\n",
      "|    policy_loss        | -0.253   |\n",
      "|    std                | 0.467    |\n",
      "|    value_loss         | 0.0542   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 326      |\n",
      "|    ep_rew_mean        | -79.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 22900    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 114500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | -1.29    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22899    |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    std                | 0.466    |\n",
      "|    value_loss         | 0.227    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-58.18 +/- 16.87\n",
      "Episode length: 314.20 +/- 80.87\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 314      |\n",
      "|    mean_reward        | -58.2    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 115000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | -3.97    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22999    |\n",
      "|    policy_loss        | -0.271   |\n",
      "|    std                | 0.464    |\n",
      "|    value_loss         | 0.0768   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 332      |\n",
      "|    ep_rew_mean     | -78.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 677      |\n",
      "|    iterations      | 23000    |\n",
      "|    time_elapsed    | 169      |\n",
      "|    total_timesteps | 115000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 335      |\n",
      "|    ep_rew_mean        | -77.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 23100    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 115500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.45    |\n",
      "|    explained_variance | -60.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23099    |\n",
      "|    policy_loss        | -3.49    |\n",
      "|    std                | 0.467    |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | -77.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 23200    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 116000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | 0.66     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23199    |\n",
      "|    policy_loss        | -1.17    |\n",
      "|    std                | 0.464    |\n",
      "|    value_loss         | 0.391    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | -77.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 23300    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 116500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | -353     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23299    |\n",
      "|    policy_loss        | 0.744    |\n",
      "|    std                | 0.462    |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | -77.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 23400    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 117000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.39    |\n",
      "|    explained_variance | -10.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23399    |\n",
      "|    policy_loss        | 0.221    |\n",
      "|    std                | 0.459    |\n",
      "|    value_loss         | 0.0319   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 309      |\n",
      "|    ep_rew_mean        | -77.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 23500    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 117500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.4     |\n",
      "|    explained_variance | -14.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23499    |\n",
      "|    policy_loss        | -0.232   |\n",
      "|    std                | 0.461    |\n",
      "|    value_loss         | 0.0468   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | -77      |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 23600    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 118000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.38    |\n",
      "|    explained_variance | -18.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23599    |\n",
      "|    policy_loss        | 1.13     |\n",
      "|    std                | 0.458    |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | -77.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 23700    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 118500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.39    |\n",
      "|    explained_variance | -0.273   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23699    |\n",
      "|    policy_loss        | -0.959   |\n",
      "|    std                | 0.46     |\n",
      "|    value_loss         | 0.369    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 303      |\n",
      "|    ep_rew_mean        | -77.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 23800    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 119000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.37    |\n",
      "|    explained_variance | 0.662    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23799    |\n",
      "|    policy_loss        | -0.193   |\n",
      "|    std                | 0.456    |\n",
      "|    value_loss         | 0.0896   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 290      |\n",
      "|    ep_rew_mean        | -78      |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 23900    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 119500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.38    |\n",
      "|    explained_variance | -10.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23899    |\n",
      "|    policy_loss        | -0.574   |\n",
      "|    std                | 0.457    |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-114.85 +/- 1.93\n",
      "Episode length: 66.80 +/- 7.11\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 66.8     |\n",
      "|    mean_reward        | -115     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.38    |\n",
      "|    explained_variance | -12.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23999    |\n",
      "|    policy_loss        | 0.373    |\n",
      "|    std                | 0.458    |\n",
      "|    value_loss         | 0.0818   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 282      |\n",
      "|    ep_rew_mean     | -78.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 682      |\n",
      "|    iterations      | 24000    |\n",
      "|    time_elapsed    | 175      |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 282      |\n",
      "|    ep_rew_mean        | -78.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 24100    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 120500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.36    |\n",
      "|    explained_variance | -8.47    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24099    |\n",
      "|    policy_loss        | -0.715   |\n",
      "|    std                | 0.455    |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 282      |\n",
      "|    ep_rew_mean        | -78.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 24200    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 121000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.35    |\n",
      "|    explained_variance | 0.845    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24199    |\n",
      "|    policy_loss        | 0.829    |\n",
      "|    std                | 0.454    |\n",
      "|    value_loss         | 0.215    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 253      |\n",
      "|    ep_rew_mean        | -79.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 24300    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 121500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.34    |\n",
      "|    explained_variance | -44.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24299    |\n",
      "|    policy_loss        | 3.91     |\n",
      "|    std                | 0.453    |\n",
      "|    value_loss         | 3.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 253      |\n",
      "|    ep_rew_mean        | -79.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 24400    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 122000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.33    |\n",
      "|    explained_variance | -45      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24399    |\n",
      "|    policy_loss        | -0.377   |\n",
      "|    std                | 0.452    |\n",
      "|    value_loss         | 0.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 261      |\n",
      "|    ep_rew_mean        | -79.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 24500    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 122500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.33    |\n",
      "|    explained_variance | -5.36    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24499    |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    std                | 0.452    |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 261      |\n",
      "|    ep_rew_mean        | -79.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 24600    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 123000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.27    |\n",
      "|    explained_variance | -8.32    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24599    |\n",
      "|    policy_loss        | 1.56     |\n",
      "|    std                | 0.446    |\n",
      "|    value_loss         | 0.867    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -78.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 24700    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 123500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | -1.15    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24699    |\n",
      "|    policy_loss        | 0.61     |\n",
      "|    std                | 0.446    |\n",
      "|    value_loss         | 0.0829   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -78.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 24800    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 124000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | -3.71    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24799    |\n",
      "|    policy_loss        | 0.573    |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 282      |\n",
      "|    ep_rew_mean        | -76.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 687      |\n",
      "|    iterations         | 24900    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 124500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.22    |\n",
      "|    explained_variance | -5.48    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24899    |\n",
      "|    policy_loss        | 0.786    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.153    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-117.20 +/- 1.88\n",
      "Episode length: 65.40 +/- 2.94\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 65.4     |\n",
      "|    mean_reward        | -117     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 125000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | -3.81    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24999    |\n",
      "|    policy_loss        | 0.202    |\n",
      "|    std                | 0.44     |\n",
      "|    value_loss         | 0.0239   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 284      |\n",
      "|    ep_rew_mean     | -76.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 687      |\n",
      "|    iterations      | 25000    |\n",
      "|    time_elapsed    | 181      |\n",
      "|    total_timesteps | 125000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 280      |\n",
      "|    ep_rew_mean        | -76      |\n",
      "| time/                 |          |\n",
      "|    fps                | 687      |\n",
      "|    iterations         | 25100    |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 125500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | 0.683    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25099    |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    std                | 0.438    |\n",
      "|    value_loss         | 0.425    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | -75.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 25200    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 126000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -181     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25199    |\n",
      "|    policy_loss        | 2.22     |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 3.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -76.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 25300    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 126500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -8.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25299    |\n",
      "|    policy_loss        | 2.24     |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -76.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 25400    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 127000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -14.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25399    |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    std                | 0.433    |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -76.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 25500    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 127500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -26.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25499    |\n",
      "|    policy_loss        | -0.601   |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -76.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 25600    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 128000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -14.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25599    |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.271    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 286      |\n",
      "|    ep_rew_mean        | -73.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 25700    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 128500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25699    |\n",
      "|    policy_loss        | -0.808   |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.641    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 286      |\n",
      "|    ep_rew_mean        | -73.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 25800    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 129000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0.73     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25799    |\n",
      "|    policy_loss        | -0.806   |\n",
      "|    std                | 0.433    |\n",
      "|    value_loss         | 0.0891   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 295      |\n",
      "|    ep_rew_mean        | -72.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 25900    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 129500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.725    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25899    |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.0248   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-38.36 +/- 40.17\n",
      "Episode length: 388.80 +/- 209.25\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 389      |\n",
      "|    mean_reward        | -38.4    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | -37.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25999    |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 300      |\n",
      "|    ep_rew_mean     | -71.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 689      |\n",
      "|    iterations      | 26000    |\n",
      "|    time_elapsed    | 188      |\n",
      "|    total_timesteps | 130000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 304      |\n",
      "|    ep_rew_mean        | -70.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 26100    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 130500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0.628    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26099    |\n",
      "|    policy_loss        | 0.016    |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 0.0835   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 304      |\n",
      "|    ep_rew_mean        | -70.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 26200    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 131000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | -2.31    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26199    |\n",
      "|    policy_loss        | 0.288    |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.139    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 304      |\n",
      "|    ep_rew_mean        | -70.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 26300    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 131500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0.897    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26299    |\n",
      "|    policy_loss        | 0.394    |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.158    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 316      |\n",
      "|    ep_rew_mean        | -68.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 26400    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 132000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0.617    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26399    |\n",
      "|    policy_loss        | -0.134   |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 0.00369  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 320      |\n",
      "|    ep_rew_mean        | -67.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 26500    |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 132500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -794     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26499    |\n",
      "|    policy_loss        | -3.12    |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 3.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 320      |\n",
      "|    ep_rew_mean        | -67.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 26600    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 133000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26599    |\n",
      "|    policy_loss        | -0.343   |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 318      |\n",
      "|    ep_rew_mean        | -67.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 26700    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 133500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -6       |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26699    |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.398    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 306      |\n",
      "|    ep_rew_mean        | -68.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 26800    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 134000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -6.31    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26799    |\n",
      "|    policy_loss        | 0.284    |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.0609   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 275      |\n",
      "|    ep_rew_mean        | -73.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 26900    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 134500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0.396    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26899    |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 2.22e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-89.51 +/- 3.41\n",
      "Episode length: 110.40 +/- 10.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 110      |\n",
      "|    mean_reward        | -89.5    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 135000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -38.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26999    |\n",
      "|    policy_loss        | 0.778    |\n",
      "|    std                | 0.433    |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 274      |\n",
      "|    ep_rew_mean     | -74      |\n",
      "| time/              |          |\n",
      "|    fps             | 693      |\n",
      "|    iterations      | 27000    |\n",
      "|    time_elapsed    | 194      |\n",
      "|    total_timesteps | 135000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 274      |\n",
      "|    ep_rew_mean        | -74      |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 27100    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 135500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | -15      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27099    |\n",
      "|    policy_loss        | 1.43     |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 282      |\n",
      "|    ep_rew_mean        | -73.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 694      |\n",
      "|    iterations         | 27200    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 136000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | -4.9     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27199    |\n",
      "|    policy_loss        | -2.89    |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 281       |\n",
      "|    ep_rew_mean        | -74       |\n",
      "| time/                 |           |\n",
      "|    fps                | 694       |\n",
      "|    iterations         | 27300     |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 136500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.09     |\n",
      "|    explained_variance | -3.55e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27299     |\n",
      "|    policy_loss        | 0.465     |\n",
      "|    std                | 0.431     |\n",
      "|    value_loss         | 0.367     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | -74      |\n",
      "| time/                 |          |\n",
      "|    fps                | 695      |\n",
      "|    iterations         | 27400    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 137000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | -2.86    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27399    |\n",
      "|    policy_loss        | 0.91     |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 0.642    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | -73.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 695      |\n",
      "|    iterations         | 27500    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 137500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0.665    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27499    |\n",
      "|    policy_loss        | -0.164   |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 0.025    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | -73.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 696      |\n",
      "|    iterations         | 27600    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 138000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0.427    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27599    |\n",
      "|    policy_loss        | 0.75     |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.407    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | -73.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 696      |\n",
      "|    iterations         | 27700    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 138500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -333     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27699    |\n",
      "|    policy_loss        | 2.77     |\n",
      "|    std                | 0.433    |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | -73.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 27800    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 139000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -3.21    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27799    |\n",
      "|    policy_loss        | 0.666    |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0757   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 296      |\n",
      "|    ep_rew_mean        | -71.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 27900    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 139500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.467    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27899    |\n",
      "|    policy_loss        | -0.151   |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0749   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-90.10 +/- 5.05\n",
      "Episode length: 107.80 +/- 11.92\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 108      |\n",
      "|    mean_reward        | -90.1    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 140000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 0.55     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27999    |\n",
      "|    policy_loss        | 0.159    |\n",
      "|    std                | 0.426    |\n",
      "|    value_loss         | 0.0257   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 298      |\n",
      "|    ep_rew_mean     | -71.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 697      |\n",
      "|    iterations      | 28000    |\n",
      "|    time_elapsed    | 200      |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | -73.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 28100    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 140500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.938    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28099    |\n",
      "|    policy_loss        | 0.264    |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0632   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 286      |\n",
      "|    ep_rew_mean        | -73.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 698      |\n",
      "|    iterations         | 28200    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 141000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.847    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28199    |\n",
      "|    policy_loss        | -1.03    |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 286      |\n",
      "|    ep_rew_mean        | -73.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 698      |\n",
      "|    iterations         | 28300    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 141500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28299    |\n",
      "|    policy_loss        | -0.427   |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0513   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 297      |\n",
      "|    ep_rew_mean        | -72.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 698      |\n",
      "|    iterations         | 28400    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 142000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | -6.49    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28399    |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.137    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 297      |\n",
      "|    ep_rew_mean        | -72.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 699      |\n",
      "|    iterations         | 28500    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 142500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -6.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28499    |\n",
      "|    policy_loss        | -0.088   |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0533   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 297      |\n",
      "|    ep_rew_mean        | -72.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 699      |\n",
      "|    iterations         | 28600    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 143000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -3.67    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28599    |\n",
      "|    policy_loss        | -0.885   |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 287      |\n",
      "|    ep_rew_mean        | -74.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 700      |\n",
      "|    iterations         | 28700    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 143500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | -34.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28699    |\n",
      "|    policy_loss        | 2.07     |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | -75.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 700      |\n",
      "|    iterations         | 28800    |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 144000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -68.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28799    |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 0.742    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | -76.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 701      |\n",
      "|    iterations         | 28900    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 144500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -0.00502 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28899    |\n",
      "|    policy_loss        | -0.272   |\n",
      "|    std                | 0.428    |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-117.44 +/- 1.33\n",
      "Episode length: 60.80 +/- 1.60\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 60.8     |\n",
      "|    mean_reward        | -117     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 145000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | 0.241    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28999    |\n",
      "|    policy_loss        | -0.392   |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | -78.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 701      |\n",
      "|    iterations      | 29000    |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 145000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 244      |\n",
      "|    ep_rew_mean        | -79.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 701      |\n",
      "|    iterations         | 29100    |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 145500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0.142    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29099    |\n",
      "|    policy_loss        | 0.272    |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0463   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 203      |\n",
      "|    ep_rew_mean        | -85.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 701      |\n",
      "|    iterations         | 29200    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 146000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -0.141   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29199    |\n",
      "|    policy_loss        | -1.82    |\n",
      "|    std                | 0.428    |\n",
      "|    value_loss         | 0.904    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 173      |\n",
      "|    ep_rew_mean        | -90.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 702      |\n",
      "|    iterations         | 29300    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 146500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | 0.00692  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29299    |\n",
      "|    policy_loss        | -1.38    |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.408    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 145      |\n",
      "|    ep_rew_mean        | -96.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 702      |\n",
      "|    iterations         | 29400    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 147000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0.236    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29399    |\n",
      "|    policy_loss        | -0.621   |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.0823   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 135      |\n",
      "|    ep_rew_mean        | -98.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 29500    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 147500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.8      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29499    |\n",
      "|    policy_loss        | 0.0876   |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 0.00457  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 130      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 29600    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 148000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.256    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29599    |\n",
      "|    policy_loss        | 0.55     |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.0498   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 113      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 29700    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 148500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.723    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29699    |\n",
      "|    policy_loss        | -0.12    |\n",
      "|    std                | 0.433    |\n",
      "|    value_loss         | 0.0305   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.1     |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 29800    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 149000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -4.48    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29799    |\n",
      "|    policy_loss        | -0.624   |\n",
      "|    std                | 0.433    |\n",
      "|    value_loss         | 0.675    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.6     |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 29900    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 149500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -1.33    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29899    |\n",
      "|    policy_loss        | -0.301   |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.0839   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-115.12 +/- 5.44\n",
      "Episode length: 85.20 +/- 24.52\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 85.2     |\n",
      "|    mean_reward        | -115     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 150000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -1.74    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29999    |\n",
      "|    policy_loss        | -1.69    |\n",
      "|    std                | 0.436    |\n",
      "|    value_loss         | 0.307    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 65.6     |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    fps             | 704      |\n",
      "|    iterations      | 30000    |\n",
      "|    time_elapsed    | 212      |\n",
      "|    total_timesteps | 150000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 62.6     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 30100    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 150500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | 0.736    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30099    |\n",
      "|    policy_loss        | -0.0152  |\n",
      "|    std                | 0.436    |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 62.8     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 30200    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 151000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -3.32    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30199    |\n",
      "|    policy_loss        | -0.477   |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 0.164    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.2     |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 30300    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 151500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | -50.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30299    |\n",
      "|    policy_loss        | -1.43    |\n",
      "|    std                | 0.438    |\n",
      "|    value_loss         | 0.964    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 64.1     |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 30400    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 152000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -32.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30399    |\n",
      "|    policy_loss        | 5.3      |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 3.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 66       |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 30500    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 152500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | -2.63    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30499    |\n",
      "|    policy_loss        | -2.64    |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 69.1     |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 30600    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 153000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | -11.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30599    |\n",
      "|    policy_loss        | 0.0637   |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 69.9      |\n",
      "|    ep_rew_mean        | -109      |\n",
      "| time/                 |           |\n",
      "|    fps                | 706       |\n",
      "|    iterations         | 30700     |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 153500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.2      |\n",
      "|    explained_variance | 0.976     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30699     |\n",
      "|    policy_loss        | -4.74e-05 |\n",
      "|    std                | 0.44      |\n",
      "|    value_loss         | 0.000992  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74.4     |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 30800    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 154000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | -2.87    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30799    |\n",
      "|    policy_loss        | -0.766   |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 0.421    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 77       |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 30900    |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 154500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | 0.276    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30899    |\n",
      "|    policy_loss        | 2.75     |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-98.07 +/- 16.42\n",
      "Episode length: 156.00 +/- 90.69\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 156      |\n",
      "|    mean_reward        | -98.1    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 155000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | -73.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30999    |\n",
      "|    policy_loss        | -2.71    |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 2.24     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 81.3     |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    fps             | 706      |\n",
      "|    iterations      | 31000    |\n",
      "|    time_elapsed    | 219      |\n",
      "|    total_timesteps | 155000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 83.4     |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 31100    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 155500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | -0.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31099    |\n",
      "|    policy_loss        | 2.63     |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 0.968    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88.1     |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 31200    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 156000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | -19.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31199    |\n",
      "|    policy_loss        | 5.66     |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 6.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88.1     |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 31300    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 156500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | -600     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31299    |\n",
      "|    policy_loss        | 0.716    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.444    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88.1     |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 31400    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 157000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | -33.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31399    |\n",
      "|    policy_loss        | 0.68     |\n",
      "|    std                | 0.44     |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88.1     |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 31500    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 157500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | -1.53    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31499    |\n",
      "|    policy_loss        | -0.44    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.0338   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 107      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 31600    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 158000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | 0.536    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31599    |\n",
      "|    policy_loss        | 0.513    |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 0.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 31700    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 158500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | -112     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31699    |\n",
      "|    policy_loss        | -7.71    |\n",
      "|    std                | 0.446    |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 31800    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 159000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | -4.41    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31799    |\n",
      "|    policy_loss        | -0.0109  |\n",
      "|    std                | 0.447    |\n",
      "|    value_loss         | 0.00362  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 31900    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 159500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | -3.47    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31899    |\n",
      "|    policy_loss        | -0.674   |\n",
      "|    std                | 0.447    |\n",
      "|    value_loss         | 0.151    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=58.15 +/- 79.91\n",
      "Episode length: 1344.60 +/- 343.26\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.34e+03 |\n",
      "|    mean_reward        | 58.2     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0.888    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31999    |\n",
      "|    policy_loss        | 2.13     |\n",
      "|    std                | 0.448    |\n",
      "|    value_loss         | 0.992    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 118      |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    fps             | 701      |\n",
      "|    iterations      | 32000    |\n",
      "|    time_elapsed    | 228      |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 118      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 701      |\n",
      "|    iterations         | 32100    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 160500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | -2.41    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32099    |\n",
      "|    policy_loss        | 0.808    |\n",
      "|    std                | 0.447    |\n",
      "|    value_loss         | 0.437    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 118      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 702      |\n",
      "|    iterations         | 32200    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 161000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | -8.97    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32199    |\n",
      "|    policy_loss        | -2.29    |\n",
      "|    std                | 0.446    |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 133      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 702      |\n",
      "|    iterations         | 32300    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 161500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | -563     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32299    |\n",
      "|    policy_loss        | 1.26     |\n",
      "|    std                | 0.448    |\n",
      "|    value_loss         | 0.476    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 133      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 702      |\n",
      "|    iterations         | 32400    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 162000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | -9.09    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32399    |\n",
      "|    policy_loss        | 0.239    |\n",
      "|    std                | 0.449    |\n",
      "|    value_loss         | 0.0706   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 133      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 32500    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 162500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | -110     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32499    |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    std                | 0.449    |\n",
      "|    value_loss         | 1.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 147      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 32600    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 163000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | -21.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32599    |\n",
      "|    policy_loss        | 2.69     |\n",
      "|    std                | 0.45     |\n",
      "|    value_loss         | 3.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 153      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 32700    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 163500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.28    |\n",
      "|    explained_variance | -7.39    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32699    |\n",
      "|    policy_loss        | -0.372   |\n",
      "|    std                | 0.452    |\n",
      "|    value_loss         | 0.0724   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 156      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 32800    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 164000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.27    |\n",
      "|    explained_variance | 0.0991   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32799    |\n",
      "|    policy_loss        | -0.498   |\n",
      "|    std                | 0.451    |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 161      |\n",
      "|    ep_rew_mean        | -99.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 32900    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 164500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.28    |\n",
      "|    explained_variance | 0.578    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32899    |\n",
      "|    policy_loss        | -0.344   |\n",
      "|    std                | 0.451    |\n",
      "|    value_loss         | 0.0176   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-113.82 +/- 7.75\n",
      "Episode length: 61.60 +/- 40.39\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 61.6     |\n",
      "|    mean_reward        | -114     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 165000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.28    |\n",
      "|    explained_variance | 0.217    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32999    |\n",
      "|    policy_loss        | -89.1    |\n",
      "|    std                | 0.45     |\n",
      "|    value_loss         | 2.92e+03 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 165      |\n",
      "|    ep_rew_mean     | -100     |\n",
      "| time/              |          |\n",
      "|    fps             | 704      |\n",
      "|    iterations      | 33000    |\n",
      "|    time_elapsed    | 234      |\n",
      "|    total_timesteps | 165000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 33100    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 165500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.3     |\n",
      "|    explained_variance | 0.211    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33099    |\n",
      "|    policy_loss        | 0.723    |\n",
      "|    std                | 0.452    |\n",
      "|    value_loss         | 0.316    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 162      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 33200    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 166000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | -69.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33199    |\n",
      "|    policy_loss        | -3.41    |\n",
      "|    std                | 0.45     |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 164      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 33300    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 166500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | -75.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33299    |\n",
      "|    policy_loss        | -3.95    |\n",
      "|    std                | 0.451    |\n",
      "|    value_loss         | 5.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 164      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 33400    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 167000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.3     |\n",
      "|    explained_variance | 0.552    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33399    |\n",
      "|    policy_loss        | -0.261   |\n",
      "|    std                | 0.451    |\n",
      "|    value_loss         | 0.0492   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 33500    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 167500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | -45.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33499    |\n",
      "|    policy_loss        | -3.24    |\n",
      "|    std                | 0.451    |\n",
      "|    value_loss         | 2.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 33600    |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 168000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.28    |\n",
      "|    explained_variance | 0.927    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33599    |\n",
      "|    policy_loss        | 0.0558   |\n",
      "|    std                | 0.449    |\n",
      "|    value_loss         | 0.00361  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 33700    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 168500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0.701    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33699    |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    std                | 0.447    |\n",
      "|    value_loss         | 0.247    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 33800    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 169000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | -0.585   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33799    |\n",
      "|    policy_loss        | 0.479    |\n",
      "|    std                | 0.447    |\n",
      "|    value_loss         | 0.0623   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 162      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 33900    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 169500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | -0.377   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33899    |\n",
      "|    policy_loss        | 2.16     |\n",
      "|    std                | 0.445    |\n",
      "|    value_loss         | 0.614    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-109.04 +/- 2.98\n",
      "Episode length: 45.40 +/- 7.31\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 45.4     |\n",
      "|    mean_reward        | -109     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | 0.323    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33999    |\n",
      "|    policy_loss        | -0.0776  |\n",
      "|    std                | 0.445    |\n",
      "|    value_loss         | 0.00531  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 159      |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    fps             | 707      |\n",
      "|    iterations      | 34000    |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 170000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 147      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 34100    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 170500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | 0.973    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34099    |\n",
      "|    policy_loss        | 0.212    |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 0.00727  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 122      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 34200    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 171000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | -1.78    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34199    |\n",
      "|    policy_loss        | 0.628    |\n",
      "|    std                | 0.438    |\n",
      "|    value_loss         | 0.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 77.7     |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 34300    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 171500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | 0.189    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34299    |\n",
      "|    policy_loss        | -82.7    |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 1.6e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.4     |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 34400    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 172000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.22    |\n",
      "|    explained_variance | -0.353   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34399    |\n",
      "|    policy_loss        | -0.0441  |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.000784 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.2     |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 34500    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 172500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | -3.82    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34499    |\n",
      "|    policy_loss        | 1.42     |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 0.429    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 69.2     |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 34600    |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 173000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | 0.722    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34599    |\n",
      "|    policy_loss        | 0.272    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.0379   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 68       |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 34700    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 173500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | -10.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34699    |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    std                | 0.439    |\n",
      "|    value_loss         | 0.738    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 70.4     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 34800    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 174000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | -2.49    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34799    |\n",
      "|    policy_loss        | 0.282    |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 0.119    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.2     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 34900    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 174500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | -453     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34899    |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 0.44     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-114.80 +/- 2.30\n",
      "Episode length: 56.40 +/- 2.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 56.4     |\n",
      "|    mean_reward        | -115     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 175000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | 0.366    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34999    |\n",
      "|    policy_loss        | -4.08    |\n",
      "|    std                | 0.438    |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 70       |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    fps             | 710      |\n",
      "|    iterations      | 35000    |\n",
      "|    time_elapsed    | 246      |\n",
      "|    total_timesteps | 175000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 70       |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 35100    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 175500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | -42.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35099    |\n",
      "|    policy_loss        | -3.61    |\n",
      "|    std                | 0.439    |\n",
      "|    value_loss         | 8.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 68.6     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 35200    |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 176000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | -0.0616  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35199    |\n",
      "|    policy_loss        | -0.295   |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 0.0893   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74.1     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 35300    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 176500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | -159     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35299    |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 0.436    |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74.1     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 35400    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 177000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | -3.84    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35399    |\n",
      "|    policy_loss        | 0.011    |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 0.0542   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74.1     |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 35500    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 177500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -157     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35499    |\n",
      "|    policy_loss        | -0.444   |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.467    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89.3     |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 712      |\n",
      "|    iterations         | 35600    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 178000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -2.56    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35599    |\n",
      "|    policy_loss        | -0.792   |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.659    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89.3     |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 712      |\n",
      "|    iterations         | 35700    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 178500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -16.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35699    |\n",
      "|    policy_loss        | -4.11    |\n",
      "|    std                | 0.436    |\n",
      "|    value_loss         | 5.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89.3     |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 712      |\n",
      "|    iterations         | 35800    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 179000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -12      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35799    |\n",
      "|    policy_loss        | -1.54    |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.801    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89.3     |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 713      |\n",
      "|    iterations         | 35900    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 179500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -7.17    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35899    |\n",
      "|    policy_loss        | -1.02    |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.654    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-109.08 +/- 55.84\n",
      "Episode length: 964.00 +/- 604.02\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 964      |\n",
      "|    mean_reward        | -109     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -1.01    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35999    |\n",
      "|    policy_loss        | 3.78     |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    fps             | 707      |\n",
      "|    iterations      | 36000    |\n",
      "|    time_elapsed    | 254      |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 104      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 36100    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 180500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -4.09    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36099    |\n",
      "|    policy_loss        | 0.351    |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.156    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 115      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 36200    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 181000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0.573    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36199    |\n",
      "|    policy_loss        | 0.947    |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.408    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 115      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 36300    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 181500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.892    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36299    |\n",
      "|    policy_loss        | 0.0535   |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 121      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 36400    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 182000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | -0.657   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36399    |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 123      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 36500    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 182500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | -51.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36499    |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 126      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 36600    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 183000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | -17.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36599    |\n",
      "|    policy_loss        | 2.38     |\n",
      "|    std                | 0.426    |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 126      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 36700    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 183500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | -0.142   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36699    |\n",
      "|    policy_loss        | 0.346    |\n",
      "|    std                | 0.425    |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 136      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 36800    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 184000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | -472     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36799    |\n",
      "|    policy_loss        | -14      |\n",
      "|    std                | 0.423    |\n",
      "|    value_loss         | 20.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 132      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 36900    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 184500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | -0.0931  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36899    |\n",
      "|    policy_loss        | 2.06     |\n",
      "|    std                | 0.425    |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-101.10 +/- 0.56\n",
      "Episode length: 50.20 +/- 0.75\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 50.2     |\n",
      "|    mean_reward        | -101     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 185000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | 0.758    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36999    |\n",
      "|    policy_loss        | -0.773   |\n",
      "|    std                | 0.424    |\n",
      "|    value_loss         | 0.579    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 131      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    fps             | 710      |\n",
      "|    iterations      | 37000    |\n",
      "|    time_elapsed    | 260      |\n",
      "|    total_timesteps | 185000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 136      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 37100    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 185500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | -27.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37099    |\n",
      "|    policy_loss        | -5.15    |\n",
      "|    std                | 0.424    |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 137      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 37200    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 186000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | -2.04    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37199    |\n",
      "|    policy_loss        | 1.47     |\n",
      "|    std                | 0.423    |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 139      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 37300    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 186500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | -28.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37299    |\n",
      "|    policy_loss        | -17.6    |\n",
      "|    std                | 0.423    |\n",
      "|    value_loss         | 99.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 142      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 37400    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 187000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | -49.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37399    |\n",
      "|    policy_loss        | 5.31     |\n",
      "|    std                | 0.424    |\n",
      "|    value_loss         | 23.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 145      |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 37500    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 187500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | 0.96     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37499    |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    std                | 0.423    |\n",
      "|    value_loss         | 0.215    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 147      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 712      |\n",
      "|    iterations         | 37600    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 188000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | -329     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37599    |\n",
      "|    policy_loss        | 2.82     |\n",
      "|    std                | 0.425    |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 149      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 712      |\n",
      "|    iterations         | 37700    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 188500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0.482    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37699    |\n",
      "|    policy_loss        | -0.52    |\n",
      "|    std                | 0.425    |\n",
      "|    value_loss         | 0.0532   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 153      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 712      |\n",
      "|    iterations         | 37800    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 189000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 0.829    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37799    |\n",
      "|    policy_loss        | 0.0662   |\n",
      "|    std                | 0.426    |\n",
      "|    value_loss         | 0.00155  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 155      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 713      |\n",
      "|    iterations         | 37900    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 189500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | 0.938    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37899    |\n",
      "|    policy_loss        | 0.47     |\n",
      "|    std                | 0.425    |\n",
      "|    value_loss         | 0.0811   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-111.03 +/- 0.12\n",
      "Episode length: 58.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 58       |\n",
      "|    mean_reward        | -111     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0.477    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37999    |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    std                | 0.425    |\n",
      "|    value_loss         | 0.83     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 156      |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 712      |\n",
      "|    iterations      | 38000    |\n",
      "|    time_elapsed    | 266      |\n",
      "|    total_timesteps | 190000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 157      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 713      |\n",
      "|    iterations         | 38100    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 190500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | -0.817   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38099    |\n",
      "|    policy_loss        | 0.678    |\n",
      "|    std                | 0.428    |\n",
      "|    value_loss         | 0.237    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 713      |\n",
      "|    iterations         | 38200    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 191000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38199    |\n",
      "|    policy_loss        | 0.00759  |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 0.00415  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 713      |\n",
      "|    iterations         | 38300    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 191500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0.442    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38299    |\n",
      "|    policy_loss        | 0.916    |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 167      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 38400    |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -9.71    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38399    |\n",
      "|    policy_loss        | 0.516    |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 0.367    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 175      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 38500    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 192500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -16.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38499    |\n",
      "|    policy_loss        | -11.5    |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 31.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 178      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 38600    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 193000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | -34.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38599    |\n",
      "|    policy_loss        | -7.52    |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 180      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 38700    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 193500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0.973    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38699    |\n",
      "|    policy_loss        | 0.443    |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 0.063    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 184      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 38800    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 194000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -2.97    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38799    |\n",
      "|    policy_loss        | 2.53     |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 149      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 38900    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 194500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | -30.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38899    |\n",
      "|    policy_loss        | 1.55     |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-86.53 +/- 3.89\n",
      "Episode length: 126.00 +/- 14.38\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 126      |\n",
      "|    mean_reward        | -86.5    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 195000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.979    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38999    |\n",
      "|    policy_loss        | 0.635    |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.155    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 132      |\n",
      "|    ep_rew_mean     | -99.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 714      |\n",
      "|    iterations      | 39000    |\n",
      "|    time_elapsed    | 272      |\n",
      "|    total_timesteps | 195000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 131      |\n",
      "|    ep_rew_mean        | -98.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 39100    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 195500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | 0.723    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39099    |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    std                | 0.428    |\n",
      "|    value_loss         | 0.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 131      |\n",
      "|    ep_rew_mean        | -98.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 39200    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 196000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 0.472    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39199    |\n",
      "|    policy_loss        | -2.34    |\n",
      "|    std                | 0.428    |\n",
      "|    value_loss         | 983      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 125      |\n",
      "|    ep_rew_mean        | -97.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 39300    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 196500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | -281     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39299    |\n",
      "|    policy_loss        | 4.27     |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 22.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 126      |\n",
      "|    ep_rew_mean        | -97.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 39400    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 197000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -0.871   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39399    |\n",
      "|    policy_loss        | 0.00884  |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.0736   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 126      |\n",
      "|    ep_rew_mean        | -97.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 39500    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 197500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.626    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39499    |\n",
      "|    policy_loss        | -0.643   |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 0.0585   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 126      |\n",
      "|    ep_rew_mean        | -97.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 39600    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 198000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -40.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39599    |\n",
      "|    policy_loss        | -0.548   |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.275    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 141      |\n",
      "|    ep_rew_mean        | -94.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 39700    |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 198500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.125    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39699    |\n",
      "|    policy_loss        | -0.943   |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.595    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 141      |\n",
      "|    ep_rew_mean        | -94.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 39800    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 199000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | -3.08    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39799    |\n",
      "|    policy_loss        | -0.146   |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 0.0241   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 153      |\n",
      "|    ep_rew_mean        | -93.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 39900    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 199500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | -28.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39899    |\n",
      "|    policy_loss        | -2.79    |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 6.05     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-82.55 +/- 20.67\n",
      "Episode length: 291.00 +/- 110.22\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 291      |\n",
      "|    mean_reward        | -82.6    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | 0.863    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39999    |\n",
      "|    policy_loss        | 0.62     |\n",
      "|    std                | 0.43     |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 157      |\n",
      "|    ep_rew_mean     | -93.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 715      |\n",
      "|    iterations      | 40000    |\n",
      "|    time_elapsed    | 279      |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -94.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 40100    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 200500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | -37.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40099    |\n",
      "|    policy_loss        | 0.304    |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 158      |\n",
      "|    ep_rew_mean        | -95.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 40200    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 201000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | -14.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40199    |\n",
      "|    policy_loss        | 3.69     |\n",
      "|    std                | 0.433    |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 154      |\n",
      "|    ep_rew_mean        | -97      |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 40300    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 201500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | -8.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40299    |\n",
      "|    policy_loss        | 3.02     |\n",
      "|    std                | 0.431    |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 151      |\n",
      "|    ep_rew_mean        | -97      |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 40400    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 202000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | -12.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40399    |\n",
      "|    policy_loss        | -4.22    |\n",
      "|    std                | 0.428    |\n",
      "|    value_loss         | 7.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 147      |\n",
      "|    ep_rew_mean        | -98.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 40500    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 202500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | -4.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40499    |\n",
      "|    policy_loss        | 0.668    |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.833    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 136      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 40600    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 203000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | -0.488   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40599    |\n",
      "|    policy_loss        | 1.36     |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.443    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 136      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 40700    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 203500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | -0.601   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40699    |\n",
      "|    policy_loss        | -0.655   |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.653    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 139      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 40800    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 204000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0.183    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40799    |\n",
      "|    policy_loss        | 2.53     |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 137      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 40900    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 204500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0.19     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40899    |\n",
      "|    policy_loss        | -0.948   |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.49     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=-123.38 +/- 16.78\n",
      "Episode length: 174.80 +/- 58.85\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 175      |\n",
      "|    mean_reward        | -123     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 205000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | 0.796    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40999    |\n",
      "|    policy_loss        | -0.286   |\n",
      "|    std                | 0.438    |\n",
      "|    value_loss         | 0.0223   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 142      |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 717      |\n",
      "|    iterations      | 41000    |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 205000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 130      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 41100    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 205500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -1.14    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41099    |\n",
      "|    policy_loss        | 0.92     |\n",
      "|    std                | 0.44     |\n",
      "|    value_loss         | 0.177    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 134      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 41200    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 206000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | -2.27    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41199    |\n",
      "|    policy_loss        | -1.3     |\n",
      "|    std                | 0.438    |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 137      |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 41300    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 206500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -2.61    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41299    |\n",
      "|    policy_loss        | 0.8      |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 137      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 41400    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 207000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41399    |\n",
      "|    policy_loss        | -0.199   |\n",
      "|    std                | 0.434    |\n",
      "|    value_loss         | 0.0986   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 139      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 41500    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 207500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0.81     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41499    |\n",
      "|    policy_loss        | -0.132   |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 0.00767  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 139      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 41600    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 208000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -5.44    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41599    |\n",
      "|    policy_loss        | -0.415   |\n",
      "|    std                | 0.436    |\n",
      "|    value_loss         | 0.397    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 146      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 41700    |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 208500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -0.247   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41699    |\n",
      "|    policy_loss        | -1.41    |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 148      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 41800    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 209000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | -60.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41799    |\n",
      "|    policy_loss        | 0.568    |\n",
      "|    std                | 0.435    |\n",
      "|    value_loss         | 2.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 41900    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 209500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -153     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41899    |\n",
      "|    policy_loss        | 6.24     |\n",
      "|    std                | 0.439    |\n",
      "|    value_loss         | 5.52     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-101.90 +/- 37.15\n",
      "Episode length: 789.20 +/- 679.95\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 789      |\n",
      "|    mean_reward        | -102     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.13    |\n",
      "|    explained_variance | -23.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41999    |\n",
      "|    policy_loss        | 1.51     |\n",
      "|    std                | 0.439    |\n",
      "|    value_loss         | 3.06     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 154      |\n",
      "|    ep_rew_mean     | -114     |\n",
      "| time/              |          |\n",
      "|    fps             | 716      |\n",
      "|    iterations      | 42000    |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 210000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 154      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 42100    |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 210500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | -47.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42099    |\n",
      "|    policy_loss        | 0.0622   |\n",
      "|    std                | 0.438    |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 154      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 42200    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 211000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | -2.94    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42199    |\n",
      "|    policy_loss        | 0.486    |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 169      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 42300    |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 211500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1     |\n",
      "|    explained_variance | 0.473    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42299    |\n",
      "|    policy_loss        | -83.5    |\n",
      "|    std                | 0.436    |\n",
      "|    value_loss         | 3.11e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 167      |\n",
      "|    ep_rew_mean        | -116     |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 42400    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 212000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | -8.26    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42399    |\n",
      "|    policy_loss        | 0.62     |\n",
      "|    std                | 0.439    |\n",
      "|    value_loss         | 0.602    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 171      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 42500    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 212500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -0.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42499    |\n",
      "|    policy_loss        | 0.533    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.214    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 171      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 42600    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 213000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -9.92    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42599    |\n",
      "|    policy_loss        | -4.38    |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 4.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 152      |\n",
      "|    ep_rew_mean        | -122     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 42700    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 213500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -0.248   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42699    |\n",
      "|    policy_loss        | 3.35     |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 138      |\n",
      "|    ep_rew_mean        | -122     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 42800    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 214000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -6.33    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42799    |\n",
      "|    policy_loss        | 2.12     |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.594    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 138      |\n",
      "|    ep_rew_mean        | -122     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 42900    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 214500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | 0.669    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42899    |\n",
      "|    policy_loss        | 0.889    |\n",
      "|    std                | 0.443    |\n",
      "|    value_loss         | 0.156    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-113.55 +/- 0.45\n",
      "Episode length: 69.60 +/- 0.49\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 69.6     |\n",
      "|    mean_reward        | -114     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 215000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -27.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42999    |\n",
      "|    policy_loss        | -2.94    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 2.12     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 138      |\n",
      "|    ep_rew_mean     | -121     |\n",
      "| time/              |          |\n",
      "|    fps             | 719      |\n",
      "|    iterations      | 43000    |\n",
      "|    time_elapsed    | 299      |\n",
      "|    total_timesteps | 215000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 138      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 43100    |\n",
      "|    time_elapsed       | 299      |\n",
      "|    total_timesteps    | 215500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -36.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43099    |\n",
      "|    policy_loss        | 5.99     |\n",
      "|    std                | 0.441    |\n",
      "|    value_loss         | 7.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 138      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 43200    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 216000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | -96.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43199    |\n",
      "|    policy_loss        | -1.59    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 138      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 43300    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 216500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | -28.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43299    |\n",
      "|    policy_loss        | -0.0402  |\n",
      "|    std                | 0.446    |\n",
      "|    value_loss         | 0.932    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 147      |\n",
      "|    ep_rew_mean        | -121     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 43400    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 217000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | -85.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43399    |\n",
      "|    policy_loss        | 8.64     |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 151      |\n",
      "|    ep_rew_mean        | -121     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 43500    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 217500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | -13.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43499    |\n",
      "|    policy_loss        | -1.25    |\n",
      "|    std                | 0.446    |\n",
      "|    value_loss         | 0.487    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 151      |\n",
      "|    ep_rew_mean        | -121     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 43600    |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 218000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | -481     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43599    |\n",
      "|    policy_loss        | 2.76     |\n",
      "|    std                | 0.447    |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 151      |\n",
      "|    ep_rew_mean        | -121     |\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 43700    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 218500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | -110     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43699    |\n",
      "|    policy_loss        | 0.198    |\n",
      "|    std                | 0.448    |\n",
      "|    value_loss         | 0.237    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 167      |\n",
      "|    ep_rew_mean        | -121     |\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 43800    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 219000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | -0.484   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43799    |\n",
      "|    policy_loss        | -0.62    |\n",
      "|    std                | 0.448    |\n",
      "|    value_loss         | 0.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 166      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 43900    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 219500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.2     |\n",
      "|    explained_variance | -1.76    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43899    |\n",
      "|    policy_loss        | -1.39    |\n",
      "|    std                | 0.447    |\n",
      "|    value_loss         | 0.13     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-106.19 +/- 0.02\n",
      "Episode length: 34.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 34       |\n",
      "|    mean_reward        | -106     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | -6.42    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43999    |\n",
      "|    policy_loss        | -0.0844  |\n",
      "|    std                | 0.444    |\n",
      "|    value_loss         | 0.0264   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 166      |\n",
      "|    ep_rew_mean     | -120     |\n",
      "| time/              |          |\n",
      "|    fps             | 721      |\n",
      "|    iterations      | 44000    |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 220000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 166      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 722      |\n",
      "|    iterations         | 44100    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 220500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | 0.325    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44099    |\n",
      "|    policy_loss        | 0.215    |\n",
      "|    std                | 0.442    |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 722      |\n",
      "|    iterations         | 44200    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 221000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -2.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44199    |\n",
      "|    policy_loss        | 0.764    |\n",
      "|    std                | 0.44     |\n",
      "|    value_loss         | 0.0641   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 722      |\n",
      "|    iterations         | 44300    |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 221500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -1.1     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44299    |\n",
      "|    policy_loss        | 0.105    |\n",
      "|    std                | 0.44     |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 722      |\n",
      "|    iterations         | 44400    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 222000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | -0.14    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44399    |\n",
      "|    policy_loss        | -0.023   |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 0.0203   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 197      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 723      |\n",
      "|    iterations         | 44500    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 222500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | -0.663   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44499    |\n",
      "|    policy_loss        | -0.0996  |\n",
      "|    std                | 0.439    |\n",
      "|    value_loss         | 0.0599   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 197      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 723      |\n",
      "|    iterations         | 44600    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 223000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.576    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44599    |\n",
      "|    policy_loss        | 0.0573   |\n",
      "|    std                | 0.437    |\n",
      "|    value_loss         | 0.00588  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 197      |\n",
      "|    ep_rew_mean        | -120     |\n",
      "| time/                 |          |\n",
      "|    fps                | 723      |\n",
      "|    iterations         | 44700    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 223500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | -4.15    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44699    |\n",
      "|    policy_loss        | 0.502    |\n",
      "|    std                | 0.436    |\n",
      "|    value_loss         | 0.0407   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 212      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 723      |\n",
      "|    iterations         | 44800    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 224000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | -36.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44799    |\n",
      "|    policy_loss        | 0.56     |\n",
      "|    std                | 0.432    |\n",
      "|    value_loss         | 0.383    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 212      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 724      |\n",
      "|    iterations         | 44900    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 224500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | -0.282   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44899    |\n",
      "|    policy_loss        | 0.547    |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 0.0361   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-78.87 +/- 0.81\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -78.9    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 225000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | -0.465   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44999    |\n",
      "|    policy_loss        | 0.0951   |\n",
      "|    std                | 0.429    |\n",
      "|    value_loss         | 0.043    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 212      |\n",
      "|    ep_rew_mean     | -119     |\n",
      "| time/              |          |\n",
      "|    fps             | 716      |\n",
      "|    iterations      | 45000    |\n",
      "|    time_elapsed    | 313      |\n",
      "|    total_timesteps | 225000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 212      |\n",
      "|    ep_rew_mean        | -119     |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 45100    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 225500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.05    |\n",
      "|    explained_variance | 0.443    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45099    |\n",
      "|    policy_loss        | 0.274    |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0151   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 227      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 45200    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 226000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | -23.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45199    |\n",
      "|    policy_loss        | -0.805   |\n",
      "|    std                | 0.426    |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 227      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 45300    |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 226500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | -17.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45299    |\n",
      "|    policy_loss        | -0.233   |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0203   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 227      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 45400    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 227000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | 0.238    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45399    |\n",
      "|    policy_loss        | -0.19    |\n",
      "|    std                | 0.427    |\n",
      "|    value_loss         | 0.0094   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 45500    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 227500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.01    |\n",
      "|    explained_variance | -1.38    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45499    |\n",
      "|    policy_loss        | -0.391   |\n",
      "|    std                | 0.426    |\n",
      "|    value_loss         | 0.0393   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 45600    |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 228000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | -0.14    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45599    |\n",
      "|    policy_loss        | 0.114    |\n",
      "|    std                | 0.425    |\n",
      "|    value_loss         | 0.0201   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 242      |\n",
      "|    ep_rew_mean        | -118     |\n",
      "| time/                 |          |\n",
      "|    fps                | 718      |\n",
      "|    iterations         | 45700    |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 228500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.01    |\n",
      "|    explained_variance | -3.75    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45699    |\n",
      "|    policy_loss        | 0.494    |\n",
      "|    std                | 0.426    |\n",
      "|    value_loss         | 0.054    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 45800    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 229000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | 0.273    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45799    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    std                | 0.422    |\n",
      "|    value_loss         | 0.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 45900    |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 229500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | -0.505   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45899    |\n",
      "|    policy_loss        | -0.374   |\n",
      "|    std                | 0.423    |\n",
      "|    value_loss         | 0.067    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-100.01 +/- 0.23\n",
      "Episode length: 80.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 80       |\n",
      "|    mean_reward        | -100     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 230000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.99    |\n",
      "|    explained_variance | 0.0259   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45999    |\n",
      "|    policy_loss        | -0.0413  |\n",
      "|    std                | 0.424    |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 257      |\n",
      "|    ep_rew_mean     | -117     |\n",
      "| time/              |          |\n",
      "|    fps             | 719      |\n",
      "|    iterations      | 46000    |\n",
      "|    time_elapsed    | 319      |\n",
      "|    total_timesteps | 230000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 46100    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 230500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | 0.0542   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46099    |\n",
      "|    policy_loss        | -0.0102  |\n",
      "|    std                | 0.424    |\n",
      "|    value_loss         | 0.000158 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 46200    |\n",
      "|    time_elapsed       | 320      |\n",
      "|    total_timesteps    | 231000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.97    |\n",
      "|    explained_variance | -2.17    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46199    |\n",
      "|    policy_loss        | -0.0874  |\n",
      "|    std                | 0.42     |\n",
      "|    value_loss         | 0.00169  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 46300    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 231500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.95    |\n",
      "|    explained_variance | -1.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46299    |\n",
      "|    policy_loss        | -0.117   |\n",
      "|    std                | 0.418    |\n",
      "|    value_loss         | 0.00387  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 271      |\n",
      "|    ep_rew_mean        | -117     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 46400    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 232000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.94    |\n",
      "|    explained_variance | -0.143   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46399    |\n",
      "|    policy_loss        | -0.29    |\n",
      "|    std                | 0.416    |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | -116     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 46500    |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 232500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | -0.255   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46499    |\n",
      "|    policy_loss        | -0.246   |\n",
      "|    std                | 0.413    |\n",
      "|    value_loss         | 0.00652  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | -116     |\n",
      "| time/                 |          |\n",
      "|    fps                | 720      |\n",
      "|    iterations         | 46600    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 233000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.89    |\n",
      "|    explained_variance | -0.636   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46599    |\n",
      "|    policy_loss        | -0.265   |\n",
      "|    std                | 0.411    |\n",
      "|    value_loss         | 0.0283   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | -116     |\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 46700    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 233500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | -0.0574  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46699    |\n",
      "|    policy_loss        | 0.00695  |\n",
      "|    std                | 0.409    |\n",
      "|    value_loss         | 0.000492 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 301      |\n",
      "|    ep_rew_mean        | -116     |\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 46800    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 234000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.86    |\n",
      "|    explained_variance | -0.0542  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46799    |\n",
      "|    policy_loss        | -0.0386  |\n",
      "|    std                | 0.408    |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 301      |\n",
      "|    ep_rew_mean        | -116     |\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 46900    |\n",
      "|    time_elapsed       | 324      |\n",
      "|    total_timesteps    | 234500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.85    |\n",
      "|    explained_variance | -0.0741  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46899    |\n",
      "|    policy_loss        | 0.0856   |\n",
      "|    std                | 0.408    |\n",
      "|    value_loss         | 0.0036   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=-84.58 +/- 5.63\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -84.6    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 235000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.83    |\n",
      "|    explained_variance | -0.0214  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46999    |\n",
      "|    policy_loss        | -0.0259  |\n",
      "|    std                | 0.406    |\n",
      "|    value_loss         | 0.00158  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 301      |\n",
      "|    ep_rew_mean     | -116     |\n",
      "| time/              |          |\n",
      "|    fps             | 714      |\n",
      "|    iterations      | 47000    |\n",
      "|    time_elapsed    | 329      |\n",
      "|    total_timesteps | 235000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 47100    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 235500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.82    |\n",
      "|    explained_variance | 0.434    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47099    |\n",
      "|    policy_loss        | -0.16    |\n",
      "|    std                | 0.406    |\n",
      "|    value_loss         | 0.00797  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 47200    |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 236000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | -0.792   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47199    |\n",
      "|    policy_loss        | -0.0194  |\n",
      "|    std                | 0.403    |\n",
      "|    value_loss         | 0.00212  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 47300    |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 236500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | -0.912   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47299    |\n",
      "|    policy_loss        | -0.133   |\n",
      "|    std                | 0.404    |\n",
      "|    value_loss         | 0.0217   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 328      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 47400    |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 237000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.8     |\n",
      "|    explained_variance | -9.31    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47399    |\n",
      "|    policy_loss        | 0.56     |\n",
      "|    std                | 0.405    |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 328      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 47500    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 237500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.8     |\n",
      "|    explained_variance | 0.409    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47499    |\n",
      "|    policy_loss        | -0.0185  |\n",
      "|    std                | 0.405    |\n",
      "|    value_loss         | 0.000806 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 328      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 47600    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 238000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0.149    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47599    |\n",
      "|    policy_loss        | 0.102    |\n",
      "|    std                | 0.401    |\n",
      "|    value_loss         | 0.00637  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 328      |\n",
      "|    ep_rew_mean        | -115     |\n",
      "| time/                 |          |\n",
      "|    fps                | 715      |\n",
      "|    iterations         | 47700    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 238500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0.243    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47699    |\n",
      "|    policy_loss        | -0.0804  |\n",
      "|    std                | 0.401    |\n",
      "|    value_loss         | 0.00284  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 342      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 47800    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 239000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | -0.35    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47799    |\n",
      "|    policy_loss        | -0.252   |\n",
      "|    std                | 0.401    |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 342      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 47900    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 239500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.72    |\n",
      "|    explained_variance | -3.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47899    |\n",
      "|    policy_loss        | 0.192    |\n",
      "|    std                | 0.399    |\n",
      "|    value_loss         | 0.0384   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-120.39 +/- 5.98\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -120     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | -0.715   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47999    |\n",
      "|    policy_loss        | 0.289    |\n",
      "|    std                | 0.398    |\n",
      "|    value_loss         | 0.0351   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 342      |\n",
      "|    ep_rew_mean     | -114     |\n",
      "| time/              |          |\n",
      "|    fps             | 709      |\n",
      "|    iterations      | 48000    |\n",
      "|    time_elapsed    | 338      |\n",
      "|    total_timesteps | 240000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 356      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 48100    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 240500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | -0.0547  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48099    |\n",
      "|    policy_loss        | -0.0381  |\n",
      "|    std                | 0.396    |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 356      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 48200    |\n",
      "|    time_elapsed       | 339      |\n",
      "|    total_timesteps    | 241000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48199    |\n",
      "|    policy_loss        | 0.156    |\n",
      "|    std                | 0.395    |\n",
      "|    value_loss         | 0.0202   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 356      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 48300    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 241500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | -0.326   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48299    |\n",
      "|    policy_loss        | -0.0717  |\n",
      "|    std                | 0.392    |\n",
      "|    value_loss         | 0.00571  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 371      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 48400    |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 242000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | 0.0411   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48399    |\n",
      "|    policy_loss        | 0.111    |\n",
      "|    std                | 0.392    |\n",
      "|    value_loss         | 0.00758  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 371      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 48500    |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 242500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | -0.418   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48499    |\n",
      "|    policy_loss        | -0.116   |\n",
      "|    std                | 0.392    |\n",
      "|    value_loss         | 0.00488  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 371      |\n",
      "|    ep_rew_mean        | -114     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 48600    |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 243000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | 0.186    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48599    |\n",
      "|    policy_loss        | -0.413   |\n",
      "|    std                | 0.39     |\n",
      "|    value_loss         | 0.0204   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 385      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 48700    |\n",
      "|    time_elapsed       | 342      |\n",
      "|    total_timesteps    | 243500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | -0.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48699    |\n",
      "|    policy_loss        | -0.0314  |\n",
      "|    std                | 0.391    |\n",
      "|    value_loss         | 0.00149  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 385      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 48800    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 244000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | -0.29    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48799    |\n",
      "|    policy_loss        | 0.153    |\n",
      "|    std                | 0.389    |\n",
      "|    value_loss         | 0.00729  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 385      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 48900    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 244500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0.463    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48899    |\n",
      "|    policy_loss        | 0.00189  |\n",
      "|    std                | 0.388    |\n",
      "|    value_loss         | 0.000814 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=-70.16 +/- 5.64\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -70.2    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 245000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.59    |\n",
      "|    explained_variance | -0.836   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48999    |\n",
      "|    policy_loss        | 0.534    |\n",
      "|    std                | 0.387    |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 399      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    fps             | 704      |\n",
      "|    iterations      | 49000    |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 245000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 399      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 49100    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 245500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0.316    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49099    |\n",
      "|    policy_loss        | 0.0634   |\n",
      "|    std                | 0.388    |\n",
      "|    value_loss         | 0.00825  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 399      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 49200    |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 246000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | 0.00864  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49199    |\n",
      "|    policy_loss        | 0.0639   |\n",
      "|    std                | 0.387    |\n",
      "|    value_loss         | 0.0202   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 399      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 49300    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 246500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.59    |\n",
      "|    explained_variance | -0.195   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49299    |\n",
      "|    policy_loss        | -0.0867  |\n",
      "|    std                | 0.387    |\n",
      "|    value_loss         | 0.00379  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 414      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 49400    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 247000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.57    |\n",
      "|    explained_variance | -1.18    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49399    |\n",
      "|    policy_loss        | -0.0888  |\n",
      "|    std                | 0.384    |\n",
      "|    value_loss         | 0.00383  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 414      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 49500    |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 247500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49499    |\n",
      "|    policy_loss        | 0.00379  |\n",
      "|    std                | 0.383    |\n",
      "|    value_loss         | 0.0519   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 414      |\n",
      "|    ep_rew_mean        | -113     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 49600    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 248000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | -29.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49599    |\n",
      "|    policy_loss        | 2.44     |\n",
      "|    std                | 0.383    |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 49700    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 248500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | 0.525    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49699    |\n",
      "|    policy_loss        | 0.15     |\n",
      "|    std                | 0.38     |\n",
      "|    value_loss         | 0.0336   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 49800    |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 249000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0.819    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49799    |\n",
      "|    policy_loss        | -0.462   |\n",
      "|    std                | 0.381    |\n",
      "|    value_loss         | 0.0264   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | -112     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 49900    |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 249500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | 0.043    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49899    |\n",
      "|    policy_loss        | 0.244    |\n",
      "|    std                | 0.38     |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-108.97 +/- 0.23\n",
      "Episode length: 55.00 +/- 1.26\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 55       |\n",
      "|    mean_reward        | -109     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 250000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 0.406    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49999    |\n",
      "|    policy_loss        | -0.434   |\n",
      "|    std                | 0.378    |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 436      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    fps             | 707      |\n",
      "|    iterations      | 50000    |\n",
      "|    time_elapsed    | 353      |\n",
      "|    total_timesteps | 250000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 436      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 50100    |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 250500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | -10.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50099    |\n",
      "|    policy_loss        | 0.231    |\n",
      "|    std                | 0.377    |\n",
      "|    value_loss         | 0.0681   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 436      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 707      |\n",
      "|    iterations         | 50200    |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 251000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | -3.64    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50199    |\n",
      "|    policy_loss        | 0.0271   |\n",
      "|    std                | 0.375    |\n",
      "|    value_loss         | 0.00271  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 451      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 50300    |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 251500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | -0.678   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50299    |\n",
      "|    policy_loss        | -0.0539  |\n",
      "|    std                | 0.375    |\n",
      "|    value_loss         | 0.00939  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 451      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 50400    |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 252000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | -1.92    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50399    |\n",
      "|    policy_loss        | -0.569   |\n",
      "|    std                | 0.376    |\n",
      "|    value_loss         | 0.151    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 451      |\n",
      "|    ep_rew_mean        | -111     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 50500    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 252500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | -3.01    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50499    |\n",
      "|    policy_loss        | -0.665   |\n",
      "|    std                | 0.375    |\n",
      "|    value_loss         | 0.159    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 464      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 708      |\n",
      "|    iterations         | 50600    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 253000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | -1.58    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50599    |\n",
      "|    policy_loss        | -0.0235  |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.00987  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 464      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 50700    |\n",
      "|    time_elapsed       | 357      |\n",
      "|    total_timesteps    | 253500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | -8.25    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50699    |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    std                | 0.373    |\n",
      "|    value_loss         | 0.0818   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 464      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 50800    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 254000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | 0.865    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50799    |\n",
      "|    policy_loss        | -0.121   |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 464      |\n",
      "|    ep_rew_mean        | -110     |\n",
      "| time/                 |          |\n",
      "|    fps                | 709      |\n",
      "|    iterations         | 50900    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 254500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | -1.76    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50899    |\n",
      "|    policy_loss        | -0.346   |\n",
      "|    std                | 0.373    |\n",
      "|    value_loss         | 0.0321   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=-95.53 +/- 7.04\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -95.5    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 255000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0.524    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50999    |\n",
      "|    policy_loss        | 0.0702   |\n",
      "|    std                | 0.378    |\n",
      "|    value_loss         | 0.00251  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 479      |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    fps             | 703      |\n",
      "|    iterations      | 51000    |\n",
      "|    time_elapsed    | 362      |\n",
      "|    total_timesteps | 255000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 479      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 51100    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 255500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 0.4      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51099    |\n",
      "|    policy_loss        | 0.188    |\n",
      "|    std                | 0.376    |\n",
      "|    value_loss         | 0.0382   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 479      |\n",
      "|    ep_rew_mean        | -109     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 51200    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 256000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | 0.371    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51199    |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    std                | 0.379    |\n",
      "|    value_loss         | 0.0332   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 493      |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 51300    |\n",
      "|    time_elapsed       | 364      |\n",
      "|    total_timesteps    | 256500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | -3.06    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51299    |\n",
      "|    policy_loss        | 0.0552   |\n",
      "|    std                | 0.376    |\n",
      "|    value_loss         | 0.131    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 493      |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 51400    |\n",
      "|    time_elapsed       | 364      |\n",
      "|    total_timesteps    | 257000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | 0.895    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51399    |\n",
      "|    policy_loss        | 0.269    |\n",
      "|    std                | 0.376    |\n",
      "|    value_loss         | 0.0332   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 493      |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 51500    |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 257500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | -16.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51499    |\n",
      "|    policy_loss        | 0.0332   |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.029    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 509      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 704      |\n",
      "|    iterations         | 51600    |\n",
      "|    time_elapsed       | 366      |\n",
      "|    total_timesteps    | 258000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | -3.63    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51599    |\n",
      "|    policy_loss        | -0.311   |\n",
      "|    std                | 0.376    |\n",
      "|    value_loss         | 0.0387   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 509      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 51700    |\n",
      "|    time_elapsed       | 366      |\n",
      "|    total_timesteps    | 258500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | -1.19    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51699    |\n",
      "|    policy_loss        | -0.0104  |\n",
      "|    std                | 0.377    |\n",
      "|    value_loss         | 0.00317  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 509      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 51800    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 259000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | 0.542    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51799    |\n",
      "|    policy_loss        | 0.326    |\n",
      "|    std                | 0.375    |\n",
      "|    value_loss         | 0.0749   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 523      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 51900    |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 259500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | -3.86    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51899    |\n",
      "|    policy_loss        | -1.7     |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.608    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-51.84 +/- 13.70\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -51.8    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | -11.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51999    |\n",
      "|    policy_loss        | -0.335   |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.125    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 523      |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    fps             | 699      |\n",
      "|    iterations      | 52000    |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 260000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 523      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 699      |\n",
      "|    iterations         | 52100    |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 260500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | -9.23    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52099    |\n",
      "|    policy_loss        | -0.258   |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.812    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 523      |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 699      |\n",
      "|    iterations         | 52200    |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 261000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | -50.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52199    |\n",
      "|    policy_loss        | -0.0682  |\n",
      "|    std                | 0.37     |\n",
      "|    value_loss         | 0.066    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 536      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 699      |\n",
      "|    iterations         | 52300    |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 261500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0.795    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52299    |\n",
      "|    policy_loss        | -1.11    |\n",
      "|    std                | 0.372    |\n",
      "|    value_loss         | 0.305    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 536      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 699      |\n",
      "|    iterations         | 52400    |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 262000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0.701    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52399    |\n",
      "|    policy_loss        | -0.226   |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.0285   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 536      |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 700      |\n",
      "|    iterations         | 52500    |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 262500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0.383    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52499    |\n",
      "|    policy_loss        | -0.0345  |\n",
      "|    std                | 0.372    |\n",
      "|    value_loss         | 0.00723  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 544      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 700      |\n",
      "|    iterations         | 52600    |\n",
      "|    time_elapsed       | 375      |\n",
      "|    total_timesteps    | 263000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | -17.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52599    |\n",
      "|    policy_loss        | -0.839   |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.146    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 544      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 700      |\n",
      "|    iterations         | 52700    |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 263500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | -0.61    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52699    |\n",
      "|    policy_loss        | 0.0233   |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.0103   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 544      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 700      |\n",
      "|    iterations         | 52800    |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 264000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | -0.0602  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52799    |\n",
      "|    policy_loss        | -0.0445  |\n",
      "|    std                | 0.372    |\n",
      "|    value_loss         | 0.00625  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 558      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 701      |\n",
      "|    iterations         | 52900    |\n",
      "|    time_elapsed       | 377      |\n",
      "|    total_timesteps    | 264500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0.181    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52899    |\n",
      "|    policy_loss        | 0.0338   |\n",
      "|    std                | 0.373    |\n",
      "|    value_loss         | 0.00631  |\n",
      "------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-68.91 +/- 13.17\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -68.9    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 265000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | -0.669   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 52999    |\n",
      "|    policy_loss        | 0.103    |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 558      |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 695      |\n",
      "|    iterations      | 53000    |\n",
      "|    time_elapsed    | 381      |\n",
      "|    total_timesteps | 265000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 558      |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 695      |\n",
      "|    iterations         | 53100    |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 265500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | -0.273   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53099    |\n",
      "|    policy_loss        | -0.0938  |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.0176   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 571      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 695      |\n",
      "|    iterations         | 53200    |\n",
      "|    time_elapsed       | 382      |\n",
      "|    total_timesteps    | 266000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | -1.97    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53199    |\n",
      "|    policy_loss        | 0.162    |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.405    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 571      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 695      |\n",
      "|    iterations         | 53300    |\n",
      "|    time_elapsed       | 382      |\n",
      "|    total_timesteps    | 266500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | -0.513   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53299    |\n",
      "|    policy_loss        | -0.0751  |\n",
      "|    std                | 0.372    |\n",
      "|    value_loss         | 0.00673  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 571      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 696      |\n",
      "|    iterations         | 53400    |\n",
      "|    time_elapsed       | 383      |\n",
      "|    total_timesteps    | 267000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | 0.0125   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53399    |\n",
      "|    policy_loss        | -0.0439  |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 571      |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 696      |\n",
      "|    iterations         | 53500    |\n",
      "|    time_elapsed       | 384      |\n",
      "|    total_timesteps    | 267500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | -3.17    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53499    |\n",
      "|    policy_loss        | 0.0365   |\n",
      "|    std                | 0.373    |\n",
      "|    value_loss         | 0.00432  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 586      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 696      |\n",
      "|    iterations         | 53600    |\n",
      "|    time_elapsed       | 384      |\n",
      "|    total_timesteps    | 268000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | -0.49    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53599    |\n",
      "|    policy_loss        | 0.229    |\n",
      "|    std                | 0.374    |\n",
      "|    value_loss         | 0.0922   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 586      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 696      |\n",
      "|    iterations         | 53700    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 268500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | -0.377   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53699    |\n",
      "|    policy_loss        | -0.276   |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 586      |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 53800    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 269000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | -3.44    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53799    |\n",
      "|    policy_loss        | 0.000816 |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.0552   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 600      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 53900    |\n",
      "|    time_elapsed       | 386      |\n",
      "|    total_timesteps    | 269500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | -2.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53899    |\n",
      "|    policy_loss        | 0.204    |\n",
      "|    std                | 0.372    |\n",
      "|    value_loss         | 0.0202   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-117.77 +/- 12.33\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -118     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 270000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0.468    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53999    |\n",
      "|    policy_loss        | 0.275    |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.0639   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 600      |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    fps             | 691      |\n",
      "|    iterations      | 54000    |\n",
      "|    time_elapsed    | 390      |\n",
      "|    total_timesteps | 270000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 600      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 54100    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 270500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | -0.0839  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54099    |\n",
      "|    policy_loss        | 0.122    |\n",
      "|    std                | 0.372    |\n",
      "|    value_loss         | 0.00595  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 615      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 691      |\n",
      "|    iterations         | 54200    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 271000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0.372    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54199    |\n",
      "|    policy_loss        | -0.223   |\n",
      "|    std                | 0.371    |\n",
      "|    value_loss         | 0.0339   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 615      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 54300    |\n",
      "|    time_elapsed       | 392      |\n",
      "|    total_timesteps    | 271500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | 0.487    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54299    |\n",
      "|    policy_loss        | 0.00592  |\n",
      "|    std                | 0.368    |\n",
      "|    value_loss         | 0.00357  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 615      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 54400    |\n",
      "|    time_elapsed       | 392      |\n",
      "|    total_timesteps    | 272000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | -5.04    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54399    |\n",
      "|    policy_loss        | 0.255    |\n",
      "|    std                | 0.369    |\n",
      "|    value_loss         | 0.0562   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 630      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 54500    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 272500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | -0.403   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54499    |\n",
      "|    policy_loss        | 0.25     |\n",
      "|    std                | 0.37     |\n",
      "|    value_loss         | 0.0345   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 630      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 692      |\n",
      "|    iterations         | 54600    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 273000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0.277    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54599    |\n",
      "|    policy_loss        | -0.245   |\n",
      "|    std                | 0.368    |\n",
      "|    value_loss         | 0.021    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 630      |\n",
      "|    ep_rew_mean        | -102     |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 54700    |\n",
      "|    time_elapsed       | 394      |\n",
      "|    total_timesteps    | 273500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.0409   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54699    |\n",
      "|    policy_loss        | -0.197   |\n",
      "|    std                | 0.365    |\n",
      "|    value_loss         | 0.0201   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 641      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 54800    |\n",
      "|    time_elapsed       | 395      |\n",
      "|    total_timesteps    | 274000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | -2.06    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54799    |\n",
      "|    policy_loss        | 0.0985   |\n",
      "|    std                | 0.363    |\n",
      "|    value_loss         | 0.0197   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 641      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 693      |\n",
      "|    iterations         | 54900    |\n",
      "|    time_elapsed       | 395      |\n",
      "|    total_timesteps    | 274500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.166    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54899    |\n",
      "|    policy_loss        | 0.099    |\n",
      "|    std                | 0.363    |\n",
      "|    value_loss         | 0.0251   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-50.21 +/- 12.02\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -50.2    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 275000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.54     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54999    |\n",
      "|    policy_loss        | 0.0256   |\n",
      "|    std                | 0.362    |\n",
      "|    value_loss         | 0.00534  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 641      |\n",
      "|    ep_rew_mean     | -101     |\n",
      "| time/              |          |\n",
      "|    fps             | 688      |\n",
      "|    iterations      | 55000    |\n",
      "|    time_elapsed    | 399      |\n",
      "|    total_timesteps | 275000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 641      |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 55100    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 275500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0.116    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55099    |\n",
      "|    policy_loss        | -0.288   |\n",
      "|    std                | 0.36     |\n",
      "|    value_loss         | 0.0344   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 656      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 55200    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 276000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -17.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55199    |\n",
      "|    policy_loss        | -0.464   |\n",
      "|    std                | 0.357    |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 656      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 688      |\n",
      "|    iterations         | 55300    |\n",
      "|    time_elapsed       | 401      |\n",
      "|    total_timesteps    | 276500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.716    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55299    |\n",
      "|    policy_loss        | 0.0403   |\n",
      "|    std                | 0.357    |\n",
      "|    value_loss         | 0.00635  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 656      |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 55400    |\n",
      "|    time_elapsed       | 401      |\n",
      "|    total_timesteps    | 277000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | -0.0312  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55399    |\n",
      "|    policy_loss        | -0.0129  |\n",
      "|    std                | 0.358    |\n",
      "|    value_loss         | 6.84e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 656      |\n",
      "|    ep_rew_mean        | -98.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 55500    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 277500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.147    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55499    |\n",
      "|    policy_loss        | -0.346   |\n",
      "|    std                | 0.358    |\n",
      "|    value_loss         | 0.0648   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 656      |\n",
      "|    ep_rew_mean        | -98.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 55600    |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 278000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | -123     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55599    |\n",
      "|    policy_loss        | -0.226   |\n",
      "|    std                | 0.359    |\n",
      "|    value_loss         | 0.0107   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 656      |\n",
      "|    ep_rew_mean        | -98.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 55700    |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 278500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -2.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55699    |\n",
      "|    policy_loss        | -0.0254  |\n",
      "|    std                | 0.358    |\n",
      "|    value_loss         | 0.0514   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 672      |\n",
      "|    ep_rew_mean        | -98      |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 55800    |\n",
      "|    time_elapsed       | 404      |\n",
      "|    total_timesteps    | 279000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -63.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55799    |\n",
      "|    policy_loss        | 0.357    |\n",
      "|    std                | 0.358    |\n",
      "|    value_loss         | 0.443    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 672      |\n",
      "|    ep_rew_mean        | -98      |\n",
      "| time/                 |          |\n",
      "|    fps                | 690      |\n",
      "|    iterations         | 55900    |\n",
      "|    time_elapsed       | 404      |\n",
      "|    total_timesteps    | 279500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | -0.278   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55899    |\n",
      "|    policy_loss        | 0.373    |\n",
      "|    std                | 0.357    |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-28.02 +/- 2.00\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -28      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 280000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.698    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55999    |\n",
      "|    policy_loss        | -0.188   |\n",
      "|    std                | 0.356    |\n",
      "|    value_loss         | 0.0694   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 672      |\n",
      "|    ep_rew_mean     | -98      |\n",
      "| time/              |          |\n",
      "|    fps             | 684      |\n",
      "|    iterations      | 56000    |\n",
      "|    time_elapsed    | 408      |\n",
      "|    total_timesteps | 280000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 681      |\n",
      "|    ep_rew_mean        | -96.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 56100    |\n",
      "|    time_elapsed       | 409      |\n",
      "|    total_timesteps    | 280500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.21     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56099    |\n",
      "|    policy_loss        | -23.9    |\n",
      "|    std                | 0.356    |\n",
      "|    value_loss         | 874      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 678      |\n",
      "|    ep_rew_mean        | -96.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 56200    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 281000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -13.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56199    |\n",
      "|    policy_loss        | 1.85     |\n",
      "|    std                | 0.357    |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 678      |\n",
      "|    ep_rew_mean        | -96.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 56300    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 281500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -0.178   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56299    |\n",
      "|    policy_loss        | 0.18     |\n",
      "|    std                | 0.356    |\n",
      "|    value_loss         | 0.028    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 678      |\n",
      "|    ep_rew_mean        | -96.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 56400    |\n",
      "|    time_elapsed       | 411      |\n",
      "|    total_timesteps    | 282000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -0.721   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56399    |\n",
      "|    policy_loss        | -1.31    |\n",
      "|    std                | 0.355    |\n",
      "|    value_loss         | 0.156    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 693      |\n",
      "|    ep_rew_mean        | -95.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 685      |\n",
      "|    iterations         | 56500    |\n",
      "|    time_elapsed       | 411      |\n",
      "|    total_timesteps    | 282500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | -0.204   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56499    |\n",
      "|    policy_loss        | -0.236   |\n",
      "|    std                | 0.354    |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 693      |\n",
      "|    ep_rew_mean        | -95.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 56600    |\n",
      "|    time_elapsed       | 412      |\n",
      "|    total_timesteps    | 283000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.811    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56599    |\n",
      "|    policy_loss        | 0.104    |\n",
      "|    std                | 0.355    |\n",
      "|    value_loss         | 0.0245   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 693      |\n",
      "|    ep_rew_mean        | -95.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 56700    |\n",
      "|    time_elapsed       | 413      |\n",
      "|    total_timesteps    | 283500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | -0.339   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56699    |\n",
      "|    policy_loss        | -0.508   |\n",
      "|    std                | 0.355    |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 693      |\n",
      "|    ep_rew_mean        | -95.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 56800    |\n",
      "|    time_elapsed       | 413      |\n",
      "|    total_timesteps    | 284000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | -0.0652  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56799    |\n",
      "|    policy_loss        | -0.171   |\n",
      "|    std                | 0.353    |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 709      |\n",
      "|    ep_rew_mean        | -94.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 56900    |\n",
      "|    time_elapsed       | 414      |\n",
      "|    total_timesteps    | 284500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.743    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56899    |\n",
      "|    policy_loss        | -0.111   |\n",
      "|    std                | 0.353    |\n",
      "|    value_loss         | 0.0189   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-117.84 +/- 68.29\n",
      "Episode length: 1368.60 +/- 316.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.37e+03 |\n",
      "|    mean_reward        | -118     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 285000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | -0.338   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56999    |\n",
      "|    policy_loss        | 0.0933   |\n",
      "|    std                | 0.354    |\n",
      "|    value_loss         | 0.024    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 709      |\n",
      "|    ep_rew_mean     | -94.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 682      |\n",
      "|    iterations      | 57000    |\n",
      "|    time_elapsed    | 417      |\n",
      "|    total_timesteps | 285000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 709      |\n",
      "|    ep_rew_mean        | -94.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 57100    |\n",
      "|    time_elapsed       | 418      |\n",
      "|    total_timesteps    | 285500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | -1.33    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57099    |\n",
      "|    policy_loss        | -0.341   |\n",
      "|    std                | 0.354    |\n",
      "|    value_loss         | 0.0459   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 724      |\n",
      "|    ep_rew_mean        | -94.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 682      |\n",
      "|    iterations         | 57200    |\n",
      "|    time_elapsed       | 418      |\n",
      "|    total_timesteps    | 286000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.815    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57199    |\n",
      "|    policy_loss        | 0.0499   |\n",
      "|    std                | 0.353    |\n",
      "|    value_loss         | 0.016    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 724      |\n",
      "|    ep_rew_mean        | -94.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 57300    |\n",
      "|    time_elapsed       | 419      |\n",
      "|    total_timesteps    | 286500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.879    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57299    |\n",
      "|    policy_loss        | -0.135   |\n",
      "|    std                | 0.355    |\n",
      "|    value_loss         | 0.00824  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 724      |\n",
      "|    ep_rew_mean        | -94.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 57400    |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 287000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.778    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57399    |\n",
      "|    policy_loss        | 0.023    |\n",
      "|    std                | 0.355    |\n",
      "|    value_loss         | 0.00982  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 739      |\n",
      "|    ep_rew_mean        | -94.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 57500    |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 287500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57499    |\n",
      "|    policy_loss        | -0.594   |\n",
      "|    std                | 0.355    |\n",
      "|    value_loss         | 0.187    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 739      |\n",
      "|    ep_rew_mean        | -94.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 57600    |\n",
      "|    time_elapsed       | 421      |\n",
      "|    total_timesteps    | 288000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | -0.152   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57599    |\n",
      "|    policy_loss        | 0.68     |\n",
      "|    std                | 0.357    |\n",
      "|    value_loss         | 0.104    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 739      |\n",
      "|    ep_rew_mean        | -94.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 57700    |\n",
      "|    time_elapsed       | 421      |\n",
      "|    total_timesteps    | 288500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | -2.93    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57699    |\n",
      "|    policy_loss        | 0.0489   |\n",
      "|    std                | 0.357    |\n",
      "|    value_loss         | 0.0157   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 754      |\n",
      "|    ep_rew_mean        | -94.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 57800    |\n",
      "|    time_elapsed       | 422      |\n",
      "|    total_timesteps    | 289000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.542    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57799    |\n",
      "|    policy_loss        | 0.24     |\n",
      "|    std                | 0.357    |\n",
      "|    value_loss         | 0.0181   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 754      |\n",
      "|    ep_rew_mean        | -94.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 684      |\n",
      "|    iterations         | 57900    |\n",
      "|    time_elapsed       | 422      |\n",
      "|    total_timesteps    | 289500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.451    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57899    |\n",
      "|    policy_loss        | -0.00192 |\n",
      "|    std                | 0.356    |\n",
      "|    value_loss         | 6.23e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-135.49 +/- 5.90\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -135     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 290000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.706    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 57999    |\n",
      "|    policy_loss        | -0.306   |\n",
      "|    std                | 0.356    |\n",
      "|    value_loss         | 0.0196   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 754      |\n",
      "|    ep_rew_mean     | -94.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 679      |\n",
      "|    iterations      | 58000    |\n",
      "|    time_elapsed    | 426      |\n",
      "|    total_timesteps | 290000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 769      |\n",
      "|    ep_rew_mean        | -95      |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 58100    |\n",
      "|    time_elapsed       | 427      |\n",
      "|    total_timesteps    | 290500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | -8.69    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58099    |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    std                | 0.353    |\n",
      "|    value_loss         | 0.0277   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 769      |\n",
      "|    ep_rew_mean        | -95      |\n",
      "| time/                 |          |\n",
      "|    fps                | 679      |\n",
      "|    iterations         | 58200    |\n",
      "|    time_elapsed       | 427      |\n",
      "|    total_timesteps    | 291000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | -41      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58199    |\n",
      "|    policy_loss        | 0.28     |\n",
      "|    std                | 0.35     |\n",
      "|    value_loss         | 0.286    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 778      |\n",
      "|    ep_rew_mean        | -96.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 58300    |\n",
      "|    time_elapsed       | 428      |\n",
      "|    total_timesteps    | 291500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | -33.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58299    |\n",
      "|    policy_loss        | -0.871   |\n",
      "|    std                | 0.348    |\n",
      "|    value_loss         | 5.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 779      |\n",
      "|    ep_rew_mean        | -96      |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 58400    |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 292000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | -34.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58399    |\n",
      "|    policy_loss        | -0.165   |\n",
      "|    std                | 0.346    |\n",
      "|    value_loss         | 0.0264   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 787      |\n",
      "|    ep_rew_mean        | -96.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 58500    |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 292500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.841    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58499    |\n",
      "|    policy_loss        | -0.271   |\n",
      "|    std                | 0.344    |\n",
      "|    value_loss         | 0.181    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 787      |\n",
      "|    ep_rew_mean        | -96.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 58600    |\n",
      "|    time_elapsed       | 430      |\n",
      "|    total_timesteps    | 293000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.919    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58599    |\n",
      "|    policy_loss        | 0.303    |\n",
      "|    std                | 0.342    |\n",
      "|    value_loss         | 0.157    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 790      |\n",
      "|    ep_rew_mean        | -96.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 58700    |\n",
      "|    time_elapsed       | 430      |\n",
      "|    total_timesteps    | 293500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | 0.895    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58699    |\n",
      "|    policy_loss        | -0.0688  |\n",
      "|    std                | 0.342    |\n",
      "|    value_loss         | 0.021    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 789      |\n",
      "|    ep_rew_mean        | -96.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 58800    |\n",
      "|    time_elapsed       | 431      |\n",
      "|    total_timesteps    | 294000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | -268     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58799    |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    std                | 0.343    |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 789      |\n",
      "|    ep_rew_mean        | -96.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 58900    |\n",
      "|    time_elapsed       | 432      |\n",
      "|    total_timesteps    | 294500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | -29.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58899    |\n",
      "|    policy_loss        | -0.315   |\n",
      "|    std                | 0.341    |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=-125.41 +/- 12.20\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.6e+03  |\n",
      "|    mean_reward        | -125     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 295000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.941    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58999    |\n",
      "|    policy_loss        | 0.102    |\n",
      "|    std                | 0.34     |\n",
      "|    value_loss         | 0.0389   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 789      |\n",
      "|    ep_rew_mean     | -96.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 676      |\n",
      "|    iterations      | 59000    |\n",
      "|    time_elapsed    | 436      |\n",
      "|    total_timesteps | 295000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 805      |\n",
      "|    ep_rew_mean        | -96.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 676      |\n",
      "|    iterations         | 59100    |\n",
      "|    time_elapsed       | 436      |\n",
      "|    total_timesteps    | 295500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0.493    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59099    |\n",
      "|    policy_loss        | -0.328   |\n",
      "|    std                | 0.341    |\n",
      "|    value_loss         | 0.131    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 804      |\n",
      "|    ep_rew_mean        | -96.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 59200    |\n",
      "|    time_elapsed       | 437      |\n",
      "|    total_timesteps    | 296000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.000636 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59199    |\n",
      "|    policy_loss        | -0.151   |\n",
      "|    std                | 0.342    |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 804      |\n",
      "|    ep_rew_mean        | -96.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 59300    |\n",
      "|    time_elapsed       | 437      |\n",
      "|    total_timesteps    | 296500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | -0.291   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59299    |\n",
      "|    policy_loss        | -0.00567 |\n",
      "|    std                | 0.342    |\n",
      "|    value_loss         | 5.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 804      |\n",
      "|    ep_rew_mean        | -96.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 59400    |\n",
      "|    time_elapsed       | 438      |\n",
      "|    total_timesteps    | 297000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.655    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59399    |\n",
      "|    policy_loss        | -0.00755 |\n",
      "|    std                | 0.339    |\n",
      "|    value_loss         | 3.94e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 820      |\n",
      "|    ep_rew_mean        | -96.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 59500    |\n",
      "|    time_elapsed       | 438      |\n",
      "|    total_timesteps    | 297500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | -0.166   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59499    |\n",
      "|    policy_loss        | -0.00953 |\n",
      "|    std                | 0.335    |\n",
      "|    value_loss         | 0.000135 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 820      |\n",
      "|    ep_rew_mean        | -96.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 59600    |\n",
      "|    time_elapsed       | 439      |\n",
      "|    total_timesteps    | 298000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | -0.0633  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59599    |\n",
      "|    policy_loss        | -0.0141  |\n",
      "|    std                | 0.335    |\n",
      "|    value_loss         | 0.000667 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 820      |\n",
      "|    ep_rew_mean        | -96.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 59700    |\n",
      "|    time_elapsed       | 440      |\n",
      "|    total_timesteps    | 298500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | 0.527    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59699    |\n",
      "|    policy_loss        | -0.042   |\n",
      "|    std                | 0.334    |\n",
      "|    value_loss         | 0.0249   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 835      |\n",
      "|    ep_rew_mean        | -96.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 59800    |\n",
      "|    time_elapsed       | 440      |\n",
      "|    total_timesteps    | 299000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.973   |\n",
      "|    explained_variance | -6.8     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59799    |\n",
      "|    policy_loss        | 0.511    |\n",
      "|    std                | 0.331    |\n",
      "|    value_loss         | 0.305    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 835      |\n",
      "|    ep_rew_mean        | -96.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 678      |\n",
      "|    iterations         | 59900    |\n",
      "|    time_elapsed       | 441      |\n",
      "|    total_timesteps    | 299500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.939   |\n",
      "|    explained_variance | 0.00111  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59899    |\n",
      "|    policy_loss        | -0.0116  |\n",
      "|    std                | 0.329    |\n",
      "|    value_loss         | 5.98e-05 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-109.92 +/- 0.04\n",
      "Episode length: 56.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 56       |\n",
      "|    mean_reward        | -110     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 300000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.886   |\n",
      "|    explained_variance | -0.907   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59999    |\n",
      "|    policy_loss        | 0.00649  |\n",
      "|    std                | 0.326    |\n",
      "|    value_loss         | 0.000201 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 835      |\n",
      "|    ep_rew_mean     | -96.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 678      |\n",
      "|    iterations      | 60000    |\n",
      "|    time_elapsed    | 441      |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Monitor(gym.make(\"BipedalWalker-v3\"))\n",
    "eval_env = Monitor(gym.make(\"BipedalWalker-v3\"))\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./models/a2c/\",\n",
    "    log_path=\"./logs/a2c/\",\n",
    "    eval_freq=5000,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./a2c_tensorboard/\")\n",
    "model.learn(total_timesteps=300_000, callback=eval_callback)\n",
    "model.save(\"./models/a2c/best_model\")\n",
    "\n",
    "# === Graficar recompensas ===\n",
    "eval_file_npz = \"./logs/a2c/evaluations.npz\"\n",
    "\n",
    "if os.path.exists(eval_file_npz):\n",
    "    data = np.load(eval_file_npz)\n",
    "    timesteps = data[\"timesteps\"]\n",
    "    results = data[\"results\"]\n",
    "\n",
    "    # Promedio y desviación de recompensas\n",
    "    mean_rewards = results.mean(axis=1)\n",
    "    std_rewards = results.std(axis=1)\n",
    "\n",
    "    plt.plot(timesteps, mean_rewards, label=\"Evaluación (promedio)\")\n",
    "    plt.fill_between(\n",
    "        timesteps,\n",
    "        mean_rewards - std_rewards,\n",
    "        mean_rewards + std_rewards,\n",
    "        alpha=0.2,\n",
    "        label=\"Desvío estándar\",\n",
    "    )\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Recompensa media\")\n",
    "    plt.title(\"Evolución A2C - BipedalWalker-v3\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No se encontró evaluations.npz — puede que el callback no haya guardado evaluaciones.\")\n",
    "    \n",
    "# === Cargar y evaluar ===\n",
    "model = A2C.load(\"./models/a2c/best_model\")\n",
    "obs, _ = env.reset()\n",
    "for step in range(1500):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    if done or truncated:\n",
    "        obs, _ = env.reset()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c290bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./sac_tensorboard/SAC_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 90.5     |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 221      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 362      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.97    |\n",
      "|    critic_loss     | 39.8     |\n",
      "|    ent_coef        | 0.925    |\n",
      "|    ent_coef_loss   | -0.519   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 261      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 269      |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 173      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2152     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.6    |\n",
      "|    critic_loss     | 2.93     |\n",
      "|    ent_coef        | 0.547    |\n",
      "|    ent_coef_loss   | -3.61    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2051     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 171      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 2482     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16      |\n",
      "|    critic_loss     | 11       |\n",
      "|    ent_coef        | 0.498    |\n",
      "|    ent_coef_loss   | -4.02    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2381     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 177      |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 171      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 2830     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.9    |\n",
      "|    critic_loss     | 9.92     |\n",
      "|    ent_coef        | 0.452    |\n",
      "|    ent_coef_loss   | -4.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2729     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 159      |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 170      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 3182     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.5    |\n",
      "|    critic_loss     | 27.2     |\n",
      "|    ent_coef        | 0.41     |\n",
      "|    ent_coef_loss   | -4.78    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3081     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 144      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 3449     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.8    |\n",
      "|    critic_loss     | 41.3     |\n",
      "|    ent_coef        | 0.381    |\n",
      "|    ent_coef_loss   | -4.87    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3348     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 133      |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 3715     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.9    |\n",
      "|    critic_loss     | 11       |\n",
      "|    ent_coef        | 0.354    |\n",
      "|    ent_coef_loss   | -5.16    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3614     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 126      |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 4034     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.4    |\n",
      "|    critic_loss     | 15.1     |\n",
      "|    ent_coef        | 0.325    |\n",
      "|    ent_coef_loss   | -5.49    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3933     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 121      |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 169      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 4352     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.7    |\n",
      "|    critic_loss     | 7.42     |\n",
      "|    ent_coef        | 0.299    |\n",
      "|    ent_coef_loss   | -5.48    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4251     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 116      |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 168      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 4646     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.4    |\n",
      "|    critic_loss     | 9.76     |\n",
      "|    ent_coef        | 0.276    |\n",
      "|    ent_coef_loss   | -5.77    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4545     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-86.85 +/- 6.75\n",
      "Episode length: 1302.60 +/- 594.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.3e+03  |\n",
      "|    mean_reward     | -86.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 6.8      |\n",
      "|    ent_coef        | 0.251    |\n",
      "|    ent_coef_loss   | -5.99    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4899     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 118      |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 5196     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.6    |\n",
      "|    critic_loss     | 5.85     |\n",
      "|    ent_coef        | 0.238    |\n",
      "|    ent_coef_loss   | -6.45    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5095     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 124      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 5960     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.7    |\n",
      "|    critic_loss     | 8.47     |\n",
      "|    ent_coef        | 0.194    |\n",
      "|    ent_coef_loss   | -6.29    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5859     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 122      |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 154      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 6335     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.3    |\n",
      "|    critic_loss     | 6.09     |\n",
      "|    ent_coef        | 0.176    |\n",
      "|    ent_coef_loss   | -6.34    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6234     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 143      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 156      |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 7995     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.14    |\n",
      "|    critic_loss     | 6.23     |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | -5.28    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7894     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-104.35 +/- 0.39\n",
      "Episode length: 61.20 +/- 2.14\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 61.2     |\n",
      "|    mean_reward     | -104     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.7    |\n",
      "|    critic_loss     | 5.95     |\n",
      "|    ent_coef        | 0.0731   |\n",
      "|    ent_coef_loss   | -3.79    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 167      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 157      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 10033    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.8    |\n",
      "|    critic_loss     | 5.93     |\n",
      "|    ent_coef        | 0.0726   |\n",
      "|    ent_coef_loss   | -3.74    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9932     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 161      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 157      |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 10333    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.11    |\n",
      "|    critic_loss     | 4.87     |\n",
      "|    ent_coef        | 0.0683   |\n",
      "|    ent_coef_loss   | -2.39    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10232    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-67.18 +/- 11.01\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -67.2    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 15000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 3.31     |\n",
      "|    ent_coef        | 0.0351   |\n",
      "|    ent_coef_loss   | -0.0473  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14899    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 229      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 154      |\n",
      "|    time_elapsed    | 100      |\n",
      "|    total_timesteps | 15581    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.88    |\n",
      "|    critic_loss     | 6        |\n",
      "|    ent_coef        | 0.0341   |\n",
      "|    ent_coef_loss   | 1.16     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15480    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-114.95 +/- 22.13\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -115     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.3    |\n",
      "|    critic_loss     | 2.9      |\n",
      "|    ent_coef        | 0.0436   |\n",
      "|    ent_coef_loss   | 1.17     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 285      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 20539    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13      |\n",
      "|    critic_loss     | 3.35     |\n",
      "|    ent_coef        | 0.042    |\n",
      "|    ent_coef_loss   | -0.56    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20438    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 279      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 21168    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.7    |\n",
      "|    critic_loss     | 2.74     |\n",
      "|    ent_coef        | 0.0368   |\n",
      "|    ent_coef_loss   | -2.46    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21067    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 141      |\n",
      "|    total_timesteps | 21693    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.7    |\n",
      "|    critic_loss     | 3.02     |\n",
      "|    ent_coef        | 0.0366   |\n",
      "|    ent_coef_loss   | 0.215    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21592    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 283      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 154      |\n",
      "|    total_timesteps | 23789    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.2    |\n",
      "|    critic_loss     | 2.96     |\n",
      "|    ent_coef        | 0.0405   |\n",
      "|    ent_coef_loss   | 0.582    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23688    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-124.15 +/- 4.81\n",
      "Episode length: 207.40 +/- 21.10\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 207      |\n",
      "|    mean_reward     | -124     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 25000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.8    |\n",
      "|    critic_loss     | 3.46     |\n",
      "|    ent_coef        | 0.038    |\n",
      "|    ent_coef_loss   | 0.509    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 293      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 154      |\n",
      "|    time_elapsed    | 167      |\n",
      "|    total_timesteps | 25752    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11      |\n",
      "|    critic_loss     | 3.06     |\n",
      "|    ent_coef        | 0.0345   |\n",
      "|    ent_coef_loss   | -1.3     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25651    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 287      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 154      |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 26399    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.9    |\n",
      "|    critic_loss     | 2.72     |\n",
      "|    ent_coef        | 0.0329   |\n",
      "|    ent_coef_loss   | 0.101    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26298    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 189      |\n",
      "|    total_timesteps | 29393    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.34    |\n",
      "|    critic_loss     | 1.89     |\n",
      "|    ent_coef        | 0.0232   |\n",
      "|    ent_coef_loss   | -0.631   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29292    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-74.54 +/- 4.56\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -74.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.88    |\n",
      "|    critic_loss     | 4.2      |\n",
      "|    ent_coef        | 0.0231   |\n",
      "|    ent_coef_loss   | -0.636   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29899    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-83.63 +/- 10.32\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -83.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 35000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.46    |\n",
      "|    critic_loss     | 2.13     |\n",
      "|    ent_coef        | 0.0185   |\n",
      "|    ent_coef_loss   | 0.749    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 358      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 236      |\n",
      "|    total_timesteps | 35793    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.96    |\n",
      "|    critic_loss     | 2.37     |\n",
      "|    ent_coef        | 0.0185   |\n",
      "|    ent_coef_loss   | 0.908    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35692    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 392      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 39533    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.47    |\n",
      "|    critic_loss     | 1.71     |\n",
      "|    ent_coef        | 0.0186   |\n",
      "|    ent_coef_loss   | 0.49     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39432    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 378      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 261      |\n",
      "|    total_timesteps | 39934    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.21    |\n",
      "|    critic_loss     | 1.97     |\n",
      "|    ent_coef        | 0.0184   |\n",
      "|    ent_coef_loss   | -0.294   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39833    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-103.09 +/- 15.71\n",
      "Episode length: 406.60 +/- 598.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 407      |\n",
      "|    mean_reward     | -103     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.08    |\n",
      "|    critic_loss     | 2.52     |\n",
      "|    ent_coef        | 0.0184   |\n",
      "|    ent_coef_loss   | 0.518    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 407      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 282      |\n",
      "|    total_timesteps | 43228    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.41    |\n",
      "|    critic_loss     | 1.5      |\n",
      "|    ent_coef        | 0.0161   |\n",
      "|    ent_coef_loss   | -1.71    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 43127    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-86.76 +/- 20.12\n",
      "Episode length: 1026.80 +/- 703.12\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.03e+03 |\n",
      "|    mean_reward     | -86.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 45000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.19    |\n",
      "|    critic_loss     | 1.89     |\n",
      "|    ent_coef        | 0.0146   |\n",
      "|    ent_coef_loss   | 0.738    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 44899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 424      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 45249    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.619   |\n",
      "|    critic_loss     | 2.39     |\n",
      "|    ent_coef        | 0.0147   |\n",
      "|    ent_coef_loss   | 2.43     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 45148    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 438      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 307      |\n",
      "|    total_timesteps | 47023    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.78    |\n",
      "|    critic_loss     | 5.06     |\n",
      "|    ent_coef        | 0.0161   |\n",
      "|    ent_coef_loss   | -0.548   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 46922    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-106.90 +/- 20.88\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -107     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 50000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.413    |\n",
      "|    critic_loss     | 1.95     |\n",
      "|    ent_coef        | 0.0169   |\n",
      "|    ent_coef_loss   | -0.481   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 49899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 469      |\n",
      "|    ep_rew_mean     | -115     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 332      |\n",
      "|    total_timesteps | 50391    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.11     |\n",
      "|    critic_loss     | 2.33     |\n",
      "|    ent_coef        | 0.0167   |\n",
      "|    ent_coef_loss   | -0.0332  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 50290    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 507      |\n",
      "|    ep_rew_mean     | -116     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 54370    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.466   |\n",
      "|    critic_loss     | 1.56     |\n",
      "|    ent_coef        | 0.0155   |\n",
      "|    ent_coef_loss   | -0.82    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 54269    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-118.67 +/- 26.58\n",
      "Episode length: 540.60 +/- 535.01\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 541      |\n",
      "|    mean_reward     | -119     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 55000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.01    |\n",
      "|    critic_loss     | 2.45     |\n",
      "|    ent_coef        | 0.0164   |\n",
      "|    ent_coef_loss   | 0.824    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 54899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 545      |\n",
      "|    ep_rew_mean     | -116     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 383      |\n",
      "|    total_timesteps | 58509    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.1     |\n",
      "|    critic_loss     | 1.26     |\n",
      "|    ent_coef        | 0.013    |\n",
      "|    ent_coef_loss   | 0.597    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 58408    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-147.40 +/- 13.54\n",
      "Episode length: 453.40 +/- 214.75\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 453      |\n",
      "|    mean_reward     | -147     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.113   |\n",
      "|    critic_loss     | 1.77     |\n",
      "|    ent_coef        | 0.0139   |\n",
      "|    ent_coef_loss   | 0.687    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 59899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 562      |\n",
      "|    ep_rew_mean     | -117     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 397      |\n",
      "|    total_timesteps | 60558    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.19     |\n",
      "|    critic_loss     | 1.27     |\n",
      "|    ent_coef        | 0.0145   |\n",
      "|    ent_coef_loss   | 1.38     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 60457    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-142.85 +/- 32.60\n",
      "Episode length: 774.60 +/- 582.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 775      |\n",
      "|    mean_reward     | -143     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 65000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.13    |\n",
      "|    critic_loss     | 2.06     |\n",
      "|    ent_coef        | 0.0137   |\n",
      "|    ent_coef_loss   | -0.401   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 64899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 604      |\n",
      "|    ep_rew_mean     | -116     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 426      |\n",
      "|    total_timesteps | 65020    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.45     |\n",
      "|    critic_loss     | 1.78     |\n",
      "|    ent_coef        | 0.0137   |\n",
      "|    ent_coef_loss   | 0.698    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 64919    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-115.27 +/- 6.79\n",
      "Episode length: 231.80 +/- 132.31\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 232      |\n",
      "|    mean_reward     | -115     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 70000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.13     |\n",
      "|    critic_loss     | 1.08     |\n",
      "|    ent_coef        | 0.0114   |\n",
      "|    ent_coef_loss   | -1.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 69899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 657      |\n",
      "|    ep_rew_mean     | -115     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 462      |\n",
      "|    total_timesteps | 70894    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.2      |\n",
      "|    critic_loss     | 1.7      |\n",
      "|    ent_coef        | 0.0115   |\n",
      "|    ent_coef_loss   | 3.09     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 70793    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-87.79 +/- 19.03\n",
      "Episode length: 1301.80 +/- 596.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.3e+03  |\n",
      "|    mean_reward     | -87.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 75000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.745   |\n",
      "|    critic_loss     | 0.886    |\n",
      "|    ent_coef        | 0.0132   |\n",
      "|    ent_coef_loss   | 0.206    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 74899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 694      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 492      |\n",
      "|    total_timesteps | 75312    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.907    |\n",
      "|    critic_loss     | 1.08     |\n",
      "|    ent_coef        | 0.0132   |\n",
      "|    ent_coef_loss   | 0.663    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 75211    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-83.29 +/- 14.02\n",
      "Episode length: 1299.00 +/- 602.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.3e+03  |\n",
      "|    mean_reward     | -83.3    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.00506 |\n",
      "|    critic_loss     | 0.814    |\n",
      "|    ent_coef        | 0.0112   |\n",
      "|    ent_coef_loss   | -0.129   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 79899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 745      |\n",
      "|    ep_rew_mean     | -113     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 528      |\n",
      "|    total_timesteps | 80836    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.21    |\n",
      "|    critic_loss     | 0.952    |\n",
      "|    ent_coef        | 0.0108   |\n",
      "|    ent_coef_loss   | -0.597   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 80735    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-66.50 +/- 9.39\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -66.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 85000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.51     |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.0107   |\n",
      "|    ent_coef_loss   | 0.352    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 84899    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 781      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 564      |\n",
      "|    total_timesteps | 86077    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.314   |\n",
      "|    critic_loss     | 1.33     |\n",
      "|    ent_coef        | 0.0102   |\n",
      "|    ent_coef_loss   | 1.32     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 85976    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-118.69 +/- 0.44\n",
      "Episode length: 73.40 +/- 7.23\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 73.4     |\n",
      "|    mean_reward     | -119     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 90000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.24     |\n",
      "|    critic_loss     | 0.762    |\n",
      "|    ent_coef        | 0.0106   |\n",
      "|    ent_coef_loss   | 1.13     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 89899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 806      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 591      |\n",
      "|    total_timesteps | 90610    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.09     |\n",
      "|    critic_loss     | 1.15     |\n",
      "|    ent_coef        | 0.0109   |\n",
      "|    ent_coef_loss   | -1.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 90509    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 842      |\n",
      "|    ep_rew_mean     | -112     |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 615      |\n",
      "|    total_timesteps | 94530    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.65    |\n",
      "|    critic_loss     | 5.04     |\n",
      "|    ent_coef        | 0.0178   |\n",
      "|    ent_coef_loss   | 0.181    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 94429    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-109.29 +/- 7.99\n",
      "Episode length: 500.40 +/- 553.68\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | -109     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 95000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.18    |\n",
      "|    critic_loss     | 2.9      |\n",
      "|    ent_coef        | 0.018    |\n",
      "|    ent_coef_loss   | 1.07     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 94899    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-78.61 +/- 20.62\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -78.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.6    |\n",
      "|    critic_loss     | 3.32     |\n",
      "|    ent_coef        | 0.0314   |\n",
      "|    ent_coef_loss   | 1.74     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 99899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 853      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 660      |\n",
      "|    total_timesteps | 100930   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.5    |\n",
      "|    critic_loss     | 4.47     |\n",
      "|    ent_coef        | 0.0349   |\n",
      "|    ent_coef_loss   | -0.441   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 100829   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-81.26 +/- 16.66\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -81.3    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 105000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 2.2      |\n",
      "|    ent_coef        | 0.0276   |\n",
      "|    ent_coef_loss   | -0.717   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 104899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 868      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 702      |\n",
      "|    total_timesteps | 107330   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.7    |\n",
      "|    critic_loss     | 3.22     |\n",
      "|    ent_coef        | 0.0274   |\n",
      "|    ent_coef_loss   | 1.08     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 107229   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-59.05 +/- 30.72\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -59.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 110000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.1    |\n",
      "|    critic_loss     | 1.54     |\n",
      "|    ent_coef        | 0.0218   |\n",
      "|    ent_coef_loss   | -0.336   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 109899   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 926      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 745      |\n",
      "|    total_timesteps | 113730   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.3    |\n",
      "|    critic_loss     | 1.46     |\n",
      "|    ent_coef        | 0.0184   |\n",
      "|    ent_coef_loss   | 0.81     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 113629   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-101.49 +/- 36.71\n",
      "Episode length: 1111.20 +/- 602.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.11e+03 |\n",
      "|    mean_reward     | -101     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 115000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 1.85     |\n",
      "|    ent_coef        | 0.0184   |\n",
      "|    ent_coef_loss   | 0.642    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 114899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 960      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 772      |\n",
      "|    total_timesteps | 117710   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 1.17     |\n",
      "|    ent_coef        | 0.0175   |\n",
      "|    ent_coef_loss   | -0.971   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 117609   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-98.85 +/- 14.06\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -98.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 120000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.6    |\n",
      "|    critic_loss     | 1.54     |\n",
      "|    ent_coef        | 0.0146   |\n",
      "|    ent_coef_loss   | -0.346   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 119899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 994      |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 810      |\n",
      "|    total_timesteps | 123198   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.3    |\n",
      "|    critic_loss     | 0.795    |\n",
      "|    ent_coef        | 0.0122   |\n",
      "|    ent_coef_loss   | -0.595   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 123097   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-129.72 +/- 9.73\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -130     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 125000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.3    |\n",
      "|    critic_loss     | 2.8      |\n",
      "|    ent_coef        | 0.0102   |\n",
      "|    ent_coef_loss   | -0.242   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 124899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03e+03 |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 847      |\n",
      "|    total_timesteps | 128748   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.35    |\n",
      "|    critic_loss     | 0.572    |\n",
      "|    ent_coef        | 0.0107   |\n",
      "|    ent_coef_loss   | 1.41     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 128647   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-111.61 +/- 46.92\n",
      "Episode length: 1508.60 +/- 182.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.51e+03 |\n",
      "|    mean_reward     | -112     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 130000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.78    |\n",
      "|    critic_loss     | 0.925    |\n",
      "|    ent_coef        | 0.0102   |\n",
      "|    ent_coef_loss   | 0.153    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 129899   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-11.54 +/- 17.62\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -11.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 135000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.08    |\n",
      "|    critic_loss     | 0.421    |\n",
      "|    ent_coef        | 0.00849  |\n",
      "|    ent_coef_loss   | -0.057   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 134899   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 894      |\n",
      "|    total_timesteps | 135148   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.77    |\n",
      "|    critic_loss     | 1.24     |\n",
      "|    ent_coef        | 0.00853  |\n",
      "|    ent_coef_loss   | 0.494    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 135047   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 916      |\n",
      "|    total_timesteps | 138752   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.42    |\n",
      "|    critic_loss     | 0.544    |\n",
      "|    ent_coef        | 0.00892  |\n",
      "|    ent_coef_loss   | 1.13     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 138651   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | -107     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 921      |\n",
      "|    total_timesteps | 139644   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.04    |\n",
      "|    critic_loss     | 0.587    |\n",
      "|    ent_coef        | 0.00882  |\n",
      "|    ent_coef_loss   | -2.15    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 139543   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-54.36 +/- 41.34\n",
      "Episode length: 1337.20 +/- 525.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.34e+03 |\n",
      "|    mean_reward     | -54.4    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 140000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.83    |\n",
      "|    critic_loss     | 0.702    |\n",
      "|    ent_coef        | 0.00881  |\n",
      "|    ent_coef_loss   | 1.33     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 139899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 946      |\n",
      "|    total_timesteps | 143181   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.47    |\n",
      "|    critic_loss     | 0.874    |\n",
      "|    ent_coef        | 0.00878  |\n",
      "|    ent_coef_loss   | -0.661   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 143080   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-87.73 +/- 28.00\n",
      "Episode length: 1492.80 +/- 214.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.49e+03 |\n",
      "|    mean_reward     | -87.7    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 145000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.35    |\n",
      "|    critic_loss     | 0.497    |\n",
      "|    ent_coef        | 0.00841  |\n",
      "|    ent_coef_loss   | 0.198    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 144899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.1e+03  |\n",
      "|    ep_rew_mean     | -104     |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 989      |\n",
      "|    total_timesteps | 149581   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.98    |\n",
      "|    critic_loss     | 0.815    |\n",
      "|    ent_coef        | 0.00776  |\n",
      "|    ent_coef_loss   | -0.558   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 149480   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-67.55 +/- 8.02\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -67.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 150000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.44    |\n",
      "|    critic_loss     | 1.05     |\n",
      "|    ent_coef        | 0.00767  |\n",
      "|    ent_coef_loss   | 0.638    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 149899   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-76.29 +/- 24.73\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -76.3    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 155000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.61    |\n",
      "|    critic_loss     | 0.758    |\n",
      "|    ent_coef        | 0.00732  |\n",
      "|    ent_coef_loss   | 0.302    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 154899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.13e+03 |\n",
      "|    ep_rew_mean     | -100     |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 1036     |\n",
      "|    total_timesteps | 155981   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.25    |\n",
      "|    critic_loss     | 0.814    |\n",
      "|    ent_coef        | 0.00741  |\n",
      "|    ent_coef_loss   | 0.729    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 155880   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-69.25 +/- 38.28\n",
      "Episode length: 1444.20 +/- 311.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.44e+03 |\n",
      "|    mean_reward     | -69.2    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 160000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.4     |\n",
      "|    critic_loss     | 0.621    |\n",
      "|    ent_coef        | 0.00693  |\n",
      "|    ent_coef_loss   | 0.559    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 159899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.17e+03 |\n",
      "|    ep_rew_mean     | -96.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 1078     |\n",
      "|    total_timesteps | 162381   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.696   |\n",
      "|    critic_loss     | 0.43     |\n",
      "|    ent_coef        | 0.00761  |\n",
      "|    ent_coef_loss   | 2.23     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 162280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-38.86 +/- 17.02\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -38.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 165000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.74    |\n",
      "|    critic_loss     | 0.312    |\n",
      "|    ent_coef        | 0.00766  |\n",
      "|    ent_coef_loss   | -0.494   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 164899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.21e+03 |\n",
      "|    ep_rew_mean     | -91.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 1117     |\n",
      "|    total_timesteps | 168078   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.75     |\n",
      "|    critic_loss     | 0.394    |\n",
      "|    ent_coef        | 0.00695  |\n",
      "|    ent_coef_loss   | -0.061   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 167977   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-55.51 +/- 29.81\n",
      "Episode length: 1396.00 +/- 408.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.4e+03  |\n",
      "|    mean_reward     | -55.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 170000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.08    |\n",
      "|    critic_loss     | 0.391    |\n",
      "|    ent_coef        | 0.00636  |\n",
      "|    ent_coef_loss   | -0.539   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 169899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.24e+03 |\n",
      "|    ep_rew_mean     | -87.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 1160     |\n",
      "|    total_timesteps | 174478   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.32     |\n",
      "|    critic_loss     | 0.456    |\n",
      "|    ent_coef        | 0.00555  |\n",
      "|    ent_coef_loss   | 0.389    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 174377   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-55.87 +/- 26.16\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -55.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 175000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.1      |\n",
      "|    critic_loss     | 0.66     |\n",
      "|    ent_coef        | 0.00552  |\n",
      "|    ent_coef_loss   | -2.08    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 174899   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-83.78 +/- 47.55\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -83.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 180000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.4      |\n",
      "|    critic_loss     | 0.21     |\n",
      "|    ent_coef        | 0.0052   |\n",
      "|    ent_coef_loss   | -0.0758  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 179899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.27e+03 |\n",
      "|    ep_rew_mean     | -85.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1207     |\n",
      "|    total_timesteps | 180878   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.303    |\n",
      "|    critic_loss     | 0.293    |\n",
      "|    ent_coef        | 0.0051   |\n",
      "|    ent_coef_loss   | -1.63    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 180777   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-35.27 +/- 4.00\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -35.3    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 185000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1        |\n",
      "|    critic_loss     | 0.172    |\n",
      "|    ent_coef        | 0.00535  |\n",
      "|    ent_coef_loss   | -0.248   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 184899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.29e+03 |\n",
      "|    ep_rew_mean     | -82.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1250     |\n",
      "|    total_timesteps | 187278   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.24     |\n",
      "|    critic_loss     | 0.367    |\n",
      "|    ent_coef        | 0.00525  |\n",
      "|    ent_coef_loss   | 0.373    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 187177   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-76.88 +/- 35.99\n",
      "Episode length: 1350.00 +/- 500.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.35e+03 |\n",
      "|    mean_reward     | -76.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 190000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.02     |\n",
      "|    critic_loss     | 0.35     |\n",
      "|    ent_coef        | 0.00512  |\n",
      "|    ent_coef_loss   | -0.817   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 189899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | -80      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1292     |\n",
      "|    total_timesteps | 193678   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.59     |\n",
      "|    critic_loss     | 0.617    |\n",
      "|    ent_coef        | 0.0059   |\n",
      "|    ent_coef_loss   | -0.973   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 193577   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-69.15 +/- 7.30\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -69.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 195000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.367   |\n",
      "|    critic_loss     | 0.736    |\n",
      "|    ent_coef        | 0.00691  |\n",
      "|    ent_coef_loss   | -0.336   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 194899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | -79.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1326     |\n",
      "|    total_timesteps | 198720   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.8     |\n",
      "|    critic_loss     | 1.32     |\n",
      "|    ent_coef        | 0.00978  |\n",
      "|    ent_coef_loss   | 0.327    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 198619   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-84.24 +/- 4.94\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -84.2    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 200000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.51    |\n",
      "|    critic_loss     | 1.17     |\n",
      "|    ent_coef        | 0.0133   |\n",
      "|    ent_coef_loss   | 1.19     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 199899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | -80.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1361     |\n",
      "|    total_timesteps | 203651   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.1    |\n",
      "|    critic_loss     | 2.31     |\n",
      "|    ent_coef        | 0.0271   |\n",
      "|    ent_coef_loss   | 1.88     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 203550   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=-121.80 +/- 3.76\n",
      "Episode length: 215.80 +/- 40.97\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 216      |\n",
      "|    mean_reward     | -122     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 205000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.7    |\n",
      "|    critic_loss     | 1.31     |\n",
      "|    ent_coef        | 0.0296   |\n",
      "|    ent_coef_loss   | 1.7      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 204899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | -81      |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1392     |\n",
      "|    total_timesteps | 208646   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.2    |\n",
      "|    critic_loss     | 1.68     |\n",
      "|    ent_coef        | 0.0256   |\n",
      "|    ent_coef_loss   | 0.0843   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 208545   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-123.28 +/- 8.48\n",
      "Episode length: 1310.40 +/- 579.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.31e+03 |\n",
      "|    mean_reward     | -123     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 210000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.6    |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    ent_coef        | 0.022    |\n",
      "|    ent_coef_loss   | -1.26    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 209899   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-107.83 +/- 6.07\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -108     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 215000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21      |\n",
      "|    critic_loss     | 1.02     |\n",
      "|    ent_coef        | 0.0128   |\n",
      "|    ent_coef_loss   | -0.837   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 214899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | -81.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1440     |\n",
      "|    total_timesteps | 215046   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20.9    |\n",
      "|    critic_loss     | 1.49     |\n",
      "|    ent_coef        | 0.0128   |\n",
      "|    ent_coef_loss   | -1.16    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 214945   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.32e+03 |\n",
      "|    ep_rew_mean     | -81.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1459     |\n",
      "|    total_timesteps | 218271   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.1    |\n",
      "|    critic_loss     | 1.26     |\n",
      "|    ent_coef        | 0.0107   |\n",
      "|    ent_coef_loss   | -1.09    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 218170   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-81.96 +/- 123.00\n",
      "Episode length: 1094.40 +/- 446.88\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.09e+03 |\n",
      "|    mean_reward     | -82      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 220000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17      |\n",
      "|    critic_loss     | 0.906    |\n",
      "|    ent_coef        | 0.0113   |\n",
      "|    ent_coef_loss   | 0.941    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 219899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | -81.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1498     |\n",
      "|    total_timesteps | 224130   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.2    |\n",
      "|    critic_loss     | 0.651    |\n",
      "|    ent_coef        | 0.0107   |\n",
      "|    ent_coef_loss   | -0.215   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 224029   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-87.99 +/- 22.14\n",
      "Episode length: 1027.00 +/- 701.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.03e+03 |\n",
      "|    mean_reward     | -88      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 225000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 0.508    |\n",
      "|    ent_coef        | 0.0102   |\n",
      "|    ent_coef_loss   | -0.0812  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 224899   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-3.59 +/- 28.69\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -3.59    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 230000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 1.42     |\n",
      "|    ent_coef        | 0.0077   |\n",
      "|    ent_coef_loss   | 0.665    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 229899   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | -78.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1544     |\n",
      "|    total_timesteps | 230530   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.5    |\n",
      "|    critic_loss     | 0.24     |\n",
      "|    ent_coef        | 0.00738  |\n",
      "|    ent_coef_loss   | -1.45    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 230429   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=51.85 +/- 36.20\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | 51.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 235000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.22    |\n",
      "|    critic_loss     | 0.739    |\n",
      "|    ent_coef        | 0.0066   |\n",
      "|    ent_coef_loss   | 2.79     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 234899   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | -74.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1587     |\n",
      "|    total_timesteps | 236930   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.69    |\n",
      "|    critic_loss     | 0.347    |\n",
      "|    ent_coef        | 0.00637  |\n",
      "|    ent_coef_loss   | 0.576    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 236829   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=82.88 +/- 31.82\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | 82.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 240000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.21    |\n",
      "|    critic_loss     | 0.655    |\n",
      "|    ent_coef        | 0.00653  |\n",
      "|    ent_coef_loss   | 0.536    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 239899   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | -71.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1629     |\n",
      "|    total_timesteps | 243052   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.6     |\n",
      "|    critic_loss     | 0.273    |\n",
      "|    ent_coef        | 0.00586  |\n",
      "|    ent_coef_loss   | -1.69    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 242951   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=-46.46 +/- 74.91\n",
      "Episode length: 1470.20 +/- 259.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.47e+03 |\n",
      "|    mean_reward     | -46.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 245000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.08    |\n",
      "|    critic_loss     | 0.377    |\n",
      "|    ent_coef        | 0.0056   |\n",
      "|    ent_coef_loss   | 0.37     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 244899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | -69.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1663     |\n",
      "|    total_timesteps | 247947   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.1     |\n",
      "|    critic_loss     | 0.671    |\n",
      "|    ent_coef        | 0.00461  |\n",
      "|    ent_coef_loss   | -0.82    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 247846   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-45.39 +/- 9.29\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -45.4    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 250000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.48    |\n",
      "|    critic_loss     | 0.234    |\n",
      "|    ent_coef        | 0.00434  |\n",
      "|    ent_coef_loss   | -3       |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 249899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.37e+03 |\n",
      "|    ep_rew_mean     | -66      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 1706     |\n",
      "|    total_timesteps | 254347   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1       |\n",
      "|    critic_loss     | 0.29     |\n",
      "|    ent_coef        | 0.00394  |\n",
      "|    ent_coef_loss   | 0.241    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 254246   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=-51.95 +/- 19.96\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -51.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 255000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.91    |\n",
      "|    critic_loss     | 0.227    |\n",
      "|    ent_coef        | 0.00424  |\n",
      "|    ent_coef_loss   | -1.91    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 254899   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-79.09 +/- 5.50\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -79.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 260000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.09    |\n",
      "|    critic_loss     | 0.268    |\n",
      "|    ent_coef        | 0.00367  |\n",
      "|    ent_coef_loss   | 0.555    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 259899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | -60      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 1753     |\n",
      "|    total_timesteps | 260747   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.09    |\n",
      "|    critic_loss     | 0.199    |\n",
      "|    ent_coef        | 0.00375  |\n",
      "|    ent_coef_loss   | -1.42    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 260646   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-63.57 +/- 6.95\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | -63.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 265000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.157    |\n",
      "|    critic_loss     | 0.398    |\n",
      "|    ent_coef        | 0.00403  |\n",
      "|    ent_coef_loss   | 0.242    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 264899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | -55.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 1796     |\n",
      "|    total_timesteps | 267147   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.428   |\n",
      "|    critic_loss     | 0.225    |\n",
      "|    ent_coef        | 0.00367  |\n",
      "|    ent_coef_loss   | -1.53    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 267046   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=1.09 +/- 66.47\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | 1.09     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 270000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.734   |\n",
      "|    critic_loss     | 0.264    |\n",
      "|    ent_coef        | 0.0041   |\n",
      "|    ent_coef_loss   | 0.19     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 269899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | -51.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 1834     |\n",
      "|    total_timesteps | 272786   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.54    |\n",
      "|    critic_loss     | 0.134    |\n",
      "|    ent_coef        | 0.00357  |\n",
      "|    ent_coef_loss   | -4.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 272685   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-123.61 +/- 29.82\n",
      "Episode length: 904.80 +/- 386.31\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 905      |\n",
      "|    mean_reward     | -124     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 275000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.07    |\n",
      "|    critic_loss     | 0.358    |\n",
      "|    ent_coef        | 0.00365  |\n",
      "|    ent_coef_loss   | -1.03    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 274899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.39e+03 |\n",
      "|    ep_rew_mean     | -47.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 1869     |\n",
      "|    total_timesteps | 278141   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.363    |\n",
      "|    critic_loss     | 0.154    |\n",
      "|    ent_coef        | 0.00329  |\n",
      "|    ent_coef_loss   | 1.32     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 278040   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-42.72 +/- 23.36\n",
      "Episode length: 1415.40 +/- 369.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.42e+03 |\n",
      "|    mean_reward     | -42.7    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 280000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.036   |\n",
      "|    critic_loss     | 0.17     |\n",
      "|    ent_coef        | 0.00323  |\n",
      "|    ent_coef_loss   | 1.38     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 279899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.44e+03 |\n",
      "|    ep_rew_mean     | -42.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 1906     |\n",
      "|    total_timesteps | 283630   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.761    |\n",
      "|    critic_loss     | 0.157    |\n",
      "|    ent_coef        | 0.00316  |\n",
      "|    ent_coef_loss   | 1.08     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 283529   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=22.74 +/- 47.79\n",
      "Episode length: 1487.60 +/- 224.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.49e+03 |\n",
      "|    mean_reward     | 22.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 285000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.394   |\n",
      "|    critic_loss     | 0.12     |\n",
      "|    ent_coef        | 0.00357  |\n",
      "|    ent_coef_loss   | -2.52    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 284899   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=94.03 +/- 48.93\n",
      "Episode length: 1565.80 +/- 68.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.57e+03 |\n",
      "|    mean_reward     | 94       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 290000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.683   |\n",
      "|    critic_loss     | 0.143    |\n",
      "|    ent_coef        | 0.00413  |\n",
      "|    ent_coef_loss   | -0.806   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 289899   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.47e+03 |\n",
      "|    ep_rew_mean     | -36.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 1954     |\n",
      "|    total_timesteps | 290029   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.613    |\n",
      "|    critic_loss     | 0.343    |\n",
      "|    ent_coef        | 0.00414  |\n",
      "|    ent_coef_loss   | 3.84     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 289928   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=172.48 +/- 8.13\n",
      "Episode length: 1600.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.6e+03  |\n",
      "|    mean_reward     | 172      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 295000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.09    |\n",
      "|    critic_loss     | 0.116    |\n",
      "|    ent_coef        | 0.00417  |\n",
      "|    ent_coef_loss   | -1.22    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 294899   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.47e+03 |\n",
      "|    ep_rew_mean     | -27.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 1998     |\n",
      "|    total_timesteps | 296429   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.324    |\n",
      "|    critic_loss     | 0.2      |\n",
      "|    ent_coef        | 0.00414  |\n",
      "|    ent_coef_loss   | 1.79     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 296328   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=103.39 +/- 76.16\n",
      "Episode length: 1490.00 +/- 134.74\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.49e+03 |\n",
      "|    mean_reward     | 103      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 300000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.839   |\n",
      "|    critic_loss     | 0.198    |\n",
      "|    ent_coef        | 0.00428  |\n",
      "|    ent_coef_loss   | -1.97    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 299899   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Monitor(gym.make(\"BipedalWalker-v3\"))\n",
    "eval_env = Monitor(gym.make(\"BipedalWalker-v3\"))\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./models/sac/\",\n",
    "    log_path=\"./logs/sac/\",\n",
    "    eval_freq=5000,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./sac_tensorboard/\")\n",
    "model.learn(total_timesteps=300_000, callback=eval_callback)\n",
    "model.save(\"./models/sac/best_model\")\n",
    "\n",
    "# === Graficar recompensas ===\n",
    "eval_file_npz = \"./logs/sac/evaluations.npz\"\n",
    "\n",
    "if os.path.exists(eval_file_npz):\n",
    "    data = np.load(eval_file_npz)\n",
    "    timesteps = data[\"timesteps\"]\n",
    "    results = data[\"results\"]\n",
    "\n",
    "    # Calcular promedio y desviación de recompensas\n",
    "    mean_rewards = results.mean(axis=1)\n",
    "    std_rewards = results.std(axis=1)\n",
    "\n",
    "    plt.plot(timesteps, mean_rewards, label=\"Evaluación (promedio)\")\n",
    "    plt.fill_between(\n",
    "        timesteps,\n",
    "        mean_rewards - std_rewards,\n",
    "        mean_rewards + std_rewards,\n",
    "        alpha=0.2,\n",
    "        label=\"Desvío estándar\",\n",
    "    )\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Recompensa media\")\n",
    "    plt.title(\"Evolución SAC - BipedalWalker-v3\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No se encontró evaluations.npz — puede que el callback no haya guardado evaluaciones.\")\n",
    "\n",
    "# === Cargar y evaluar ===\n",
    "model = SAC.load(\"./models/sac/best_model\")\n",
    "obs, _ = env.reset()\n",
    "for step in range(1500):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    if done or truncated:\n",
    "        obs, _ = env.reset()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "442c92de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mean_reward(alg_name):\n",
    "    eval_file = f\"./logs/{alg_name}/evaluations.npz\"\n",
    "    if os.path.exists(eval_file):\n",
    "        data = np.load(eval_file)\n",
    "        results = data[\"results\"]  # matriz [n_evals, n_episodios]\n",
    "        return results.mean(axis=1)[-1]  # promedio del último bloque de evaluaciones\n",
    "    else:\n",
    "        print(f\"⚠️ No se encontró evaluations.npz para {alg_name}\")\n",
    "        return np.nan\n",
    "\n",
    "# === Comparar los tres algoritmos ===\n",
    "algos = [\"a2c\", \"ppo\", \"sac\"]\n",
    "means = [get_mean_reward(a) for a in algos]\n",
    "\n",
    "plt.bar(algos, means, color=[\"orange\", \"blue\", \"green\"])\n",
    "plt.ylabel(\"Recompensa media final\")\n",
    "plt.title(\"Comparativa A2C vs PPO vs SAC - BipedalWalker-v3\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceia-aprendizajerefuerzoii-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
